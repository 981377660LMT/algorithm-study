# 前端处理并发问题，有合适的解决方式吗，最佳实践是什么，如何运用分布式理论分析问题 比如表单联动场景

## 并发问题

并发问题通常指多个异步操作在时间上交错执行，导致程序状态或结果依赖于不可控的执行顺序。
当用户操作频繁或有多个请求同时进行时，前端可能出现：

- **竞态条件和数据不一致**：由于异步请求返回顺序无法保证，可能出现早发出的请求晚返回，覆盖了用户更后发出的操作结果​。例如用户快速切换选项卡，最后停留的Tab内容可能被第一个Tab的迟返结果覆盖，导致显示错误内容。
- **重复或冲突请求**：用户多次点击提交，可能产生重复的数据提交；或者两个并发操作尝试修改同一数据，造成冲突。

## 前端处理并发问题的通用解决方案

核心原则是：要么避免并发发生，要么正确处理并发结果。

- 避免并发发生

  - **请求去重与合并**：合并请求，减少请求次数。
  - **节流和防抖**

- 处理并发结果

  **目的：保证数据的最终一致性。**
  `加锁`保证数据的最终一致性；注意前端不存在强一致性，强一致性依赖于共识。
  Consistency Models 是 safety 属性，而最终一致性是 liveness 属性。

  1. 乐观锁
     **在用户操作后立即更新 UI，提高可用性**
     例如：用户点击“点赞”，前端先将点赞数加 1，同时发送更新请求；若服务器返回冲突（例如数据版本不一致），则回滚或提示用户。

     - 版本号/时间戳检测更新冲突
     - 取消更新

  2. 悲观锁

     **在用户操作后 UI 会有锁定状态。**
     比如按钮置灰，或者显示 loading 状态，防止其他用户同时修改数据。

     - mutex

       1. 获取锁失败，被打回
          实现方式为 `locked` 字段。
       2. 获取锁失败，阻塞等待
          实现方式为 `promise + 队列`

          ```js
          // 当用户重复点击提交按钮时，会发送多次请求
          // 此时，多个函数中的 doSomething() 没有 happens-before 关系，会导致 race condition
          async function handleClick() {
            await doSomething()
          }

          // 悲观锁的实现方式
          // 此时可以保证，第一个handleClick()完全执行完后，第二个handleClick()才会执行
          async function handleClick() {
            try {
              await mu.lock()
              await doSomething()
            } finally {
              mu.unlock()
            }
          }
          ```

## 理解

1. 有时候不需要满足最终一致性。
   想一想，`不满足最终一致性的后果是什么`？
   如果用户可以接受，则不需要。最终一致性 = 没有一致性。

2. cancel、版本号等方法本质是什么，用数据同步，一致性理论解释
   从数据同步和一致性理论的角度看，版本号及其替代方案的本质都是为了**提供一种机制，在多节点（或多客户端）同时对数据进行操作时，保证数据最终能够按照预期顺序合并并保持一致。**
3. 递归函数加锁会不会死锁，如何解决
   在递归函数中如果使用普通的、不可重入的锁（non-recursive lock），会很容易导致死锁。原因在于，递归调用会在同一线程中多次尝试获取同一把锁，而普通锁在同一线程中再次请求时会被阻塞，导致程序永远等待自己释放锁，从而形成死锁。

   为了解决这个问题，可以采用以下两种方法：

   - **使用递归锁（可重入锁）：**  
      递归锁`允许同一线程在持有锁的情况下多次加锁，而不会阻塞自己`。内部通常会维护一个计数器，记录加锁次数，只有当计数器归零时才真正释放锁。例如，在 C/C++ 中，可以通过设置 `pthread_mutexattr_settype` 为 `PTHREAD_MUTEX_RECURSIVE` 来创建递归锁；在 Java 中使用 `ReentrantLock`；在 Python 中使用 `threading.RLock`。

   - **调整锁粒度：**  
      如果条件允许，也可以**考虑把锁放到递归函数的外层**，只在进入递归前加锁，递归结束后再解锁，这样就避免了在递归过程中反复加锁的需求，从而避免死锁风险。

   综上所述，关键在于避免同一线程在未释放锁的情况下再次请求普通锁。如果需要在递归过程中保护共享资源，最佳实践就是使用递归锁或重新设计代码逻辑以减少锁的使用。
