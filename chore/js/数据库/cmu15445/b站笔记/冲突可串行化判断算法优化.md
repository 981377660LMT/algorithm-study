# 优化冲突可串行化判断算法

当前算法中的双重循环是检查操作间冲突的主要性能瓶颈，时间复杂度为O(n²)，其中n是操作数量。以下是几种优化方法：

## 方法1：使用哈希表索引数据项

最直接的优化是按数据项对操作进行分组，这样我们只需要比较访问相同数据项的操作。

```python
def is_conflict_serializable_optimized(schedule):
    transactions = set(op.transaction for op in schedule)
    graph = DirectedGraph()

    for txn in transactions:
        graph.add_node(txn)

    # 按数据项对操作进行分组
    data_item_ops = {}
    for i, op in enumerate(schedule):
        if op.data_item not in data_item_ops:
            data_item_ops[op.data_item] = []
        data_item_ops[op.data_item].append((i, op))

    # 只比较操作相同数据项的操作
    for data_item, operations in data_item_ops.items():
        for i in range(len(operations)):
            idx_i, op_i = operations[i]
            for j in range(i+1, len(operations)):
                idx_j, op_j = operations[j]

                # 检查是否来自不同事务
                if op_i.transaction != op_j.transaction:
                    # 检查是否冲突
                    if op_i.is_write() or op_j.is_write():
                        graph.add_edge(op_i.transaction, op_j.transaction)

    # 检测环
    if graph.has_cycle():
        return False, None

    # 生成等价串行顺序
    serial_order = graph.topological_sort()
    return True, serial_order
```

这种优化在操作分散在多个不同数据项时特别有效，可以将比较次数从O(n²)减少到Σk_i²，其中k_i是访问数据项i的操作数量。

## 方法2：增量构建依赖图

我们可以在线性扫描调度的同时构建依赖图，并跟踪每个数据项最后一次被哪个事务读/写。

```python
def is_conflict_serializable_incremental(schedule):
    transactions = set(op.transaction for op in schedule)
    graph = DirectedGraph()

    for txn in transactions:
        graph.add_node(txn)

    # 跟踪每个数据项的最后读/写事务
    last_read = {}   # 数据项 -> 读取事务集合
    last_write = {}  # 数据项 -> 写入事务

    for op in schedule:
        item = op.data_item
        txn = op.transaction

        if op.is_write():  # 写操作
            # 添加从之前读取该项的所有事务到当前事务的边
            if item in last_read:
                for reader in last_read[item]:
                    if reader != txn:
                        graph.add_edge(reader, txn)

            # 添加从之前写入该项的事务到当前事务的边
            if item in last_write and last_write[item] != txn:
                graph.add_edge(last_write[item], txn)

            # 更新最后写入记录
            last_write[item] = txn
            # 清除读记录，只保留当前事务
            last_read[item] = {txn} if op.type == 'R' else set()
        else:  # 读操作
            # 添加从之前写入该项的事务到当前事务的边
            if item in last_write and last_write[item] != txn:
                graph.add_edge(last_write[item], txn)

            # 更新最后读取记录
            if item not in last_read:
                last_read[item] = set()
            last_read[item].add(txn)

    # 检测环和生成拓扑排序
    if graph.has_cycle():
        return False, None

    serial_order = graph.topological_sort()
    return True, serial_order
```

这种方法的时间复杂度是O(n)，因为我们只需遍历一次调度，然后对每个操作执行常数时间的工作。

## 方法3：使用二进制关系矩阵

如果事务数量不多，我们可以直接使用邻接矩阵表示依赖关系：

```python
def is_conflict_serializable_matrix(schedule):
    # 提取并映射事务ID到连续索引
    txn_set = set(op.transaction for op in schedule)
    txn_to_idx = {txn: i for i, txn in enumerate(txn_set)}
    n_txns = len(txn_set)

    # 初始化依赖矩阵
    dep_matrix = [[0] * n_txns for _ in range(n_txns)]

    # 按数据项对操作分组
    data_item_ops = {}
    for op in schedule:
        if op.data_item not in data_item_ops:
            data_item_ops[op.data_item] = []
        data_item_ops[op.data_item].append(op)

    # 填充依赖矩阵
    for ops in data_item_ops.values():
        for i in range(len(ops)):
            for j in range(i+1, len(ops)):
                op_i, op_j = ops[i], ops[j]
                if op_i.transaction != op_j.transaction and (op_i.is_write() or op_j.is_write()):
                    idx_i = txn_to_idx[op_i.transaction]
                    idx_j = txn_to_idx[op_j.transaction]
                    dep_matrix[idx_i][idx_j] = 1

    # 检测环（使用矩阵幂）
    # 如果第i行第j列的闭包结果为1，表示从i到j有路径
    closure = dep_matrix.copy()
    for k in range(n_txns):
        for i in range(n_txns):
            for j in range(n_txns):
                if closure[i][k] and closure[k][j]:
                    closure[i][j] = 1

    # 检查对角线，如果有1则存在环
    for i in range(n_txns):
        if closure[i][i] == 1:
            return False, None

    # 使用拓扑排序生成等价串行顺序
    visited = [False] * n_txns
    stack = []

    def topo_sort_util(node):
        visited[node] = True
        for i in range(n_txns):
            if dep_matrix[node][i] and not visited[i]:
                topo_sort_util(i)
        stack.append(node)

    for i in range(n_txns):
        if not visited[i]:
            topo_sort_util(i)

    # 逆转获得正确顺序，并将索引映射回事务ID
    idx_to_txn = {i: txn for txn, i in txn_to_idx.items()}
    serial_order = [idx_to_txn[stack[n_txns-i-1]] for i in range(n_txns)]

    return True, serial_order
```

这种方法在事务数量较少时效率高，时间复杂度主要是O(t³)用于传递闭包，其中t是事务数量。

## 方法4：多线程并行处理

如果操作或事务数量极大，可以考虑并行处理：

```python
import concurrent.futures

def is_conflict_serializable_parallel(schedule):
    transactions = set(op.transaction for op in schedule)
    graph = DirectedGraph()

    for txn in transactions:
        graph.add_node(txn)

    # 按数据项分组
    data_item_ops = {}
    for op in schedule:
        if op.data_item not in data_item_ops:
            data_item_ops[op.data_item] = []
        data_item_ops[op.data_item].append(op)

    # 每个数据项的操作分别处理冲突
    def process_data_item(ops):
        edges = []
        for i in range(len(ops)):
            for j in range(i+1, len(ops)):
                op_i, op_j = ops[i], ops[j]
                if op_i.transaction != op_j.transaction and (op_i.is_write() or op_j.is_write()):
                    edges.append((op_i.transaction, op_j.transaction))
        return edges

    # 并行处理所有数据项
    all_edges = []
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future_to_item = {executor.submit(process_data_item, ops): ops
                         for ops in data_item_ops.values()}

        for future in concurrent.futures.as_completed(future_to_item):
            all_edges.extend(future.result())

    # 构建图
    for from_txn, to_txn in all_edges:
        graph.add_edge(from_txn, to_txn)

    # 检查环和生成拓扑排序
    if graph.has_cycle():
        return False, None

    serial_order = graph.topological_sort()
    return True, serial_order
```

## 总结优化策略

1. **数据项分组**：按数据项对操作进行分组，只比较操作同一数据项的操作
2. **增量构建**：线性扫描调度，维护每个数据项的最后读/写记录
3. **矩阵表示**：使用邻接矩阵直接表示事务间依赖关系
4. **并行处理**：对大规模调度，可以并行检测不同数据项上的冲突

一个平衡的实现可能是：

- 对于小型调度（<1000操作），使用方法2（增量构建）
- 对于中型调度，使用方法1（数据项分组）
- 对于大型调度，使用方法4（并行处理）
- 如果事务数量远小于操作数量，可以考虑方法3（矩阵表示）

这些优化使判断冲突可串行化的算法在大多数实际场景中都能高效执行，为数据库系统的并发控制提供理论支持。
