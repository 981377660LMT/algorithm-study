2018-03-04-消息队列
https://blog.fishedee.com/2018/03/04/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/#%E9%94%99%E5%B3%B0%E6%B5%81%E6%8E%A7

## 概述

无论是在单一系统还是在分布式系统，消息队列都是不可或缺的一个重要部分

## 作用

1. 解耦
   发布订阅模式
   将依赖反过来，其他系统提前订阅了这个 topic 的信息，当这个 topic 的信息被触发时，由队列来负责通知各个系统
2. 削峰限流
   发邮件的例子
   即使是异步操作，发送邮件的并发量也不能太大，避免被对方拉入恶意攻击黑名单，所以也需要流量控制
   队列的作用是，将发送邮件放入到队列中，由队列通知邮箱系统来往外发送邮件。而无论工作量有多庞大，`同时最多只有 N 个邮箱进程在往外并发发邮件`，一旦邮件太多忙不过来，这些邮件就会堆积在队列中等候发送。这样做既避免了邮箱系统拖垮了用户系统，又避免了邮箱系统并发量太大，有效地控制了最大流量，避免了峰值流量下雪崩的问题
3. 最终一致性事务(使用事件和消息队列实现分布式事务)
   https://www.cnblogs.com/520playboy/p/6715438.html
   https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%AB%98%E6%89%8B%E8%AF%BE/04%20%20%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%EF%BC%9F.md

   微服务的成本，其中的一个莫过于`分布式事务`了
   在以前的单一系统中，要保证数据是强一致性的，相当简单，`直接在 db 层 begin，然后 commit 启动一个事务就可以了`，由数据库的 ACID 特性保证不可能出现数据不一致的情况

   - 使用本地事务和消息队列的组合

   1. 开启事务
   2. 发送半消息
   3. 成功后执行本地事务，创建订单
   4. 本地事务执行成功，则提交事务；本地事务执行失败，则回滚事务
      如果如果本地事务执行成功，提交事务的时候，请求失败了，怎么办？或者本地事务执行失败，回滚事务的时候失败了，怎么办？
      问题的本质：`如何让生产者和消费者的操作数据库和操作消息队列这两个操作成为一个原子操作`
      **任何涉及到数据库和中间件之间的业务逻辑操作，都需要考虑二者之间的一致性**
      比如，你先操作了数据库，再操作缓存，数据库和缓存之间一致性如何解决？

      - Kafka：直接抛出异常，让用户自行处理。我们可以在业务代码中反复重试提交，直到提交成功，或者删除之前创建的订单进行补偿
      - RocketMQ：提供了`反查机制`，需要业务代码提供接口，消息队列在未收到发送方的确认消息时，会主动调用业务方提供的接口，查询订单是否创建成功，如果没有成功则删除订单

   `消息队列来实现分布式事务解决了两阶段提交的性能问题`

4. 定时器
   类似 gpm 模型中的全局队列
   让定时器定时向队列发送一个 topic，然后让两台机器竞争地在这个 topic 中获取消息，谁获取到消息的就去执行定时任务，这样就能很好地实现任务的均衡分配了
5. 请求合并
   vue 的 queueJob
   队列如果能将相邻的事件一次合并直接发给处理器来处理，那么这些合并事件就不再需要竞争性插入数据了，这大大地提高了插入性能和系统吞吐量

## 模型

### JMS（没啥用)

topic 通知模式仅仅作为消息转发，不会做消息存储

### AMQP

AMQP 从模式上统一了生产者消费者，和，发布者订阅者两种模式，它引入了两个概念，exchange，queue

缺点：生产者/消费者并发竞争瓶颈，造成吞吐量下降

### kafka(最牛)

有消费者组和消费者的模型，但是没有 topic 与 queue 映射的模型，同时加入了分区(partition)的模型；

大家刚开始就只是把日志放进去，后来连大数据都放进去了。
例如，动态抓取的爬虫数据，用户点击数据，访问数据等等。
然后在 kafka 的另外一端将数据读出来，做流式计算，这样就能实现大数据的实时计算了，
慢慢地衍生出 kafka 的生态系统，形成`成熟的 kafka streams 大数据处理方式`。

## 接收方式

1. push

往死里推消息的方式，很有可能直接打爆消费者;
改进：当消费者收到消息后，需要返回一个 ACK 包给服务器。服务器`按照当前发送的消息量和 ACK 量来确定是否需要将消息暂存服务器，还是仍然继续推送消费者`；
这是目前 rabbitmq 的处理方式。

2. pull

由消费者主动向服务器拉取消息，当消息不存在时，消费者马上返回，然后等候一个时间段以后再继续查询服务器
时效性低，而且消息量小时不断轮询导致瞎忙，浪费资源
这是之前 kafka 的处理方式

3. 长连接

消费者主动发送一个连接给服务器，服务器 hold 住连接，直到收到消息后返回给消费者。
当然，也可以确定一个超时时间，让消费者空等一段时间后先提前返回，实现 `keeplive`。
这样做可以说是最好的，既考虑了消费者的处理速度和承受能力，同时时效性不错，也不会导致瞎忙。
唯一缺点就是对服务器的开发要求比较高，需要同时 hold 住大量的长连接。
目前这个方法是业界最优方案，redis，nsq，rocketmq，kafka 都是这个方案。
