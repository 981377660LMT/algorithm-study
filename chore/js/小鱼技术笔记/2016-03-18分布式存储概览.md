分布式存储概览
https://blog.fishedee.com/2016/03/18/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E6%A6%82%E8%A7%88/

## ACID

1. 简陋数据库
   数据库在执行完 update 操作后，竟然没有调用 file 的 sync，让数据强制写落到磁盘上，而是只缓存到内存中，`导致数据库掉电后重启造成事务丢失`。
   所以，数据库的第一个要求特性是持久性（Durability)，让每个事务执行后都必须落地磁盘，保证即使机器掉电后数据也不会丢失
2. D 数据库

转账断电，发现 10002 用户多了 100 元，而 10002 用户仍然是保持原值，没有增加 100 元!
有一个中间态!
所以，数据库的第二个要求特性是原子性（Atomicity），事务要么是全部提交的，要么是全部不提交的，这部分数据库是用 undo 日志来实现的。

3. AD 数据库

用户在家看到自己的钱突然多了 100 元，而后又少了 100 元。他空欢喜了一场，然后投诉我们公司，为什么给了自己 100 元，然后又突然抽走，他甚至还截图了自己多了 100 元数据的页面
为了避免这种恶心的情况，数据库的第三个要求特性是一致性(Consistency)，数据库只能看到提交后事务的数据，`不能看到事务操作过程中处于不一致状态`的数据。这部分数据库使用 MVCC 机制来实现的。

4. ACD 数据库

用户 10001 需要向 10002 与 10003 用户各转 100 元的，当然 10001 用户只有 120 元的情况下，他会成功么。答案是，他有可能会成功
所以，数据库的第四个要求特性是隔离性（Isolation），事务间应该有隔离，如果他们有数据冲突，应该进行上锁操作的

5. ACID 数据库

我们用了转钱的例子，来证明了 ACID 的每个特性都是多么必要的，不然会导致后果很严重的金钱问题。数据不一致，钱转多了，或者转少了。最后，总结一下 ACID 特性

原子性（Atomicity），强调写一致，要么全部完成，要么全部不完成。
一致性（Consistency），强调读一致，只能看到已经提交的事务数据。
隔离性（Isolation），强调并发一致，即使事务是并发执行的，数据也不会造成不一致。
持久性（Durability)，强调可靠，只要事务提交了，就不会丢失数据。

## CAP (C 和 A 无法同时在分布式系统中同时满足:网络延迟)

CP 和 AP 其实针对就是分布式系统当中的数据状态，在实际业务中还是需要根据实际情况来进行取舍和平衡

在一个 CAP 分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可得兼。

- 一致性（Consistency）：
  在分布式系统中的所有`数据备份，在同一时刻是否同样的值`。（等同于所有节点访问同一份最新的数据副本）
- 可用性（Availability）：
  在集群中一部分节点`故障`后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性）
- 分区容忍性（Partition tolerance）：
  以实际效果而言，分区相当于`对通信的时限要求`。
  系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在 C 和 A 之间做出选择。

CAP 原理就像是能量守恒定律一样，给那些想实现永动机，和想实现`分布式 ACID` 的人们当头一棒，这是不可能的

### 分区容错性

系统要么是分布式的，要么是单机的。

### 一致性

这个一致性和 ACID 的一致性不同，这个一致性是`单个操作的一致性`，而不是`单个事务（多个操作）`的一致性。分布式的一致性有以下几种：

强一致性。在更新完成后，（A、B 或 C 进行的）任何后续访问都将返回更新过的值。
弱一致性。系统不保证后续访问将返回更新过的值。
最终一致性。存储系统保证如果对象没有新的更新，最终（在不一致窗口关闭之后）所有访问都将返回最后更新的值。
注意，弱一致性中包含着最终一致性的范围。

### 可用性

在分布式环境下，有 N 台机器

高可用，N-1 台机器都当机了，仍然可以对外服务。
低可用，1 太机器当机了，就不能对外服务。

### 极端场景

CAP 原理看起来是个绝望的结论，但它其实并没有限制构造这样的系统：

CP 系统，强一致性+基本可用性，即使当掉了 `N/2-1` 台机器，仍然可以对外提供一致性服务。
AP 系统，最终一致性+高可用性，即使当掉了 `N-1` 台机器，仍然可以对外服务，但是数据可能是不一致的，只保证经过一段时间窗口后，数据是最终一致的。

### 各种中间件使用什么理论

https://juejin.cn/post/7021717177220726798

- 单机 mysql:CA
- zookeeper:CP
- eureka:AP
- mysql 主从: 与 redis 类似，一主多从，不保证数据数据节点同步的实时性，保证数据吞吐量使用 AP，保证主从同步一致则使用 CP.
- nacos: 会根据不同的实例类型选择不同的架构
  临时实例，选择 AP 架构，使用 Distro 协议，分布式协议的一种，阿里内部的协议，服务是放在内存中
  持久实例，选择 CP 架构，使用 Raft 协议来实现，点击查看 Raft 协议详情！服务是放在磁盘中

## BASE 原则

BASE 是在无法满足 CAP 原则的情况下评估出的一种原则，代表是基本可用（`B`asically `A`vailable）、软状态（`S`oft state）和最终一致性（`E`ventually consistent）
**BASE 是对 CAP 中一致性和可用性权衡的结果**

- 基本可用指的是分布式系统在遇到故障的情况下降低一定的可用性，例如请求返回要慢点，活动期间出现等待页面。
- 软状态是在和服务器的交互过程中出现下游系统拥堵的情况下，给数据加上一个中间状态，例如商城购买商品时候的支付中，支付完成。允许系统在多个不同节点的数据副本存在数据延时。
- 最终一致性是数据最终要达到一致的情况。比如一笔支付中状态的数据，它最终要么是支付完成，要么是支付失败。支付中的状态存留的时间取决下游支付系统完成这笔支付的时间。

BASE 理论面向的是大型高可用可扩展的分布式系统，和传统的事物 ACID 特性是相反的，它完全不同于 ACID 的强一致性模型，而是通过`牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态`

## 伸缩性

有状态服务，怎样实现数据在多台机器中透明伸缩 -> 一致性哈希算法(寻址?)
分布式的高伸缩性主要要解决的问题是：

- 数据的均衡分布
- 数据的透明迁移

## 可用性

现在数据的确是分布到多个机器上，而且负载均衡了
但是，怎样做到即使崩掉了一两台机器，系统仍然可以无损地对外服务？

1. 单写
   建立多台备机，同时对外只有一台主机在服务，当主机挂掉后，备机顶上即可

   - 强同步：CP 系统
     Master 完成操作后向 Slave 复制数据，需要 await
     优点是主从机器是强一致的
     缺点是从机当机会导致可用性降低
   - 异步：AP 系统
     优点是事务延时与单机无异，同步效率高，备机当机不会影响可用性。
     缺点是主从数据在突然当机下会不一致
   - 半同步：CP 系统->AP 系统->CP 系统的配置
     Master 向 Slave 复制数据出现异常时，超时退化成异步复制
     双节点间的数据复制恢复正常，异步复制会恢复成强同步

2. 多写
   多台机器中的每一台机器都能对外服务的，机器之间的地位平等，所以这种方案叫多写

   - NWR 模型
     N 个节点，W 个节点写入成功即可，R 个节点读取成功即可
     每次写入一个节点的数据，都会自动逐渐传播到其他节点上。`NWR 模型将 CAP 的选择权交给了用户，由用户自己选择 CAP 中的哪两个`。其中，N 代表 N 个备份，W 代表至少写 W 份才认为成功，R 代表至少要读 R 份才认为成功。
     如果 W+R>N ，是可以保证强一致性的。因为 W+R > N， 所以 R > N-W，什么意思呢？就是`读取的份数必须要大于未成功写的份数，这样至少能读到一份最新值`。
     如果 W+R<=N，则能够保证最终一致性。

3. 故障恢复
   在单写的分布式结构下，如果其中一台机器崩溃了，如何向调用方透明地进行故障恢复，恢复系统的可用性
   - paxos 或 raft
     在多台机器中分布式地无中心地选出一个主席

## nosql 实例

考虑伸缩性+可用性

- PostgresSQL
  典型的`单机`关系型数据库，满足 ACID 原则，显然的 AC 系统
- HBase
  hbase 的底层是 hdfs，使用一致性哈希 meta+数据库实现伸缩性，一主多从实现高可用性。显然是 CP 系统
- MongoDb
  使用普通哈希实现伸缩性，一主多从实现高可用性。显然是 CP 系统
- Redis
  默认的 redis 是单机的，redis 集群一般的话是使用一致性哈希做伸缩性，主从做高可用性，显然也是 CP 系统

## 分布式事务

CAP 中的一致性与 ACID 是一致性是不同的，CAP 强调的是`单个数据在分布式中一致性，ACID 强调的是多个数据在事务过程中的一致性`

1. 原子操作
   如果有两个操作要实现事务，第一个想法是能不能将这两个操作合并成一个操作，成为一个事务。
2. 单机事务：利用单机数据库的事务操作实现分布式中多个操作的事务性
   分区时这两个表都是以食谱 ID 为 key，这`保证了这两个表的数据都在同一个数据库下`
3. 重试与幂等
   如果有两个操作要实现事务，第三个想法是能不能`放宽一下数据的一致性，让补偿机制不断重试运行，来保证数据最终的一致性`
   如果中途当机了，没有关系，任务会自动重启执行，由于每个任务都有一个唯一的 UUID，那么任务中任何已重复的部分都不会重做，而只做那些中途当机导致数据不一致的部分。这就是`幂等带来的任务可以无限重试的能力`。
4. **两阶段提交**
   如果在某些情况下，确实需要保证多个操作是同时操作，而且是保证事务一致性怎么办。好了，`只能使用大杀器，真正意义上的分布式事务，两阶段提交协议`

   - 第一阶段：
     `协调者收集所有参与者的意见`，询问这些参与者（包括自身），是否能够提交这个事务；
     参与者在接受到这个 prepare T 消息以后，会根据自身的情况，进行事务的预处理，如果参与者能够提交该事务，则会将日志写入磁盘，并返回给协调者一个 ready T 信息，同时自身进入预提交状态状态；如果不能提交该事务，则记录日志，并返回一个 not commit T 信息给协调者，同时撤销在自身上所做的数据库改
   - 第二阶段：
     如果收到参与者发来的 not commit T 信息，则标识着该事务不能提交，协调者会将 Abort T 记录到日志中，并向所有参与者发送一个 Abort T 信息，让所有参与者撤销在自身上所有的预操作
     如果协调者收到所有参与者发来 prepare T 信息，那么协调者会将 Commit T 日志写入磁盘，并向所有参与者发送一个 Commit T 信息，提交该事务。若协调者迟迟未收到某个参与者发来的信息，则认为该参与者发送了一个 VOTE_ABORT 信息，从而取消该事务的执行。
     `参与者接收到协调者发来的 Abort T 信息以后，参与者会终止提交，并将 Abort T 记录到日志中；如果参与者收到的是 Commit T 信息，则会将事务进行提交，并写入记录`

     两阶段提交协议的假设是第一阶段的耗时较长，第二阶段的耗时很短。第二阶段在分布式中导致数据突然不一致的可能性低，从而来实现分布式事务。为了避免协调者造成单点故障，一般会引入多个协调者，以及 paxos 或 raft 来提高系统的可用性。

## 总结
