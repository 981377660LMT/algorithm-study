# 40亿qq号去重

这个问题其实考察的是“**在数据量非常大且内存有限的情况下，如何去重**”的思路。我们可以从两个层次来分析：

1. **数据量并不太大（能放进内存）时，怎么做？**
2. **数据量特别大（无法一次放进内存）时，怎么做？**

---

## 1. 如果数据量不大，能放进内存怎么办？

1. **用哈希表（HashSet）做去重**
2. **用排序 + 一次线性去重**
   `sort+dedup`

---

## 2. 如果数据量特别大，内存不够怎么办？

题目提到的数据规模可能有 **40 亿个 QQ 号**，而内存只有 **1GB**。要想在内存有限的情况下去重，就得用**外部存储**（硬盘或 SSD）辅助，结合**分而治之**、**外排序**、或**位图** / **布隆过滤器**等技术来实现。

下面介绍几种常见的大规模去重思路：

### 2.1 外排序（External Sort）+ 去重

**外排序**的核心思路是——在内存中只能处理一部分数据时，利用硬盘辅助多次排序。常规做法大概是：

1. **分批读入内存**
   - 从原始文件中，读取能放进内存的一部分数据（例如一次读取几百万或上千万行 QQ 号）。
   - 在内存中对这部分数据进行排序，然后输出到硬盘，形成一个“已排序的临时小文件”。
2. **多路归并**
   - 当所有数据都被分批读完并在硬盘上形成若干个“已排序小文件”后，再把这些小文件做**多路归并**，最后得到一个全局有序的大文件。
3. **一次扫描去重**
   - 对归并出来的有序数据，做一次线性去重（因为相同的 QQ 号都挨在一起）。

这样就能在硬盘辅助下，把所有数据去重并输出。

**优点**：

- 逻辑简单，复用排序思想；
- 一次性得到去重后结果，方便后续处理；
- 可利用现成的“外排序”库或 `MapReduce 框架。`

**缺点**：

- `排序本身的磁盘 I/O 开销较大；`
- 临时文件多，需要管理好磁盘空间。

### 2.2 分段 + Hash（桶划分思想）

有时候我们不一定要对所有数据排序，只要去重就行。那可以采用**分段+hash**（或者说“**分桶**”）的思路：

1. **桶划分**
   - 根据 QQ 号的数值范围，把可能的 QQ 号区间等分成 N 份（例如 N=10 或更大）。每个区间对应一个“桶”。
   - 遍历原始文件中的 QQ 号，根据其数值归属，写入对应桶的文件当中。
     - 比如 QQ 号是 `1234567890`，根据哈希或范围分桶到第 x 号桶文件。
2. **逐个处理桶文件**
   - 对于每个桶文件里的 QQ 号，由于只包含该区间（或哈希值）的数据，数据量减少了。
   - 我们可以依次把桶文件数据读入内存，如果一个桶文件仍然过大，可以再次进行分桶或者分批处理：
     - 小的桶文件可直接在内存里用 `HashSet` 或排序去重；
     - 如果一个桶依然特别大，重复以上步骤：继续拆分或利用外排序思想。
3. **合并输出**
   - 由于每个桶文件是“互不相交”的区间或哈希段，所以不需要跨桶去重。
   - 最后把每个桶去重后的结果拼起来，就得到全局去重后的所有 QQ 号。

**优点**：

- 只关心去重，不做全局排序；
- 利用桶划分，把数据分散到多个文件，单个文件就小得多，方便内存处理。

**缺点**：

- 如果有些分桶的“热点”数据特别多（QQ 号分布不均匀），需要设计好哈希函数或区间划分，否则会导致单个桶过大；
- 依旧需要多次读写硬盘。

### 2.3 位图（BitMap）去重

因为 QQ 号最多只有 10 位数值（**实际范围：0 ~ 9999999999**，大约 100 亿），可以考虑**位图（BitMap）**去重：

- 如果我们给每个 QQ 号对应一个 bit（0/1），当读到某个 QQ 号时，就把该位置的 bit 标记为 1；最终再把标记为 1 的 QQ 号输出。
- 这样可以**快速判断**某个 QQ 号是否出现过。

但题目说**内存只有 1GB**，而 100 亿个 bit 差不多需要 `100亿 / 8 = 12.5 GB` 的空间（不算额外开销），远超过 1GB。因此：

- **单个大位图**无法一次放进 1GB 内存；
- 依旧需要“分段”或“分桶”+ 位图思路：
  1. 先在磁盘上分桶，桶的大小保证**对应的 BitMap 能放入 1GB**。
  2. 依次处理每个桶，用位图标记去重。
  3. 合并输出去重结果。

### 2.4 布隆过滤器（Bloom Filter）

如果对**允许少量误判**（即少量“假阳性”）容忍，或者只想做“某个 QQ 号是否出现过”这种快速判断，可以使用**布隆过滤器**。它通过多个哈希函数把元素映射到一块 bit 数组里：

- 占用空间比位图更少，去重效率高；
- 但布隆过滤器可能存在一定的误判率，如果**完全精确去重**，最终还需要再做一次精确判断。

在**海量数据场景**中，布隆过滤器通常用来做**快速预判**，例如：可能用来做 URL 去重，判断某个网址是否已经抓取过。

---

## 3. 综上，如何在 40 亿个 QQ 号、1GB 内存情况下去重？

结合上面的技术，我们可以总结一个**实际可行的方案**（**分桶 + 外排序**或者**分桶 + 内存去重**）：

1. **分桶**
   - 根据 QQ 号范围或者哈希值，把数据划分到多个桶文件中。
   - 这样每个桶文件只包含一部分数据，总大小在可控范围内。
2. **对每个桶文件做去重**
   - 如果桶文件不算太大，可以读进内存，用 `HashSet` 或**内存排序 + 去重**。
   - 如果单个桶依然过大，则在**该桶内部再做一次多路归并外排序**，然后线性扫描去重。
3. **合并输出**
   - 由于桶之间数据范围互不重叠，所以不需要跨桶去重，合并后即得到最终去重结果。

> 如果在实际工作中，需要进一步提升效率，可以结合多线程或分布式（MapReduce、Spark 等）来并行处理多个桶文件。

---

## 小结

- **能放进内存的情况**：直接用哈希表或排序去重，简单粗暴。
- **内存放不下（海量数据）**：
  1. **外排序**：分批排序 + 多路归并，然后线性去重。
  2. **分桶**：把全量数据划分成多个区间/哈希桶，逐桶读取并在内存内去重（或外排序），最后合并结果。
  3. **位图**：如果数据范围固定且不算太大，且内存够放位图，就能快速去重；若内存不够，可结合分桶或外存策略。
  4. **布隆过滤器**：适用于需要快速判断是否出现过、且容忍少量误判的场景。

面试或者做实际项目时，常见的答案基本都会围绕着这几类思路来展开，展示出对**海量数据**、**内存瓶颈**以及**外部存储算法**的综合理解。
