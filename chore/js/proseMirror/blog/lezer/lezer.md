好的，我们来对 Marijn Haverbeke 这篇关于 Lezer 解析器的博文进行一次系统且深入的分析讲解。这篇文章不仅介绍了 Lezer 的设计，更是一部浓缩的、关于“如何在代码编辑器中做解析”的斗争史和思想演进史。

我们将从以下几个角度来剖析这篇文章：

1.  **问题的核心**: 为什么在编辑器里做解析这么难？
2.  **CodeMirror 的早期探索与失败**: 从状态机到 PEG，为什么它们最终都“走远了”？
3.  **顿悟时刻：Tree-sitter**: 它带来了什么革命性的思想？
4.  **Lezer 的诞生与核心技术**: 作为 Tree-sitter 的“精神续作”，Lezer 如何用 JavaScript 实现并超越它？
    - LR/GLR 解析与错误恢复
    - 后序输出与 Buffer Tree
    - 上下文相关的词法分析
5.  **Lezer 的架构设计哲学**: 它是如何做到通用、高效且可扩展的？

---

### 1. 问题的核心：为什么在编辑器里做解析这么难？

文章开篇就点明了在代码编辑器这个特殊场景下，解析面临的四大核心约束：

1.  **文档持续变化 (Constantly changing)**: 用户一直在输入，解析器必须能快速响应局部变更，而不是每次都从头解析整个文档。这要求解析必须是**增量的 (incremental)**。
2.  **性能要求苛刻 (Can't do anything expensive)**: 任何超过几十毫秒的延迟都会让用户感觉卡顿。解析必须极快。
3.  **输入不完整/不正确 (Often incorrect)**: 用户写代码的过程中，文档大部分时间都处于有语法错误的状态。但编辑器不能因此就“罢工”，语法高亮、自动补全等功能必须尽可能地继续工作。这要求解析必须是**容错的 (error-tolerant)**。
4.  **语言混合 (Mixed languages)**: 一个文件里可能同时包含 HTML, JavaScript, CSS。解析器必须能处理这种语言嵌套。

这四大约束像四座大山，使得传统的、为编译器设计的“一次性”解析技术难以直接应用。

---

### 2. CodeMirror 的早期探索与失败

Marijn 回顾了 CodeMirror 5 及之前的几次尝试，这是一段宝贵的“试错”历史。

#### 阶段一：简单的状态化分词器 (Stateful Tokenizer)

- **方法**: 为每种语言手写一个分词器，它将文本切成 token，并给每个 token 打上类型标签（如 `keyword`, `string`）。分词器自身可以维护状态，从而模拟一个完整的解析器。
- **增量实现**: 通过在文档各处缓存分词器的“状态快照”，当发生变更时，可以从离变更点最近的一个快照恢复，从而避免重新解析整个文档。
- **问题**:
  - **难以抽象**: 直接手写状态机非常繁琐且容易出错。
  - **失败的抽象尝试**: 无论是早期的“通用 JS 语法高亮规范”，还是借鉴 ACE/TextMate 的思路，都试图用正则表达式和状态机来声明式地定义分词器。但 Marijn 发现，一旦语法变得复杂，这种“抽象”反而比手写代码更丑陋、更难维护。正则表达式的滥用让代码变得“恐怖”。

#### 阶段二：雄心勃勃的 PEG 解析器

- **动机**: 寻找比状态机更好的抽象。**解析表达式语法 (Parsing Expression Grammars, PEG)** 看上去很有吸引力，因为它支持语法组合（适合混合语言）。
- **实现**: 花了几个月构建了一个系统，它将 PEG 编译成一个状态机来运行。
- **致命缺陷 (Tragically bad idea taken way too far)**:
  1.  **回溯 (Backtracking) 与状态的根本矛盾**: PEG 的核心是回溯。这意味着解析器永远无法“确定”它已经解析完了一段内容，因为后续的输入可能让它推翻之前的结论。这与增量解析需要的“可缓存状态”是根本对立的。为了解决这个问题，Marijn 不得不引入大量“向前看”的手动标注，让语法变得非常繁琐。
  2.  **性能极差**: PEG 是“无扫描器 (scannerless)”的，它不区分分词和解析。这意味着每个字符都可能触发多次完整的解析逻辑（因为回溯），效率极低。尽管编译器做了一些优化，但速度远不如手写的分词器。

**结论**: 无论是简单的状态机还是看似高级的 PEG，都无法优雅地同时满足编辑器解析的四大约束。

---

### 3. 顿悟时刻：Tree-sitter

就在 Marijn 陷入困境时，他看到了 Tree-sitter，并称之为“顿悟 (enlightened)”。

- **Tree-sitter 的革命性思想**:

  1.  **目标升级**: 不再满足于生成一个扁平的 token 序列，而是要构建一个**完整、精确的语法树 (full, accurate syntax tree)**。有了树，能做的事情远比 token 多得多，可以`精确地理解代码结构`。
  2.  **技术整合**: Tree-sitter 并没有发明全新的理论，而是将学术界已有的思想（如 GLR 解析、增量解析）巧妙地组合成了一个实用的系统。
  3.  **解决了核心难题**: 它原生支持**增量解析**和**强大的自动错误恢复**。

- **为什么不直接用 Tree-sitter？**
  - 它是用 C 写的，在浏览器中运行不便（尤其是在非 WASM 环境）。
  - 生成的语法文件非常大，不适合 Web 环境的网络传输。

**结论**: 思想可以借鉴，但需要一个为 Web 和 JavaScript 量身定做的实现。这就是 Lezer 的由来。

---

### 4. Lezer 的诞生与核心技术

Lezer 是 Marijn 对 Tree-sitter 思想的 JavaScript 实现，并根据自己的品味和 Web 的优先级做了很多调整。它是一个 **LR (带可选 GLR) 解析器生成器**。

Marijn 在这里正面回应了他之前对“经典解析器”的偏见，并解释了 Lezer 是如何克服这些传统问题的。

#### A. 核心引擎：LR 解析与 GLR 错误恢复

- **为什么选择 LR？**: 尽管 LR 语法有局限性（如操作符优先级、空白敏感），但现代的解析器生成器可以通过**优先级声明**、**动态歧义解决 (GLR)** 等方式来弥补。最重要的是，它能从可读的语法定义中生成**真正快速**的解析器。
- **GLR (Generalized LR) 的妙用**:
  - GLR 允许解析器在遇到歧义时，**分裂 (split)** 出多个并行的解析栈，同时尝试多种可能性，直到后续的输入证明某条路是错的。
  - **Lezer 和 Tree-sitter 的天才之处在于，它们将这个处理歧义的机制“滥用”到了错误恢复上。**
- **错误恢复策略**:
  1.  **看作搜索问题**: 当遇到语法错误时，解析器卡住了。但它可以通过一系列“恢复动作”来尝试到达一个可以继续解析的“好状态”。
  2.  **用 GLR 进行搜索**: 解析器在错误点分裂，尝试各种恢复策略，每个分支都是一种可能的“修复”方案。
      - **跳过当前 token**。
      - **“发明”一个缺失的 token**（这是分支的主要来源）。
      - **强制结束当前的语法规则**。
  3.  **“坏度”评分 (Badness score)**: 每个分支都有一个“坏度”分数。执行恢复动作会增加分数，正常消费 token 会（渐近地）减少分数。
  4.  **剪枝**: Lezer 会`剪掉`那些“坏度”远高于最佳分支的分支，从而控制搜索的成本，避免指数级爆炸。最终，要么一个好分支胜出，要么在持续的错误中只保留一个分支继续前进。

**结论**: 通过`将错误恢复转化为一个带剪枝的 GLR 搜索问题`，Lezer 实现了**全自动、无需语法作者干预**的强大容错能力。

#### B. 性能优化：后序输出与 Buffer Tree

- **后序输出 (Post-Order Output)**:

  - **问题**: 在 GLR 解析中，可能会构建大量重复的、最终被丢弃的树节点，开销很大。
  - **解决方案**: 解析器不立即构建树，而是将创建的节点信息（类型、起止位置等）以**后序（子节点在前，父节点在后）**顺序追加到一个**扁平的数组**中。
  - **优点**:
    - 节点分配变得像向数组追加几个数字一样廉价。
    - 解析器状态分裂时，只需复制一个指向数组的指针和长度，无需复制任何树节点。
    - 只有在整个解析成功结束后，才根据这个扁平数组一次性构建出最终的树结构。

- **Buffer Tree**:

  - **问题**: 纯粹的扁平数组不利于增量解析（无法复用其中的一部分）。而传统的指针连接的树节点，内存开销大且局部性差。
  - **解决方案**: **混合表示法**。
    - 树的**粗粒度结构**（大节点）使用传统的**指针连接**。
    - 树的**细粒度结构**（小节点，如几千字符以内）则存储为**紧凑的扁平数组 (Buffer)**。
  - **优点**: 两全其美。既能通过复用大节点实现增量解析，又能通过对大量的小节点使用扁平数组来节省内存、提高缓存局部性。

  分块!!!

#### C. 灵活性：上下文相关的词法分析 (Contextual Tokens)

- **问题**: 很多语言存在词法歧义，例如 JS 的 `/` (除号 vs. 正则表达式) 或 C++ 的 `>>` (右移 vs. 两个模板括号)。
- **解决方案**:
  1.  **状态驱动的分词**: `解析器不再和分词器完全分离`。解析器在进入一个新状态时，会告诉分词器**当前状态下只允许哪些 token**。
  2.  **Token 组**: Lezer 会自动分析哪些 token 互相冲突，并将它们分组。每个解析状态只关联一个无冲突的 token 组。
  3.  **高效实现**: 分词器在运行时，会检查当前生成的 token 是否属于允许的组，从而自动解决歧义，并避免在不必要的路径上浪费时间。

---

### 5. Lezer 的架构设计哲学

- **关注点分离**:
  - **离线生成器**: 将复杂的语法分析和优化工作放到构建时，生成紧凑的解析表。
  - **运行时**: 轻量级，只负责执行解析表。
- **为 Web 优化**: 极度关注**紧凑性**，无论是解析表的大小还是生成的语法树的大小，都力求最小化，以减少网络传输和内存占用。
- **抽象与通用**:
  - **节点标签 (Tagging)**: Lezer 不试图定义一个跨语言的通用节点类型词汇表（这太难了）。相反，它允许外部代码通过“标签 (Tag)”给节点类型附加任意的“属性 (props)”，如高亮样式、缩进规则等。这使得语法本身与编辑器的具体功能解耦。
  - **可扩展的解析器**: 允许在运行时给解析器实例附加新的 props，这对于处理混合语言树非常有用。

### 总结

Lezer 是 Marijn Haverbeke 在经历了多年探索和失败后，吸收了 Tree-sitter 的核心思想，并结合 Web 环境的特点，精心打造出的一套现代编辑器解析方案。它通过**LR/GLR 引擎**、**基于搜索的错误恢复**、**混合式的树表示法**以及**上下文相关的词法分析**等一系列精妙的设计，成功地在**性能、容错性、增量能力和文件大小**这几个相互冲突的目标之间取得了卓越的平衡。这篇博文不仅是 Lezer 的技术宣言，更是所有希望深入理解编辑器内部工作原理的开发者的必读经典。
