# 类别特征处理

这份 PDF 是 Shusen Wang 教授 Deep Learning 课程系列中的第 9 部分第一节，主题为 **“Data Processing Basics” (数据处理基础)**。

它并未直接开始讲解 RNN（循环神经网络），而是作为前置课程，详细讲解了在将数据输入到神经网络（特别是 RNN 处理文本）之前，必须进行的**特征预处理**步骤。主要涵盖了**分类特征（Categorical Features）**的处理和**文本数据（Text Data）**的处理。

以下是对该课件的深入分析与解构：

### 1. 核心主题：数据预处理 (Data Processing Basics)

课程目标是将非数值型数据（如类别标签、文本字符串）转换为神经网络可以理解的数值向量形式。

### 2. 第一部分：处理分类特征 (Processing Categorical Features)

这部分重点讨论了如何处理像“国籍”、“性别”这样的离散数据。

- **特征区分**：

  - **数值特征 (Numeric Features)**：具有数学上的有序性。例如**年龄**（35 岁 > 31 岁），这类数据通常保持原样或归一化即可。
  - **分类特征 (Categorical Features)**：没有固有的顺序。例如**国籍**（美国、中国、印度）。你不能说“美国 > 中国”，也不能说“美国 + 中国 = 印度”。

- **处理流程**：

  1.  **建立字典 (Build Dictionary)**：将每个类别映射到一个唯一的整数索引。
      - _惯例_：索引通常从 **1** 开始计数，而非 0。（例如：US → 1, China → 2）。
  2.  **One-Hot 编码 (One-Hot Encoding)**：将索引转换为向量。
      - 如果你有 $N$ 个类别，就创建一个 $N$ 维向量。
      - 索引为 $k$ 的类别，其向量的第 $k$ 位为 1，其余位为 0。
      - 例如：US (Index 1) → `[1, 0, 0, ...]`；China (Index 2) → `[0, 1, 0, ...]`.

- **关键问题解答**：
  - **Q: 为什么要保留 0 索引？**
    - A: **0 索引 (Index 0)** 通常被保留用于表示**未知 (Unknown)** 或 **缺失 (Missing)** 的数据。其对应的 One-Hot 向量通常是全 0 向量 `[0, 0, 0, ...]`。
  - **Q: 为什么不用标量（如 1, 2, 3）直接表示类别？**
    - A: 标量会引入错误的数学关系。如果 US=1, China=2, India=3，神经网络可能会错误地推断出 `US + China = India` (1+2=3) 或 `China` 是 `US` 的两倍。One-Hot 向量之间是**正交**的，避免了这种误导。

### 3. 第二部分：处理文本数据 (Processing Text Data)

这部分是为学习 RNN 做铺垫，讲解了 NLP 中标准的预处理流水线。

- **Step 1: 分词 (Tokenization)**

  - 将长文本字符串（String）切割成单词列表（List of words）。
  - 例：`"... to be or not to be ..."` → `[..., 'to', 'be', 'or', 'not', 'to', 'be', ...]`

- **Step 2: 建立词表 (Count Word Frequencies & Build Vocabulary)**

  - **统计词频**：使用哈希表统计每个词出现的次数。
  - **排序**：按频率从高到低排序（如 `not` 出现 499 次排第 1，`to` 出现 399 次排第 2）。
  - **分配索引**：频率最高的词索引为 1，次之为 2，依此类推。
  - **截断词表 (Truncation)**：
    - 如果词汇量太大（如 > 10K），通常只保留前 $K$ 个高频词。
    - **原因 1**：低频词通常意义不大（如人名实体、拼写错误）。
    - **原因 2**：词表过大会导致 One-Hot 向量维度过高，增加计算量和 Embedding 层的参数量。

- **Step 3: 序列编码 (Sequence Encoding)**
  - 将单词列表转换为整数索引列表。
  - 例：`['to', 'be', 'or', 'not']` → `[2, 4, 8, 1]`。
  - **处理未登录词 (OOV - Out of Vocabulary)**：如果在字典中找不到某个词（如拼写错误的 `hemlat`，或者被截断的低频词），通常直接**忽略**或编码为 **0**。

### 4. 总结与启示

这份 PPT 虽然简单，但定义了神经网络模型输入的**数据标准**：

1.  神经网络不直接处理字符串，**只处理数字（向量）**。
2.  **One-Hot** 是离散数据到向量的最基础桥梁。
3.  **索引 0** 在深度学习预处理中具有特殊地位（Padding 或 Unknown）。
4.  文本处理的核心在于**词表 (Vocabulary) 的构建**，这是后续理解 Embedding 层（词嵌入）的基础。
