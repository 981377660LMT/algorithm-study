# 小样本学习：基本概念

https://www.bilibili.com/video/BV1V44y1r7cx
Few-Shot Learning

这节课是王树森老师讲解 **Few-shot Learning（小样本学习）** 的第一课，主要介绍了基本概念、问题定义以及与传统监督学习的区别。

以下是深入、有逻辑的讲解分析：

---

### 第一部分：直觉认知 —— 人类如何做小样本学习？

王老师并没有一上来就堆砌数学公式，而是用一道针对观众的“智商测试题”引出了 Few-shot Learning 的核心逻辑。

1.  **“穿山甲 vs. 犰狳”测试**：
    - **任务**：给观众看两张陌生的“穿山甲”图片和两张陌生的“犰狳”图片（这就构成了 **Support Set**）。
    - **提问**：再给一张新的图片（**Query**），问你是哪一类？
    - **结果**：几乎所有正常人都能做对。哪怕你在这一分钟之前根本不知道什么是穿山甲、什么是犰狳。
2.  **核心启示**：
    - 人类不需要看几万张穿山甲的照片才能认出穿山甲。
    - 人类通过极少的样本（每类仅一两张）就能快速学习并识别新事物。
    - 计算机能不能做到这一点？这就是 Few-shot Learning 要解决的问题。

---

### 第二部分：核心概念 —— Support Set vs. Query

这是本节课最重要的术语定义，必须牢记，否则看相关论文会一头雾水。

1.  **Support Set（支持集）**：
    - 这是一个**极小**的数据集，用于在测试时提供参考信息。
    - 例如：2 类，每类 2 张图。共 4 张图。
    - **关键点**：这不足以训练深度神经网络（哪怕是微调都很难）。它不是用来“训练”参数的，而是用来“对照”的。
2.  **Query（查询样本）**：
    - 你需要分类的目标图片。
    - 任务是判断 Query 属于 Support Set 中的哪一类。
3.  **K-way N-shot**：
    ![alt text](image.png)
    - 这是衡量任务难度的标准术语。
    - **K-way**：Support Set 里有 K 个类别（例如 6 选 1，就是 6-way）。K 越大，也就是选项越多，准确率通常越低。
    - **N-shot**：Support Set 里每个类别有 N 个样本（例如每类只给 1 张参考图，就是 1-shot）。N 越大，参考信息越多，准确率通常越高。

---

### 第三部分：本质区别 —— Learn to Learn (元学习)

王老师用了非常通俗的例子来解释 **Meta Learning (元学习)** 与传统 **Supervised Learning (监督学习)** 的区别。

#### 1. 传统监督学习 (Supervised Learning)

- **目标**：识别训练集里见过的东西。
- **场景**：训练集有“哈士奇”，测试时给一张没见过的“哈士奇”，模型能认出来。
- **局限**：如果测试时给一张“兔子”（训练集里没有），模型彻底懵逼。

#### 2. 元学习 / 小样本学习 (Meta Learning / Few-shot Learning)

- **目标**：**学会学习（Learn to Learn）**，或者说**学会区分事物的异同**。
- **场景**：
  - 训练集有“大象”、“老虎”（没有“兔子”）。
  - 训练目标不是记住大象长啥样，而是学会**如何对比两张图是否属于同一种类**。
  - 测试时，给几张“兔子”的参考图（Support Set）和一张“兔子”的 Query。虽然模型没见过兔子，但它知道 Query 长得和 Support Set 里的兔子很像，和松鼠不像。
- **类比**：
  - **去动物园的小朋友**：小朋友没见过水獭，但他有“区分能力”。给他一套带名字的卡片（Support Set），他即使第一次见水獭，也能通过对比卡片，认出这是水獭。
  - **Meta Learning** 就是培养这种“区分异同”的能力，而不是死记硬背某种动物。

---

### 第四部分：解决思路 —— 相似度函数 (Similarity Function)

基于上述逻辑，解决 Few-shot Learning 的基本数学框架就出来了：

1.  **训练一个相似度函数 `sim(x1, x2)`**：

    - 输入：两张图片。
    - 输出：相似度分数（例如 0 到 1）。
    - 目标：如果是同类，输出趋近 1；如果是异类，输出趋近 0。
    - _注：这就是下节课要讲的 Siamese Network 的雏形。_

2.  **预测流程 (Inference)**：
    - 拿到一个 Query 图片。
    - 将 Query 与 Support Set 中的每一张图片 $x_i$ 进行对比，计算 `sim(Query, x_i)`。
    - 那个分数最高，Query 就属于那一类。

---

### 第五部分：常用数据集 (Datasets)

做研究需要标准的数据集刷榜，王老师介绍了两个最经典的：

1.  **Omniglot**：

    - **可以看作 Few-shot Learning 界的 MNIST**。
    - **内容**：50 种语言的手写字母（希腊语、梵语等），共 1623 个字符类别。
    - **特点**：**类很多**（1623 类），**样本很少**（每类仅 20 个）。非常适合做 One-shot / Few-shot 实验。

2.  **Mini-ImageNet**：
    - 从巨型 ImageNet 中抽样出来的子集。
    - **内容**：100 个类别，每类 600 张图。
    - **难度**：比 Omniglot 难得多，因为也就是真实照片，背景复杂。

---

### 总结

1.  **定义**：Few-shot Learning 是在只有极少量参考样本（Support Set）的情况下，对新样本（Query）进行分类。
2.  **核心差异**：它不要求模型在训练时见过测试类别，而是要求模型学会**“对比”**或**“快速适应”**。即“授人以鱼（传统分类）不如授人以渔（元学习）”。
3.  **方法论**：最直观的方法是训练一个**相似度函数**，在测试时进行比对分类。
4.  **术语**：记住 **Support Set, Query, K-way, N-shot**，這是看懂后续课程的基础。
