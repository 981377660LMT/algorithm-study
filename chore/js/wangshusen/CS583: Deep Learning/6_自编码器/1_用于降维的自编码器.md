# 用于降维的自编码器

这份 PDF 文件是关于 **自动编码器 (Autoencoder, AE)** 的深度学习课件（第 8 讲，第 1 部分），主要使用了 **Keras** 框架和 **MNIST** 手写数字数据集进行演示。

以下是对该课件内容的深入分析与解构：

### 1. 核心主题：自动编码器 (Autoencoder)

课件通过三种递进的形式介绍了自动编码器的应用：

1.  **全连接自动编码器 (Fully Connected Autoencoder)**
2.  **卷积自动编码器 (Convolutional Autoencoder)**
3.  **去噪自动编码器 (Denoising Autoencoder)**

---

### 2. 第一部分：全连接自动编码器 (Full-Connected AE)

#### **2.1 模型架构**

- **输入层**：784 维向量 (MNIST 图片 $28 \times 28$ 展平)。
- **编码器 (Encoder)**：
  - Dense (100 units, ReLU)
  - Dense (20 units, ReLU) -> **瓶颈层 (Bottleneck)**，即压缩后的特征表示。
- **解码器 (Decoder)**：
  - Dense (100 units, ReLU)
  - Dense (784 units, ReLU) -> 输出层，重构图像。
- **总参数量**：161,804。

#### **2.2 训练细节**

- **优化器**：RMSprop。
- **损失函数**：均方误差 (Mean Squared Error, MSE)。
- **数据处理**：归一化到 [0, 1] 区间，并将 $28 \times 28$ 的图像 reshape 为 784 维向量。
- **Self-Supervised**：训练时的输入是 `x_train_vec`，目标（Target）也是 `x_train_vec`。

#### **2.3 降维与可视化 (Dimensionality Reduction)**

- 直接用 AE 将 784 维降到 2 维的效果通常不如 **t-SNE**。
- **最佳实践**：结合 AE 和 t-SNE。
  - 先由 AE 将 784 维降到 20 维（提取特征）。
  - 再用 t-SNE 将 20 维降到 2 维进行可视化。
- **对比**：
  - 仅用 AE 直接降到 2D：可视化效果差。
  - 直接对原始 784 维数据用 t-SNE：速度太慢。
  - **AE + t-SNE**：速度快且效果好，呈现出清晰的数字聚类（不同数字用不同颜色标记）。

---

### 3. 第二部分：卷积自动编码器 (Convolutional Autoencoder)

#### **3.1 动机**

- 全连接层破坏了图像的空间结构。对于图像数据，卷积神经网络 (CNN) 效果通常更好。

#### **3.2 关键操作对比**

- **编码器 (下采样)**：使用 **Max Pooling (最大池化)** 减小尺寸。
- **解码器 (上采样)**：使用 **Upsampling** 恢复尺寸。
  - _Upsampling 示例_：将 $2 \times 2$ 的矩阵通过复制元素扩展为 $4 \times 4$。

#### **3.3 模型架构**

- 输入：$28 \times 28 \times 1$
- **Encoder**:
  - Conv2D (8, 3x3) -> MaxPool (2x2) -> $14 \times 14 \times 8$
  - Conv2D (4, 3x3) -> MaxPool (2x2) -> $7 \times 7 \times 4$
  - Conv2D (4, 3x3) -> MaxPool (2x2) -> $4 \times 4 \times 4$ (Code Vector, 64 维)
- **Decoder**:
  - Conv2D -> UpSampling (2x2) -> $8 \times 8$
  - Conv2D -> UpSampling (2x2) -> $16 \times 16$
  - Conv2D -> UpSampling (2x2) -> $28 \times 28$
- **输出**：$28 \times 28 \times 1$
- **参数量**：非常轻量级，总计 1,185 个参数。

---

### 4. 第三部分：去噪自动编码器 (Denoising Autoencoder)

#### **4.1 原理**

- 不仅通过压缩重构学习特征，还强迫网络去除输入中的噪声，从而学习更鲁棒的特征表示。

#### **4.2 实现方法**

- **输入 (Inputs)**：原始图像 + 高斯噪声 (Gaussian Noise)。
  - 代码：`x_train_noisy = x_train + noise_factor * np.random.normal(...)`
  - 使用 `np.clip` 保证像素值在 [0, 1] 之间。
- **目标 (Targets)**：**原始的纯净图像 (Original Images)**。
- **效果**：模型学会了从模糊/噪点图像中恢复出清晰的数字。

---

### 5. 总结与解构 (Summary)

- **本质**：Autoencoder 是 **PCA (主成分分析)** 的非线性推广。
- **结构**：由 Encoder (压缩/编码) 和 Decoder (解压/重构) 组成。
- **应用场景**：
  1.  **降维 (Dimensionality Reduction)**：利用中间的 Code vector。
  2.  **去噪 (Denoising)**：修复损坏的数据。
  3.  **特征学习**：为监督学习任务预训练特征提取器。

这份课件是一个非常标准的深度学习入门教程，通过代码实例直观地展示了如何从最基础的 Dense AE 进化到 Conv AE，再到具有实际增强能力的 Denoising AE。
