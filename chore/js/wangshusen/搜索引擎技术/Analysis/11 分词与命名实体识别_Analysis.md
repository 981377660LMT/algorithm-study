# 11 分词与命名实体识别：把“文本”变成可检索、可建模的结构

这一章解决的是 QP（Query Processing）里两个基础但决定上限的能力：

- **分词**：把中文字符串切成“检索单位”（词粒度）
- **NER（命名实体识别）**：把文本里的品牌/品类/人物/地点等实体抽出来

它们看起来是“前置小模块”，但会直接影响：

- 文本召回（倒排命中什么词）
- 相关性/CTR 模型特征（实体、词序列）
- 改写、意图理解、类目识别（很多任务都建立在“词/实体”的表示上）

---

## 11.0 为什么中文搜索必须关心分词

搜索的文本召回以词粒度进行。query 是否能被正确切分，直接决定倒排召回是否命中。

- q = “冬季卫衣推荐”
- 若分词为 {冬季, 卫衣, 推荐}，倒排能稳定命中
- 若切错（尤其长尾词、专有名词、紧密短语），可能直接变成少结果/零结果

---

## 11.1 基于词典的分词：便宜，但上限低

这一类方法的共同点：

- 依赖一个预先准备好的词典
- 线上非常省算力
- 但**无法识别未登录词**，泛化差

### 11.1.1 最大匹配（正向/反向/双向）

最大匹配是贪心：

- 正向：从左到右，每次取最长词
- 反向：从右到左，每次取最长词

双向最大匹配会同时跑两次，然后按“词数更少/单字更少/偏反向”等规则做选择。

工程要点：

- 通常用 Trie 存词典，实现能做到 $O(n)$
- 但效果在真实业务里往往不够好（工业界实践中很少用它作为最终分词）

### 11.1.2 最短路径分词：把切词变成图最短路

把句子看成 $n+1$ 个节点：

- 单字边总是存在
- 若 $[i,j)$ 之间的字串在词典里，则加一条边 $i\to j$
- 边权都设为 1

然后找从 0 到 $n$ 的最短路径作为分词结果。

直觉：

- 更少的边 = 更倾向于更长的词

但它并不保证正确（“研究/生命/起源” vs “研究生/命/起源”是典型歧义）。

---

## 11.2 词典构造：新词发现的核心是“凝聚度 + 自由度”

工业界一般不手工维护全量词典，而是从海量语料自动挖掘，并定期更新：

- 否则未登录词会越来越多（专名、缩写、流行词）

这一节反直觉的一点：

- **“高频”不等于“成词”**（“电影的”“和国”这类都会被频率误导）

### 11.2.1 凝聚度：词内部是否“抱团”

如果字符串 $AB$ 不是一个词，它只是 A、B 偶然相邻，则：

$$
 p(AB) \approx p(A)\cdot p(B)
$$

因此用 PMI 衡量凝聚：

$$
\text{PMI}(A,B)=\log \frac{p(AB)}{p(A)\,p(B)}
$$

- PMI 越大，越像成词

对长度更长的字符串（abc、abcd），做所有切分方式的 PMI，取最小值作为凝聚度：

- “任何一刀切开都得强相关”，才认为整体像词

工程注意：

- 字符串越长 PMI 往往越高，需要**按长度设阈值**

### 11.2.2 自由度：是不是某个大词的“子串”

“和国”在“共和国”里频率高，但它并不是独立词。

观察规律：

- 真词通常左右搭配丰富（左邻/右邻很多）
- 子串的搭配往往很固定（例如左边几乎总是某个字）

因此用左右邻接字符分布的信息熵衡量自由度（不确定性）：

$$
H_{left}(A)=-\sum_l p(l\mid A)\log p(l\mid A)
$$

类似定义 $H_{right}(A)$，再取：

$$
H(A)=\min(H_{left}(A),H_{right}(A))
$$

- $H(A)$ 越大，越不像“固定搭配子串”

最终判定成词通常需要：

- 凝聚度 > 阈值
- 自由度 > 阈值

---

## 11.3 深度学习分词：BERT 序列标注（可选 CRF）

查询词短、分词准确性要求高，因此工业界常用 BERT 做分词。

### 11.3.1 B/M/E/S 四标签序列标注

把分词建模为每个字的标签预测：

- B（词首）、M（词中）、E（词尾）、S（单字词）

BERT 输出每个位置的 4 维 logits / 概率向量，训练时用交叉熵。

### 11.3.2 为什么要 CRF：约束标签转移合法

独立做 argmax 会出现不合法标签序列（例如 B 后面接 S）。

CRF 用转移矩阵 $T$ 建模相邻标签关系：

- 合法转移分数高（例如 B→M、B→E）
- 不合法转移分数低（例如 B→B、B→S）

推理时求解：

$$
\hat{y}=\arg\max_{y} \text{score}(y,L,T)
$$

常用 Viterbi 算法在 $4n$ 节点图上找最优路径。

一个实践经验（本章也提到）：

- 随着预训练越来越强，CRF 的边际收益变小；只用 BERT 也常能接近同等效果

---

## 11.4 NER：实体是搜索“强语义特征”

命名实体识别要抽取：

- 品牌、品类、人物、地点等（实际业务可达数十种实体）

NER 与分词同样是序列标注，但标签更丰富：

- 常见用 B/I/O（实体开始/实体内部/非实体）
- 若有 $k$ 种实体，则标签数约为 $2k+1$

典型例子：

- “杨幂代言的雅诗兰黛口红”
  - 杨幂：人物
  - 雅诗兰黛：品牌
  - 口红：品类

工程价值：

- 实体能显著提升相关性/CTR 模型
- 也能提升召回（实体倒排、实体约束）与改写（别名、上位下位）

本章给出的主流方案：

- BERT+CRF（或 BERT 直接序列标注）
- 需要人工标注数据做微调

### 11.4.1 LEBERT：把“词信息”注入字粒度序列标注

LEBERT 的直觉：

- 中文序列标注只用字粒度，会丢掉“词覆盖”信息

做法：

- 对每个字 $i$，找覆盖它的多个词向量 $v_{i,1}\dots v_{i,m}$
- 用交叉注意力：以字向量 $h_i$ 为 Q，以词向量为 K/V，得到增强表示 $\tilde{h}_i$
- 用 $\tilde{h}_i$ 作为 BERT 的输入表征

它本质是：

- 在“字模型”里加入“词先验”，提升中文任务效果

---

## 11.5 评价指标：Precision / Recall / F1（按词或按实体 span）

分词与 NER 的离线指标类似：

- 准确率（Precision）
- 召回率（Recall）
- F1

关键是定义 TP/FP/FN 的对象：

- 分词：按“切出的词是否与标注词边界一致”计数
- NER：常按实体 span 是否完全匹配计数

---

## 11.6 工程落地：你应该如何在系统里放置它们

- 分词通常在 QP 早期：影响倒排召回、词权重、改写等
- NER 是“强语义特征生成器”：既可用于召回约束，也可用于排序特征

建议的检查清单：

- 未登录词率（OOV）是否在上涨？是否需要更新词典/模型？
- 线上最影响体验的切词错误有哪些模式（专名、紧密短语、外文夹杂）？
- NER 是否覆盖业务核心实体（品牌/品类/地点）？是否需要实体库辅助？

---

## 11.7 练习（建议动手）

1. 用一周搜索日志做新词发现：实现 PMI + 左右熵，挖掘 top100 新词并人工验收。
2. 手工构造 50 条“紧密短语”query（如“巴黎贝甜”“权力的游戏”），对比词典分词 vs BERT 分词的差异。
3. 设计 NER 标签体系：选一个垂类（电商/本地生活/影视），列出 10 种最有用实体，并解释它们如何进入召回/排序。

---

## 11.8 与其它章节的连接

- 与第 12 章：分词结果直接作为词权重输入
- 与第 13 章：类目识别常直接用 query/doc 文本与实体特征
- 与第 15 章：改写依赖分词、同义词/上下位词与实体别名
