# 17 向量召回：用双塔跨越语义鸿沟，关键在“数据/负样本/ANN/更新机制”

本章把向量召回讲得非常工程化：

- 它的作用类似“查询词改写”：解决**语义鸿沟**，召回“文本不匹配但语义匹配”的文档
- 它通常是搜索引擎里**第二重要**的召回通道（仅次于文本召回）
- 对算法工程师来说，它的优化空间非常大：数据、负样本、蒸馏、ANN 参数、在线更新都会显著影响大盘

本章把向量召回分为两类：

- **相关性向量召回**：拟合 $(q,d)$ 的相关性
- **个性化向量召回**：拟合用户点击行为（更像推荐系统召回，但多了 query 语境）

---

## 17.1 相关性向量召回：蒸馏大模型，左塔在线、右塔离线

### 17.1.1 结构：双塔（bi-encoder）而非交叉塔（cross-encoder）

相关性向量召回用双塔：

- 左塔编码查询词 $q \to x$
- 右塔编码文档 $d \to z$
- 用相似度（常见是内积）$x^\top z$ 作为相关性打分

为什么召回必须用双塔？因为召回候选是“数亿文档”，不可能在线枚举所有 $(q,d)$。

### 17.1.2 数据：召回模型必须“混很多低相关样本”

本章强调了一个容易被忽视的点：

- 召回的目的不是把“相关档位排得很准”，而是**把无关与可能相关分开**
- 所以召回训练需要大量低相关/不相关样本，否则模型会变“软”，召回不够锋利

负样本两类：

- **简单负样本**：随机配对 $(q,d)$（太简单会导致模型弱）
- **困难负样本**：从 $q$ 删除核心词得到 $q'$，用 $(q',d)$ 当负样本（更贴近线上误召回形态）

另外还有一个工程要求：头/中/尾 query 比例要合理，否则模型只会在头部好用。

### 17.1.3 目标：知识蒸馏（distillation）

用一个更强的相关性模型（例如交叉 BERT 大模型）给 $(q,d)$ 打分得到 $y$，再让双塔拟合：

- 用 $\sigma(x^\top z)$ 拟合 $y$

直觉：

- 召回模型不是“从零学语义”，而是把大模型的判别能力压缩到一个可 ANN 检索的向量空间。

### 17.1.4 更新：文档向量不需要每日全量重算（相对省）

本章明确：相关性召回只看文本，不用文档/用户 ID embedding，也不依赖点击流，因此：

- 文档 $z$ 只需在“发布/修改”时计算并入库
- 模型参数不必每日更新

这对工程成本非常关键：相关性向量召回能相对“稳态运行”。

---

## 17.2 个性化向量召回：目标是点击行为，更新是最大成本

个性化向量召回仍然是双塔，但左塔输入更复杂：

- 左塔：$(u,q) \to x$
- 右塔：$d \to z$
- 相似度 $sim(u,q,d)$ 预测点击（以及可扩展到交互）

### 17.2.1 样本：正样本来自曝光日志，负样本要混“简单 + 困难”

- **正样本**：曝光且点击的 $(u,q,d)$
- **简单负样本**：同一个 $(u,q)$ 配随机 $d$；或 batch 内负样本
- **困难负样本**：被召回但没过海选/粗排的文档（更接近线上“差一点就上去”的干扰项）

这套设计隐含了一个目标：

- 让模型学会区分“用户真正会点的少数文档”和“看起来相关但不够吸引/不够匹配”的文档。

### 17.2.2 两种训练：pairwise 与 batch 内负采样

**(1) pairwise（RankNet 风格的二元对比）**

给定 $(u,q)$：

- 正样本 $d^+$
- 负样本 $d^-$

目标是让：

- $sim(u,q,d^+) - sim(u,q,d^-)$ 尽量大

常用 logistic 损失：

$$
\ln\big(1+\exp(-\gamma\,(sim(u,q,d^+) - sim(u,q,d^-)))\big)
$$

其中 $\gamma>0$ 控制函数形状。

**(2) batch 内负采样（in-batch negatives）**

一个 batch 有 $b$ 条正样本 $\{(u_i,q_i,d_i)\}_{i=1}^b$。

- 对于固定 $(u_i,q_i)$，把 $\{d_1,\dots,d_b\}$ 都当候选：其中 $d_i$ 是正样本，其余是负样本
- 对 $b$ 个相似度做 softmax，交叉熵鼓励正样本概率接近 1

#### 热门文档偏差与消偏

batch 内负采样会让热门文档更频繁成为负样本，带来偏差。本章给出谷歌的消偏思路：

- 在训练时把 $sim(u_i,q_i,d_j)$ 替换为 $sim(u_i,q_i,d_j) - \ln p_j$

其中 $p_j$ 与文档总体点击量相关；线上推理不需要 $p_j$。

### 17.2.3 更新：至少天级别重训 + 向量库重建索引

个性化向量召回依赖用户/文档 ID embedding 与最新点击行为，因此：

- **需要每日更新模型参数**（增量训练 1 epoch）
- **需要重算全量文档向量并重建 ANN 索引**（工程成本大、耗时小时级）

本章还提到 online learning 更先进但投入产出比未必划算（搜索里相关性优先于个性化）。

---

## 17.3 线上推理：召回靠 ANN 避免枚举，海选可直接枚举

本章把“召回 vs 海选”的推理方式区分得很清楚：

- **海选**：候选只有数万，可以逐一打分（O(n) 还能接受）
  - 文档向量可存在哈希表，线上取回向量即可

- **召回**：候选是数亿，必须避免枚举
  - 需要向量数据库（如 Faiss）建立 ANN 索引

### 17.3.1 以 IVF_FLAT 为例：把全库向量分桶再局部精排

流程（直观版）：

1. 对全量文档向量 $\{z_d\}$ 聚类得到 $m$ 个中心 $\{c_1,\dots,c_m\}$
2. 记录每个 $z_d$ 属于哪个中心（建立“中心→向量列表”索引）
3. 查询时：先算 $x_q$ 与各中心的相似度，挑 top 的中心
4. 只在这些中心对应的向量集合里算精确相似度，取 topK 文档

复杂度直觉：

- 通过“先粗后细”，把 O(n) 变成远小于 n 的开销
- 本章用 $m=\sqrt{n}$ 举例，平均每簇 $O(\sqrt{n})$，总体可到 $O(\sqrt{n})$

工程上你要调的就是：

- 聚类中心数、probe 的簇数、topK 等参数
- 召回质量 vs RT 的折中曲线

---

## 17.4 常见坑与检查清单

- 负样本太简单：模型只学到“词重叠”，对语义鸿沟没用
- 训练只用头部 query：长尾召回崩溃，线上看起来像“只对热门好用”
- 个性化模型更新/索引重建链路不稳：召回波动会直接影响大盘稳定性
- ANN 参数只看离线 Recall@K：线上要同时看 RT、尾延迟与业务指标

---

## 17.5 练习（建议动手）

1. 为同一批 query 构造三种负样本（随机/删核心词/线上误召回），比较训练后召回质量差异。
2. 用 Faiss 的 IVF 思路做一个玩具实验：改变中心数与 probe 数，看 Recall@K 与耗时如何变化。
3. 比较“相关性召回模型不日更”与“个性化召回模型日更”的工程成本，写出你能接受的刷新 SLA。

---

## 17.6 与其它章节的连接

- 与第 15 章：向量召回与改写同为“补语义匹配”，但向量召回更偏文档侧泛化
- 与第 19 章：召回阶段的向量相似度也可用于“召回截断”的轻量打分
- 与第 20 章：pairwise/listwise 的思想在排序融合与召回训练中高度复用
