# 搜索引擎技术深度分析（三）：相关性与多路召回架构

本阶段分析涵盖了第 6、16、17、18 章节，核心探讨了搜索引擎如何从数亿级别的规模中，通过“相关性”这一基石，利用多种召回手段（文本、向量、离线、反向）高效、准确地过滤出候选集。

---

## 1. 相关性（Relevance）：搜索的灵魂

相关性不仅是排序的特征，更是衡量搜索质量最核心的标尺。

### 1.1 定义与分档

- **核心逻辑**：相关性指文档 $d$ 是否能满足查询词 $q$ 的意图或回答其问题，而非单纯的字面匹配。
- **标注标准（四档位）**：
  - **高（High）**：主要需求完全匹配，且篇幅占比超过 50%。
  - **中（Medium）**：相关但非主要需求，或篇幅占比不足 50%。
  - **低（Low）**：不相关但有参考价值（丢失非核心限定词）。
  - **无（None）**：完全不相关，且无参考价值。
- **评估指标**：
  - **Pointwise**：AUC（衡量二分类准确性）。
  - **Pairwise**：正逆序比（衡量有序对排列的一致性）。

### 1.2 相关性模型的进化

1.  **统计模型**：TF-IDF、BM25（词袋模型，忽略语序和语义）。
2.  **词距模型**：OkaTP、BM25TP（解决例如“亚马逊网购...雨林”的不相关命中问题）。
3.  **深度学习模型（BERT 系列）**：
    - **交叉 BERT（Cross-Encoder）**：用于精排/粗排，通过 Self-Attention 让 $q$ 和 $d$ 进行底层交叉，精度最高但 QPS 极低。
    - **双塔 BERT（Bi-Encoder）**：用于召回/海选，$q$ 和 $d$ 独立表征，支持离线计算 $d$ 的向量。
4.  **工业界最佳实践（四步走）**：
    - `预训练` (Pre-train) -> `后预训练` (Post-pre-train, 挖掘日志获取 10 亿+伪标签样本) -> `微调` (Fine-tune, 人工标注样本) -> `蒸馏` (Distillation, 大扩小)。

---

## 2. 文本召回：工业界的基石

虽技术成熟，但仍是 QPS 承载能力最强的通道。

### 2.1 倒排索引（Inverted Index）

- **结构**：`Term -> Posting List {DocID, TF, Positions}`。
- **索引划分原则**：
  - **按文档划分（Document-partitioned）**：工业界首选。好处是各节点负载均衡，节点挂掉只会丢失部分召回而非全站不可用，节点间通信少。
- **松弛召回（Relaxation）**：当 $q$ 过长导致无结果时，基于 QP 产出的 Term Weight 丢弃非核心词（如丢弃 25% 甚至更多）。

---

## 3. 向量召回：语义匹配的跃迁

解决“语义鸿沟”问题的核心手段（例如搜“ASML”召回“芯片光刻机”）。

### 3.1 相关性向量召回 vs. 个性化向量召回

| 维度         | 相关性语义召回     | 个性化语义召回                    |
| :----------- | :----------------- | :-------------------------------- |
| **拟合目标** | 相关性档位分数     | 用户点击行为                      |
| **输入特征** | $q$ & $d$ 文本文本 | $q, d$ 文本 + 用户画像 + 行为序列 |
| **更新频率** | 低产（随模型迭代） | 高频（天级/实时 Online Learning） |

### 3.2 向量检索（ANN）的核心

- **挑战**：数亿向量通过暴力枚举计算内积不现实。
- **解决方案**：**IVF-Flat（倒排聚类）**。
  - 步骤：对向量做聚类 -> 搜索时计算 $q$ 与类中心的相似度 -> 只在最接近的类簇中做精搜。
  - 时间复杂度由 $O(N)$ 降至 $O(\sqrt{N})$。

---

## 4. 离线召回：性能与质量的平衡

利用非实时计算资源，提前“预判”用户的需求。

### 4.1 缓存召回（Cache Recall）

- **原理**：挖掘历史曝光日志。对于头部查询词，直接存储精排产生的优质结果。
- **价值**：在流量巅峰时段提高系统稳定性，即便后端组件超时也能保证基础体感。

### 4.2 反向召回（Reverse Recall / Doc2Query）

- **突破点**：传统搜索是“Query 找 Doc”，反向召回是“Doc 找 Query”。
- **Doc2Query 技术**：
  - 使用 Transformer 结构。
  - 输入文档内容，输出可能搜索它的 Query。
  - 将生成的 Query 加入文档索引，极大地丰富了文档的“命中词”，解决了抽取式摘要无法涵盖的问题。

### 4.3 离线搜索链路

- **削峰填谷**：在夜间低流量时段，对头部千万级的 Query 直接运行全量线上搜索链路。
- **指标提升**：由于离线没有 RT（响应时间）限制，可以使用更高维度的精排模型和更广的搜索范围，产出的结果往往优于线上实时召回。

---

## 5. 核心洞察

1.  **召回的多样性决定了上限**：文本召回保底线，向量召回保深度，离线召回保头部。
2.  **相关性是“一票否决权”**：没有相关性，再好的内容质量和个性化也只是噪音。
3.  **负样本构造是向量模型的关键**：简单负样本（随机匹配）+ 困难负样本（被海选过滤但不相关的 $q$ 或被删除核心词的 $q$）的配比调节，其重要性往往大于模型参数调整。

---

_下一阶段将分析：排序阶段（海选、粗排、精排）的高级策略。_
