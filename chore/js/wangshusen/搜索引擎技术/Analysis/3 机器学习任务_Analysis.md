# 3 机器学习任务：把搜索问题“翻译成可训练的形式”

搜索系统里你会不断遇到同一个元问题：

> 我现在手里有日志、特征、标注，我到底应该把它建模成分类、回归还是排序？

本章的价值在于：给你一套统一的“建模语言”，并解释这些任务之间最容易混淆的边界。

- 二分类：预测“会不会发生”
- 多分类：预测“属于哪个类”
- 回归：预测“数值大小”
- 排序：预测“相对顺序”

---

## 3.1 二分类：最常见的工业任务（CTR/是否相关/是否点击）

### 3.1.1 sigmoid 分类器 = 概率输出

模型形式：

$$
\hat{y} = f(x; w,b) = \sigma(x^\top w + b)
$$

其中 sigmoid：

$$
\sigma(z)=\frac{1}{1+e^{-z}}
$$

在搜索里非常常见的例子：CTR 预估。

- 特征 $x$ 来自 $(q,d,u)$（查询词/文档/用户）
- 标签 $y=1$ 表示“用户点击了该文档”
- 输出 $\hat{y}$ 可解释为“点击概率”

### 3.1.2 交叉熵损失：让概率分布更接近

二分类交叉熵（对单样本）：

$$
\ell = -\big(y\ln\hat{y} + (1-y)\ln(1-\hat{y})\big)
$$

它的核心含义是：

- 预测对了且很自信 → 损失很小
- 预测错了且很自信 → 损失很大

工程提醒：

- CTR 预估通常存在严重类不均衡（点击远少于曝光），训练时需要采样/加权，否则模型会倾向于全预测 0。
- “概率”是否可用还取决于校准（calibration），交叉熵优化往往比 MSE 更适合概率任务。

---

## 3.2 多分类：类别是离散的，不讲大小

### 3.2.1 softmax 分类器：输出一个分布

线性层 + softmax：

$$
\pi = \text{softmax}(z),\quad z=Wx+b
$$

softmax 定义：

$$
\text{softmax}(z)_j = \frac{e^{z_j}}{\sum_{l=1}^{k} e^{z_l}}
$$

输出 $\pi_j$ 是属于第 $j$ 类的概率。

### 3.2.2 多分类交叉熵

若真实标签用 one-hot 向量 $y$ 表示：

$$
\ell = -\sum_{j=1}^{k} y_j \ln \pi_j
$$

工程联想：搜索里的很多 NLP 任务都天然是多分类或多标签：

- 查询词类目
- 意图类型（是否地域/是否时效/是否电商购买意图…）
- 命名实体类型

**注意**：多标签（一个样本可以属于多个类）通常不是 softmax，而是 $k$ 个 sigmoid。

---

## 3.3 回归：标签是有序数值，目标是“保值”

回归的关键不是“标签是整数”，而是：

> 标签之间可以比较大小（有序）。

书里举例：相关性档位 $\{0,1,2,3,4\}$ 是有序的，所以更像回归而不是多分类。

### 3.3.1 线性回归 + MSE

$$
\hat{y}=x^\top w+b
$$

$$
\text{MSE}=\frac{1}{n}\sum_{i=1}^n (\hat{y}_i-y_i)^2
$$

### 3.3.2 用 sigmoid 做“有界回归”

如果你把 $y$ 归一化到 $[0,1]$，也可以用 sigmoid 输出，然后仍用交叉熵或 MSE。

书里的决策建议非常实用：

- 如果你真的关心“分数拟合得准”（比如要做精细打分），用回归/MSE 更自然。
- 如果你只想把低分样本过滤掉（海选阶段），那你更在意“区分相关/不相关”，用二分类会更合适。

这就是搜索工程里常说的：

- 召回/过滤：更像分类
- 精排打分：更像回归或排序

---

## 3.4 排序：目标是“保序”，不是“保值”

排序任务的核心：

- 你不需要 $\hat{y}$ 和 $y$ 数值接近
- 你需要文档之间的相对顺序正确

### 3.4.1 pairwise 思路：让正序对更多

对同一 query 的文档对 $(i,j)$，若 $y_i>y_j$，希望模型分 $p_i>p_j$。

书里给了经典的 pairwise logistic loss：

$$
L(w) = \frac{1}{m^2}\sum_{(i,j):y_i>y_j} \ln\big(1+\exp(-(p_i-p_j))\big)
$$

直觉：

- $p_i-p_j$ 越大（更符合“高相关在前”），损失越小

### 3.4.2 为什么排序更符合搜索？

因为用户看到的是列表，且注意力集中在前几位。

- 回归只关心“分数拟合”，不关心交换两个相近文档的影响。
- 排序直接对“交换次序”施加惩罚，更贴近结果页体验。

---

## 3.5 四类任务的“选择指南”（新手最需要的部分）

你可以用 3 个问题来选建模方式：

1. 标签是否有序？
   - 无序 → 多分类
   - 有序 → 回归或排序
2. 你关心的是“值”还是“序”？
   - 关心值 → 回归
   - 关心序 → 排序
3. 你主要用途是过滤还是精排？
   - 海选过滤 → 二分类/阈值决策
   - 精排重排 → 排序（或回归 + listwise 评估）

---

## 3.6 与后续章节的连接

- 第 4 章（离线评价）告诉你：不同任务该用什么指标验证（AUC/F1、NDCG 等）。
- 第 10 章（CTR 预估）会把本章的二分类落到真实的特征工程与模型结构。
- 第 19–20 章（排序与训练）会把本章的排序训练进一步系统化。

---

## 3.7 练习（建议你真的动手算一次）

1. 构造一个 query 下的 5 篇文档，给出真实相关性档位 $y$ 与模型分数 $p$，数一数正序对/逆序对，并解释为什么 pairwise loss 会推动它变好。
2. 设计一个“回归 vs 排序”的对比：
   - 用 MSE 训练一个 toy 模型
   - 用 pairwise logistic loss 训练一个 toy 模型
   - 用 NDCG@3 对比两者的排序效果
3. 找一个你熟悉的搜索场景（电商/UGC/网页），列出 5 个任务并判断它们更像二分类、多分类、回归还是排序。
