这是一个基于《第2章 搜索引擎的评价指标》的详细学习指南。如果说第一章是搜索引擎的**架构图**，那么这一章就是搜索引擎的**仪表盘**。

以下是为您整理的核心知识点：

### 1. 为什么需要评价指标？

一句话总结：**无法度量，就无法优化。**
算法工程师需要一个具体的数字作为“指挥棒”来牵引优化方向。

- 工业界通常建立一个“三角评价体系”：
  1.  **北极星指标**（商业/规模，为了公司生存）
  2.  **中间过程指标**（用户行为，为了快速验证）
  3.  **人工评估指标**（主观质量，为了校准体验）

---

### 2. 核心业务指标 (北极星指标)

这是公司层面的最高战略指标，通常非常难提升，且反应滞后。

#### A. 用户规模 (Scale)

- **DAU / MAU**: 日/月活跃用户数。
- **SDAU (Search DAU)**: 对于百度、抖音、小红书这类超级APP，必须区分**SDAU**（搜索日活）和**FDAU**（推荐流日活）。
  - **渗透率**: `SDAU / DAU`。这个指标越高，说明用户越习惯用你的APP来搜索信息。

#### B. 用户留存 (Retention)

衡量产品留住用户的能力。

- **次 n 留 (Within Next-n-day)**: 今天来的用户，在未来 n 天内**至少回来一次**的比例。（数值较高，常用）
- **第 n 留 (N-th Day)**: 今天来的用户，恰好在**第 n 天**回来的比例。（数值较低）
- **注意**: 即使策略有效，留存指标往往需要数周才能看出显著变化（滞后性）。

---

### 3. 中间过程指标 (Intermediate Metrics)

因为北极星指标太慢、太难动，算法团队日常主要看这些指标。它们反应快，但容易被误导。

#### A. 点击类 (Clicks)

- **文档点击率 (CTR)**: `点击次数 / 曝光次数`。
- **有点比 (Click Coverage)**: `有点击的搜索次数 / 总搜索次数`。衡量搜索成功率的核心指标。
- **首屏有点比**: 用户在第一屏（不用下滑）就点击的比例。这是衡量排序算法好坏的关键——最好的结果应该排在最前面。

#### B. 交互类 (Engagement) & 位置类

- **首点位置**: 用户点的第一条结果排第几？越小越好（说明用户一眼就看到了）。
- **交互**: 比点击更强烈的信号。标题党能骗点击，但骗不到**点赞、收藏、转发**。
- **主动换词率**: 用户搜了一个词没找到满意的，又换了个词搜。这个指标高通常代表体验差。

#### **关键批判**: 为什么不能只看点击？

书中给出了深刻的行业洞察：**点击率不等于满意度**。

- **相关性悖论**: 放松相关性（出一些八卦、美女图）通常会瞬间拉升CTR，但长期会损害用户对搜索引擎的信任（YMYL原则）。
- 很多优化（如提升时效性、去广告）可能不会提升CTR，但必须做。

---

### 4. 人工体验评估 (Human Evaluation)

当数据说谎（如CTR涨但体验差）时，需要人来介入。

#### A. SBS (Side-by-Side) 评估

这是搜索策略上线的必经之路。

- **做法**: 左边是对照组，右边是新策略。评估员不看代码，只看结果，判定 **Good / Same / Bad (GSB)**。
- 只有 `Good > Bad` 到一定程度，策略才能全量上线。

#### B. DCG (Discounted Cumulative Gain)

这是最经典的信息检索评估公式。
$$DCG = \sum \frac{相关性分数}{\log(排名)}$$

- **核心思想**: **位置加权**。
  - 把好结果排在第1位，得分很高。
  - 把好结果排在第10位，得分会因分母变大而被“打折”。
  - 这强迫算法把最好的结果往前提。

#### C. 人工评估的痛点

- **贵且慢**: 养团队要钱，评测一次要一周。
- **个性化难评**: 比如搜“狄仁杰”，游戏玩家想找攻略，历史爱好者想找宰相。评估员很难代入特定用户的视角去评判结果好坏。
