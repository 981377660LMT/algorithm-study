# 15 查询词改写：目标是“让 q 找到更多相关 d”，而不是让 q 像 q′

本章把“查询词改写”讲得非常工程化：

- 它是 QP 模块里最能撬大盘的手段之一
- 它的目标不是语义相似本身，而是提升召回供给

最关键的定义是：

> 把原 query $q$ 改写为 $q'$，用 $q'$ 去召回文档 $d$；改写的目标是让 $(q,d)$ 高相关，而非让 $(q,q')$ 相似。

这句话值得反复记，因为它解释了为什么很多“看起来合理的改写”在线上是灾难。

---

## 15.1 改写的业务收益：降低少结果/无结果，提升大盘指标

改写带来的典型收益：

- 降低生僻/低频 query 的无结果率、少结果率
- 提升供给 → 进而提升留存、有点比、首点位置、换词率等

本章给了两个经典问题：

1. **语义鸿沟**：
   - “粤菜” ↔ “潮汕美食”
   - “reinforcement learning” ↔ “强化学习教程”

2. **简称/别称/不规范表述**：
   - “增强学习” vs “强化学习”

从作用上看，改写与向量召回有相似之处：

- 都是在弥补纯文本检索的不足

---

## 15.2 基于分词的改写：词表 + 规则（简单、便宜、稳定）

当 query 已分词为 $t_1\dots t_m$ 后，可以做词粒度替换：

- 同义词替换（民族舞→民间舞；教程→教学）
- 别名替换（老谋子→张艺谋；苹果手机→iphone）
- 数字/中英文互换（双11↔双十一；reinforcement learning↔强化学习）

### 15.2.1 上下位词替换：只能“上位→下位”，不能反过来

一个非常重要的约束：

- 上位词 → 下位词：通常安全（更聚焦）
- 下位词 → 上位词：高风险（会召回到不相关）

例子：

- “上海的餐厅” → “浦东的餐厅”可行
- “浦东的餐厅” → “上海的餐厅”会召回闵行等，可能不满足用户意图

### 15.2.2 改写如何影响召回逻辑

不改写时，召回通常是 AND：

- 民族舞 AND 教程

改写后，本质变成“同义扩展的 OR，再做 AND”：

- (民族舞 OR 民间舞 OR 蒙古舞) AND (教程 OR 教学)

工程提醒：

- OR 扩展会显著扩大候选集，必须配合排序与质量约束

---

## 15.3 基于相关性的改写：召回模型 + 判别模型（工业落地范式）

本节是本章最硬核的工程方案：

- 用日志 + 相关性模型自动构造海量训练数据
- 训练一个改写“召回模型”和一个改写“判别模型”

目标：

- 把任意 $q$ 改写到头部集合里的 $q'$（便于召回足够供给）
- 使 $q'$ 召回的文档对 $q$ 仍高相关

### 15.3.1 数据构造：{(q, q′, y)} 的 y 是“q 与 q′召回文档的相关性”

关键设定：

- 头部查询集合 $T$：例如 500 万高频 query
- 全量查询集合 $Q$：数千万，覆盖头部与长尾

先构造候选改写对 $q\to q'$（两种方式）：

1. **语义向量候选**：用预训练 BERT 表征 query，找 $T$ 中最相似的 $q'$
2. **行为二部图候选**：query 与文档构图，共同邻居（共同点击高相关文档）越多则越关联

然后定义标签 $y$：

- 对每个头部 $q'$，先挖掘它高相关/高点击文档 $d_1\dots d_k$
- 用已有相关性模型打分 $rel(q,d_i)$
- 令

$$
 y = \frac{1}{k}\sum_{i=1}^{k} rel(q,d_i)
$$

$y$ 越高，说明改写 $q\to q'$ 越合理。

工程代价：

- 数据构造需要大量相关性打分（本章强调算力开销很大）

### 15.3.2 改写召回模型：双塔检索 q′（快，但会犯对称性错误）

训练：

- 双塔表征 $q$ 与 $q'$ 为向量 $x$ 与 $x'$
- 用 $\sigma(x^\top x')$ 拟合 $y$（pointwise 交叉熵）
- 再加一批随机负样本 $(q_1,q_2,0)$

部署：

- 离线计算所有 $q'\in T$ 的向量，存入 Faiss
- 线上对 $q$ 编码，在 Faiss 中做内积检索，取 topN 改写候选

风险（本章明确指出）：

- 双塔是对称的：若认为 $q\to q'$ 合理，也会认为 $q'\to q$ 合理
- 因此容易犯“下位→上位”的改写错误

### 15.3.3 改写判别模型：交叉 BERT 非对称打分，过滤上下位错误

为了解决上面的对称性问题，需要判别器 $f(q,q')$：

- 输入是拼接的 $(q,q')$
- 输出是改写质量分数
- 训练目标拟合 $y$
- 并加入 $(q',q',1)$ 作为正样本

关键性质：

- 判别器是非对称的：$f(q,q')\neq f(q',q)$
- 因此能更好地区分“上位→下位”与“下位→上位”

### 15.3.4 离线改写索引：q → List<q′> 覆盖大多数线上请求

本章给了一个很重要的工程策略：

- 预先离线算一个改写索引 $q\to\langle q'_1\dots q'_k\rangle$
- 线上优先查索引，只有长尾不命中才在线召回+判别

并给了存储量级估算（非常有工程参考价值）：

- 1 亿 query × 每条 5 个改写 × 平均 20 字符 → 约 24GB

离线算索引时可以用“三级漏斗”（类似搜索链路）：

- 召回/生成得到数百候选
- 判别器打分筛选
- 再用相关性模型对“q 与 q′召回文档”做最终打分排序

副产物：

- 会产出海量高质量 $(q,q',y)$，反哺召回/判别模型

---

## 15.4 基于意图的改写：需要与召回/结构化检索联动

这节强调：有些意图纯靠文本召回解决不了，需要改写 + 下游承接。

### 15.4.1 属性检索意图

例子：

- “60寸3000元以下电视机”
- “2TB西部数据移动硬盘”
- “身高161体重125女穿搭建议”

关键是把 query 结构化成：

- 品类 + 属性约束（数值范围/枚举）

下游召回要能做属性过滤/范围检索，否则文本召回会漏掉大量满足约束的商品/内容。

### 15.4.2 提问意图

把“怎么/如何”类问题改写成更可检索的表达：

- “instagram怎么注册” → “instagram注册教程”

并且排序上可能要提高权威性/答案卡片权重。

### 15.4.3 地域意图

典型思路：

- 把“附近的火锅店”改写为“火锅店”
- 同时把用户 GeoHash/城市作为召回过滤条件传下去

注意：

- 这是“改写 + 召回过滤”的组合拳，单靠文本改写不够。

---

## 15.5 常见坑与检查清单

- 只追求 $q$ 与 $q'$ 相似：会得到“看似合理但召回跑偏”的改写
- 不做判别器：双塔会大量输出上下位反向改写
- 改写扩展太猛：召回量暴涨但相关性崩，需要配合排序阈值/质量约束
- 离线索引不做版本管理：改写规则/模型变化会导致线上不可比

---

## 15.6 练习（建议动手）

1. 随机选 200 条长尾 query，人工写出 1–3 个“头部改写”，并用“q 与 q′召回文档是否仍相关”作为判断标准。
2. 实现一个最小版改写系统：
   - 召回：双塔 embedding + Faiss topN
   - 判别：交叉 encoder 打分
   - 输出：topK 改写
3. 做一个线上策略草案：
   - 哪些 query 走离线索引
   - 哪些 query 触发在线改写
   - 改写触发条件（少结果/低覆盖/意图识别）

---

## 15.7 与其它章节的连接

- 与第 6 章：改写数据构造依赖相关性模型打分
- 与第 11/12 章：词粒度改写依赖分词与词权重
- 与第 14 章：意图识别决定是否触发“意图改写 + 下游承接”
- 与第 16–18 章：改写的终点是召回，召回能力决定改写收益上限
