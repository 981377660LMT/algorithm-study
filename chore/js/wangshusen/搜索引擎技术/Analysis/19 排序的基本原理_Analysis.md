# 19 排序的基本原理：三处排序同构，差别在“打分量/模型规模/特征可用性”

本章把搜索排序拆得非常清晰：

- 搜索链路上有三处需要排序：
  - **召回截断**（数万→数千）
  - **粗排**（数千→数百）
  - **精排**（数百→最终曝光顺序）

三处排序的本质是同一个模板：

> 先预测相关性与点击/交互，再把相关性、点击率、质量、时效性等分数融合成最终排序分数。

差别主要来自：

- 候选量不同 → 允许的单文档计算不同
- 线上能拿到/愿意用的特征不同

---

## 19.0 三处排序：漏斗越往后越“贵但准”

本章给了一个很强的工程直觉：

- 精排打分量最小（数百），可以用最强模型、最丰富特征
- 粗排打分量更大（数千），模型必须更轻
- 召回截断打分量最大（数万），只能用极轻计算（例如向量内积、线性融合）

因此，排序不是“一个模型解决一切”，而是一个多级漏斗。

---

## 19.1 融合模型的特征：分数型特征 + 静态特征 + 后验统计

融合模型（或融合规则）通常用到：

- 相关性分数
- 点击率/交互率预估
- 内容质量分数
- 时效性分数
- 其它特征（意图、用户画像、文档属性、统计特征等）

其中：

- 相关性/点击率往往在排序模块内实时推理
- 其它特征多数在离线或上游计算好，通过特征服务传入

### 19.1.1 相关性模型：交叉 BERT 为王，双塔用于轻量场景

本章给出的配置梯度很实用（按算力从强到弱）：

- 精排/粗排优选交叉 BERT：输入 "[CLS]+q+[SEP]+d+[SEP]" 输出相关性
  - 算力充足：粗排 4 层，精排 12 层
  - 算力一般：粗排 4 层，精排沿用粗排分数
  - 算力紧张：精排 4 层，粗排双塔

召回截断可用双塔相关性：

- 右塔文档向量离线算好存哈希表
- 线上只跑左塔 query 向量，再做内积

若工程条件更弱，截断阶段可以退化到 BM25 等手工特征。

### 19.1.2 点击率模型：精排用大 DNN，粗排/截断用双塔

本章把 CTR 模型也按阶段分层：

- 精排 CTR：多目标大规模 DNN
  - 输入：query/文档/用户/场景 + 统计特征
  - 大 embedding：数亿用户/文档 ID
  - 输出：点击率 + 多种交互率（赞/藏/评/完播等）

- 粗排 CTR：多目标双塔
  - 离线算文档塔，线上算请求塔

- 截断 CTR：更轻量
  - 可弱个性化或不个性化
  - 可不预估交互（交互太稀疏，难估）

### 19.1.3 其它特征：意图/画像/属性/后验统计是“强信号”

本章列的特征体系可以当作一份排序工程清单：

- query 意图：类目、时效性意图、地域意图（来自 QP）
- 用户画像与场景：性别年龄、时间地点等
- 文档属性：质量档位、类型（图文/视频/商品）、年龄、类目
- 文档统计：曝光/点击/交互次数与比例（后验反映质量）
- query-doc 统计：在 $q$ 下 $d$ 的 CTR 等（后验反映匹配）

---

## 19.2 融合规则 vs 融合模型：早期要可控，后期要可学

本章对“什么时候用规则、什么时候上模型”的判断非常实战。

### 19.2.1 早期：先用融合规则（简单、可解释、好调参）

典型做法：

- 先按相关性分档（例如 4 档）
- 档内用人工公式融合 CTR/质量/时效

好处：

- 出问题好定位（骗点首图、标题党等）
- 能快速做业务约束（比如提升视频曝光占比）

### 19.2.2 中后期：用融合模型替代规则，并可松弛相关性分档

本章给了一个很强的结论：

- 用融合模型替代规则后，可以把相关性分档从 4 档松弛到 2 档
- 相关性不一定变差，但点击指标可能大幅提升

这里的逻辑是：

- 分档太硬会压制 CTR/质量信号
- 融合模型能在“相关性门槛不那么硬”的情况下，仍用多信号把排序拉回来

### 19.2.3 必须配套：相关性监控，防止“为了点击牺牲相关性”

本章提醒了一个非常现实的问题：

- 如果只用点击指标当目标，团队可能通过弱化相关性权重来“刷指标”

应对方式：

- 在实验平台监控 topK 结果的相关性档位占比（高/中/低/无）

虽然该监控分数来自模型而非人工标注，会受模型升级影响，但仍能防止策略走偏。

---

## 19.3 训练融合模型的数据：满意度（人工/教师）+ 用户行为

本章强调训练融合模型的目标不是单一点击，而是“综合满意”。

关键做法：

- 用人工标注的综合满意度 $s$
- 结合点击/交互行为得到目标 $y$

例如：

- 加权和：$y=s+\alpha\,click+\beta\,interact$
- 或“优先点击”的规则：无点击则 $y=0$，有点击则 $y=s+\beta\,interact$

当人工标注规模不足时：

- 训练一个非个性化的教师模型（常用 GBDT）估计 $s$
- 用教师模型给海量日志样本打分，扩充训练数据

这为下一章的训练方法（pointwise/pairwise/listwise）做了铺垫。

---

## 19.4 常见坑与检查清单

- 过度依赖 CTR：标题党/骗点图容易上去，长期留存会掉
- 统计特征泄露或偏差：热门文档天然高 CTR，需要配合校准与切片评估
- 相关性分档松弛但缺少监控：容易出现“相关性慢慢变差但指标短期变好”的错觉

---

## 19.5 练习（建议动手）

1. 画出你所在业务的三段漏斗：每段候选量、允许 RT、可用模型类型。
2. 写一份融合规则的初版公式，并列出“你预期它会排序错的 5 类文档”。
3. 设计相关性监控面板：topK 档位占比、分 query 类目切片、按时效意图切片。

---

## 19.6 与其它章节的连接

- 与第 16–18 章：召回供给与质量决定了排序的上限
- 与第 20 章：融合模型训练方法决定了你能否真正优化排序目标（尤其是 NDCG）
