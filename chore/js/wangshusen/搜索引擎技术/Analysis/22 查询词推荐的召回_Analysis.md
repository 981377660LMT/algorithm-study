# 22 查询词推荐的召回：SUG 走“拼写”，Q2Q/D2Q 走“行为/语义”，再用多跳拼装场景

上一章定义了 4 个推词场景，本章把“召回依据”先对齐：

- 搜前推词：基于用户兴趣（个性化）
- SUG、搜索结果页推词：基于当前 query $q$
- 文档内推词：基于当前文档 $d$

推词系统通常有一个“词库”作为候选全集：

- 精品词库（调性一致：可从优质笔记标题/首图文案提取）
- 站内热门 query（例如 1 千万）
- 外网抓取 query

召回的任务就是：从词库里拿出一批候选 query，交给排序。

---

## 22.1 SUG 召回：三类成熟的拼写/输入法召回 + 一个生成式补充

SUG 的特点是：

- 强实时：用户边输入边出结果
- 强工具：目标是补全、纠错、提高输入效率

本章把 SUG 的核心召回归纳为三类：

### 22.1.1 前缀召回

- 通用前缀："上海" → "上海迪士尼"
- 拼音前缀："美j" → "美甲"

这是最基础、最稳定的 SUG 通道。

### 22.1.2 分词召回：包含关系 / 首字匹配 / 核心词兜底

设用户输入被分词为 $Q=\{w_1,\dots,w_k\}$，候选 query 的分词为 $Q'$。

- 通用分词召回：若 $Q\subset Q'$，则召回 $Q'$
  - 例："迪士尼" → "上海 迪士尼"

- 首字召回：$w_i$ 等于 $w'_i$ 或为其首字
  - 例："上迪士尼" → "上海迪士尼"

- 核心词召回：当召回量不足时，丢弃非核心词，只保留核心词再做分词召回
  - 例："如何制作蛋挞" → "蛋挞做法"

这里本质上复用了第 12 章的“词权重/核心词”思想：

- 召回不足时，宁可松弛表达也要保证候选量。

### 22.1.3 拼写召回：输入法与同音字兜底

- 拼音简写："shdsn" → "上海迪士尼"
- 同音字："喜皮士" → "喜啤士/西皮士/嬉皮士"（通常在召回不足时触发）

### 22.1.4 生成式召回：在“可控校验”下做扩展

书里给了一个很典型的生成式补充：

- "日语慢速教学" → 生成 "教学视频" 这类扩展

但它强调必须加校验：

- 用 bigram 关联矩阵校验扩展词与原片段的关联性
- 否则生成式扩展很容易跑偏

---

## 22.2 用查询词召回查询词（Q2Q）：协同过滤与向量召回

Q2Q 用于除 SUG 外的推词场景（搜后相关搜索、搜前兴趣推词的一部分路径等）。

系统形态通常是建立索引：

- $q \to List\langle q'\rangle$

### 22.2.1 ItemCF：用“共现用户”定义 query 相似

设：

- 搜过 $q_1$ 的用户集合为 $W_1$
- 搜过 $q_2$ 的用户集合为 $W_2$
- 交集 $V=W_1\cap W_2$

ItemCF 相似度：

$$
 sim(q_1,q_2)=\frac{|V|}{\sqrt{|W_1|\,|W_2|}}
$$

直觉：

- 越多用户同时搜过两个 query，越可能兴趣点一致
- 它能挖出“文本不相似但兴趣相关”的 query 关联（如 "梅西" ↔ "阿根廷国家队"）

### 22.2.2 Swing：给“小圈子”降权，抑制刷量共现

ItemCF 只看 $|V|$，会被“微信群刷搜索”这类小圈子共现污染。

Swing 的修正是：

- 不仅看交集用户数量，还看这些用户是否来自同一小圈子

定义两位用户的 query 集合：

- $J_1, J_2$，重合度 $overlap(u_1,u_2)=|J_1\cap J_2|$

Swing 相似度：

$$
 sim(q_1,q_2)=\sum_{u_1\in V}\sum_{u_2\in V}\frac{1}{\alpha+overlap(u_1,u_2)}
$$

- $\alpha\ge 0$ 为超参
- 用户越“像同一圈子”（overlap 高），贡献越小

工程意义：

- Swing 在“反作弊/反刷量”上通常更稳

### 22.2.3 向量召回：双塔表征 query，召回相似 query

用双塔把 query 文本 + 类目 + 核心词编码成向量，ANN 检索相似 query。

训练样本来自“搜索结果页推词”：

- 用户搜 $q$，点击推荐 query $q'$，则 $(q,q')$ 为正样本
- 负样本可用随机/batch 内/困难负样本

本章强调：

- 模型结构成熟，效果提升更多来自“正负样本构造”

---

## 22.3 用文档召回查询词（D2Q）：文档发布时离线/近线算好

D2Q 用于：搜前推词、文档内推词。

系统形态：

- $d \to List\langle q\rangle$

本章给了三类做法：

### 22.3.1 生成式 D2Q：Transformer 生成 query + 相关性判别过滤

与第 18 章的反向召回呼应：

- Transformer 从文档生成 query
- 用相关性 BERT 判别过滤低相关

强调工程形态：

- 离线或近线（消息队列均衡 QPS，延迟分钟级）

### 22.3.2 向量召回 D2Q：复用相关性双塔模型

无需单独训练：

- 用文档向量去检索 query 向量
- 再用相关性 BERT 做阈值过滤

### 22.3.3 行为版 D2Q：文档点击后触发的 query 行为关联

定义：

- 点击过文档 $d$ 的用户集合 $U$
- 搜过 query $q$ 的用户集合 $W$
- 在“点击 $d$ 后 $t$ 天内搜索的前 $l$ 条 query”中包含 $q$ 的用户集合 $V$

相似度：

$$
 sim(d\to q)=\frac{|V|}{\sqrt{|U|\,|W|}}
$$

这里的时间窗与序列长度（$t,l$）非常关键：

- 太大：因果链变弱，噪声上升
- 太小：样本过稀，召回不足

---

## 22.4 场景拼装：U2Q2Q / U2D2Q / D2Q2Q

本节的核心是“多跳召回”把不同索引拼起来。

### 22.4.1 搜前推词：完全基于用户兴趣

- U2Q2Q：用户历史 query 做种子 → 用 Q2Q 扩展
  - $u \to List\langle q\rangle$（取最近 $n_1$ + 随机 $n_2$）
  - 每个种子 $q$ 用 Q2Q 召回 $m$ 个

- U2D2Q：用户历史交互文档做种子 → 用 D2Q 召回 query
  - $u \to List\langle d\rangle$（取最近 $n_1$ + 随机 $n_2$）
  - 每个种子 $d$ 用 D2Q 召回 $m$ 个

### 22.4.2 搜索结果页推词：用当前 query 直接 Q2Q

- 当前 $q$ 作为种子，Q2Q 召回一批相关 query

### 22.4.3 文档内推词：D2Q + D2Q2Q（再跳一次扩大供给）

- D2Q：$d \to \{q_1,\dots,q_n\}$
- D2Q2Q：对每个 $q_i$ 再用 Q2Q 扩展 $\{q'_{i,1},\dots,q'_{i,m}\}$
- 合并：$\{q\}\cup\{q'\}$

工程直觉：

- 多跳能扩大候选，但也更需要排序端抑噪

---

## 22.5 常见坑与检查清单

- SUG 只做前缀不做分词/拼写兜底：长尾补全差，使用率上不去
- ItemCF 受小圈子刷量污染：相关搜索质量波动大（Swing 往往更稳）
- D2Q 不做近线治理：文档发布高峰时在线算力被打爆
- 多跳召回不控爆炸：候选量过大，排序压力与延迟显著上升

---

## 22.6 练习（建议动手）

1. 用同一份日志分别实现 ItemCF 与 Swing 的 q2q，相同 topK 下对比“刷量 query”切片的质量差异。
2. 为 SUG 设计触发策略：什么时候启用同音字/核心词召回？阈值如何定？
3. 做一个 D2Q2Q 的小实验：比较 D2Q 与 D2Q2Q 的候选覆盖率与噪声比例。

---

## 22.7 与其它章节的连接

- 与第 12/16 章：核心词召回、丢词松弛与文本召回的策略同源
- 与第 17 章：Q2Q 向量召回与 ANN 检索完全复用召回体系
- 与第 18 章：生成式 D2Q 与反向召回（doc2query）是同一类思想
- 与第 23 章：召回越“扩”，排序越要对点击与转化负责
