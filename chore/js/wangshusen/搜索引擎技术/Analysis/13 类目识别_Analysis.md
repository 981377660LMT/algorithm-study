# 13 类目识别：把 query/doc 映射到“业务语义空间”的离散锚点

搜索引擎通常维护一套多级类目体系：

- 几十个一级类目
- 数百个二级类目（甚至更多层级）

类目在工程里不是“为了好看”，而是非常实用的离散特征与路由依据：

- 文档入库时离线打类目，作为文档特征存储
- query 侧在线识别类目，供召回/排序/CTR 等下游使用

而且一个 query/doc 可以是多类目（多意图、多语义覆盖），因此任务天然是：

- **多标签分类（multi-label classification）**
- 还带有**层次结构（hierarchical）**

---

## 13.1 多标签分类的基线：BERT + sigmoid + BCE

本章给出的标准建模方式：

- 用 BERT 的 [CLS] 向量作为语义表示
- 过一层全连接
- 用 sigmoid 输出 $k$ 个类目概率 $p_1\dots p_k$（不是 softmax，因为允许多标签）

标签是 $y\in\{0,1\}^k$，用二元交叉熵（BCE）训练：

$$
BCE(y,p)=-\sum_{i=1}^{k}\Bigl(y_i\ln p_i + (1-y_i)\ln(1-p_i)\Bigr)
$$

### 13.1.1 改进 1：Focal Loss 解决“难样本/长尾类目”

类目往往长尾严重：

- 头部类目数据多
- 长尾类目数据少且容易错

Focal Loss 用一个 $(1-p)^\gamma$ 或 $p^\gamma$ 的权重，让训练更关注难样本：

$$
FL(y,p)=-\sum_{i=1}^{k}\Bigl(y_i(1-p_i)^\gamma\ln p_i + (1-y_i)p_i^\gamma\ln(1-p_i)\Bigr)
$$

当 $\gamma=0$ 时退化回 BCE。

工程上你可以把它理解为：

- 预测很准的样本少学点
- 预测容易错的样本多学点

### 13.1.2 改进 2：把层级结构注入训练（递归正则）

类目不是平的，而是树/层级。

本章给的做法是“递归正则（recursive regularization）”：

- 输出层参数矩阵 $W$ 有 $k$ 行，每行 $w_i$ 对应一个二级类目
- 若二级类目 $i,j$ 属于同一个一级类目，则鼓励 $w_i$ 与 $w_j$ 接近

定义邻域集合 $N(i)$（同父一级类目的兄弟类目），正则项：

$$
R(W)=\sum_{i=1}^{k}\sum_{j\in N(i)}\lVert w_i-w_j\rVert^2
$$

训练时最小化：

- (BCE 或 FL) + 正则项加权

直觉：

- 同一大类下的子类共享部分语义模式
- 参数共享会提升样本效率与泛化

### 13.1.3 改进 3：查询词类目识别做后预训练

文档长、信息量大，类目相对好识别。

query 很短、歧义多，类目识别更难，且标注员很多时候需要“实际搜一下”才知道属于什么类目。

因此本章建议：

- 在预训练与微调之间做后预训练
- 用曝光日志挖掘：对每个 query 找“高相关 + 高点击”的文档集合
- 把这些文档的类目统计聚合成 query 的弱标签
- 用数百万 query 做多标签训练

这本质是：

- 用用户行为把 query 的语义歧义“拉回业务真实分布”

---

## 13.2 离线指标：micro/macro F1 与 MAP

类目识别常见两种评估视角。

### 13.2.1 视角 1：多标签二分类 → micro F1 / macro F1

对每个类目计算 TP/FP/FN，然后：

- micro：先把各类目的 TP/FP/FN 汇总，再算 F1（更偏向头部类目）
- macro：先对每个类目算 F1，再平均（更关注长尾）

工程建议：

- micro 更贴近整体线上效果
- macro 更适合作为长尾类目的护栏指标

### 13.2.2 视角 2：类目排序 → MAP

把 $p_1\dots p_k$ 排序，取 top-t 类目作为预测。

对每条样本算 AP，再对测试集平均得到 MAP。

工程价值：

- 适合“只展示 topN 类目”的场景
- 能评价模型对类目排序质量，而不依赖固定阈值

---

## 13.3 工程落地：类目如何进入召回与排序

典型用途：

- 召回：按类目做通道/索引/配额（例如电商、视频、图文不同通道）
- 排序：类目作为离散特征（query 类目 × doc 类目）
- 多意图 query：输出多个类目，帮助多队列混排

需要注意：

- 类目体系会演化（增删类目、合并拆分），训练与评估要做版本管理
- 类目错误会放大为下游系统性偏差（召回路由错、特征错）

---

## 13.4 常见坑与检查清单

- 只看 micro F1：长尾类目全面崩但你看不出来
- 阈值固定：不同类目先验不同，最好做分层阈值或 topK
- query 后预训练弱标签噪声大：点击偏置/位置偏置会污染
- 多标签漏标：标注不一致会让模型学到“少贴标签更安全”

---

## 13.5 练习（建议动手）

1. 给 500 条 query 做多标签类目标注（允许多意图），训练一个基线模型，并分别报告 microF1 与 macroF1。
2. 为类目体系实现递归正则：定义 N(i)，观察它对长尾类目指标的提升。
3. 用日志做 query 类目弱标注：对每条 query 聚合 top-click 文档的类目分布，作为后预训练标签。

---

## 13.6 与其它章节的连接

- 与第 14 章：类目是意图识别的一部分，也是路由依据
- 与第 10 章：类目是 CTR/个性化的重要离散特征
- 与第 16–18 章：召回通道常按类目/垂类分治
