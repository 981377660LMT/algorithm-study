这节课讲解双塔模型（two-tower，也叫 DSSM）正负样本的选取。正样本是有点击的物品。负样本是被召回、排序淘汰的物品，分为简单负样本和困难负样本。

---

这份关于双塔模型（Two-Tower Model）召回阶段**正负样本选取**的课程内容非常核心且具有实战价值。其核心逻辑在于：**在模型结构同质化的今天，数据（样本）的质量决定了最终效果的上限。**

以下是对该内容的逻辑分析与深度拆解：

### 1. 核心前提：样本优于结构

- **论点**：选对正负样本带来的收益 > 改进模型结构。
- **背景**：双塔结构本身比较简单（用户塔+物品塔），优化空间有限，因此特征工程和样本选择成为胜负手。

### 2. 正样本选取策略：解决“马太效应”

- **定义**：曝光且有点击的行为（User, Item）二元组。
- **核心痛点**：**二八法则（热度偏差）**。
  - 热门物品占据大部分点击，导致正样本集中在热门物品。
  - 后果：模型“嫌贫爱富”，冷门物品永远无法被召回，由于无法被召回也就无法积累数据，陷入死循环。
- **解决方案**：
  - **过采样（Up-Sampling）**：针对冷门物品，让其多次出现。
  - **降采样（Down-Sampling）**：针对热门物品，按概率抛弃。
  - **关键点**：抛弃概率需与热度（点击次数）正相关。

### 3. 负样本选取策略：分层构建

负样本的定义是“用户不感兴趣”，但在工业界链路中，这需要分层次来理解。

#### A. 简单负样本（Easy Negatives）

这是召回训练的基石，目的是让模型学会**区分“大概率不相关”的物品**。

- **来源 1：全局随机抽样**
  - **逻辑**：未被召回的物品 ≈ 全体物品 ≈ 负样本。
  - **抽样技巧**：**非均匀采样**。
  - **原因**：若均匀采样，负样本多为冷门物品（因为全体物品中冷门占多数）。正样本是热门，负样本是冷门，模型容易偷懒，学会“热门=正，冷门=负”，而不是真正理解用户兴趣。
  - **做法**：负样本抽样概率 $\propto$ 物品热度的 $0.75$ 次方。这是一种平滑处理，既打压热门，又不至于过度。
- **来源 2：Batch 内负样本 (In-Batch Negatives)**
  - **逻辑**：利用矩阵计算的高效性，将同一 Batch 内其他用户的正样本，作为当前用户的负样本。
  - **效率**：$N$ 个样本可生成 $N \times (N-1)$ 个负样本。
  - **严重的偏差问题**：
    - Batch 内出现的物品都是因为被点击过，所以出现概率 $\propto$ 点击次数（1 次方）。
    - 这导致热门物品作为负样本出现的概率过高，被过度打压。
  - **修正方案 (YouTube Paper)**：
    - 训练时修正 Logit：$s(u, i) - \log(p_i)$。
    - 原理：在计算损失时，人为减去物品流行度的对数，抵消掉因采样带来的过度打压。
    - 推理时：恢复正常，$s(u, i)$，无需减去。

#### B. 困难负样本（Hard Negatives）

提升模型分辨能力的“磨刀石”。

- **来源**：召回了，但被**粗排/精排**淘汰的物品。
- **逻辑**：这些物品通过了海选，说明和用户**有点相关**，但又不够好。
- **价值**：如果模型能区分出这些“似是而非”的物品，其准确度会大幅提升。
- **工业界配比**：通常 **50% 简单负样本 + 50% 困难负样本** 混合训练。

### 4. 关键误区预警：关于“曝光未点击”

这是本次分析中最需要警惕的逻辑陷阱。

- **错误做法**：将“曝光给用户但没点击”的物品作为**召回**的负样本。
- **逻辑谬误分析**：
  - **链路职能不同**：
    - **召回（Retrieval）**：负责海选，区分“不感兴趣” vs “可能感兴趣”。
    - **排序（Ranking）**：负责优选，区分“可能感兴趣” vs “最感兴趣”。
  - **样本性质**：
    - 能曝光说明已经通过了召回、粗排、精排，是**极度匹配**用户兴趣的。
    - 用户没点可能只是因为版面有限、精力有限，或者点了更好的。
  - **后果**：如果在召回阶段把这些高度相关的物品当负样本，会造成模型逻辑混乱（Confusion），因为它既学到这东西像正样本（特征相似），由于标签是负，又被强制要求远离，导致模型效果变差。

### 5. 总结：召回模型训练方法论

| 步骤             | 关键动作                      | 逻辑依据                                             |
| :--------------- | :---------------------------- | :--------------------------------------------------- |
| **正样本**       | 点击数据 + 热门降采样         | 消除热度偏差，保护冷门内容                           |
| **负样本(基准)** | 全局随机 / Batch 内负样本     | 覆盖度广，需修正热门物品的采样偏差 (LogQ Correction) |
| **负样本(进阶)** | 排序淘汰数据 (Hard Negatives) | 提升边界区分能力，混合比例约 50%                     |
| **避坑**         | **禁用**曝光未点击数据        | 召回的任务是找相关，不是做最终排序                   |

这套逻辑清晰地界定了召回模型与其他模型的边界，并给出了具体的工程化解决方案（如 $0.75$ 次方经验值、Logit 修正等）。
