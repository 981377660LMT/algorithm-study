这节课讲解双塔模型（two-tower，也叫 DSSM）的线上服务和模型更新。

在开始线上服务之前，需要把物品向量存储到 Milvus、Faiss、HnswLib 这类向量数据库，供最近邻查找（KNN 或 ANN）。当用户发起推荐请求时，用户塔用用户 ID 和用户画像现算一个用户向量，作为 query，去向量数据库中做最近邻查找。

模型需要定期做更新，分为全量更新（天级别）和增量更新（实时）。全量更新会训练整个模型，包括 embedding 和全连接层。而增量更新只需要训练 embedding 层。

---

这节课的内容从“离线训练”跨越到了推荐系统最关键的“工业落地”环节：**线上召回架构**与**模型更新机制**。王树森老师不仅讲了“怎么做”，更解释了背后深层的工程权衡。

以下是对这节课内容的深度逻辑分析与拆解：

### 1. 线上召回架构：非对称设计的工程智慧

在召回阶段，双塔模型的用户塔和物品塔在处理方式上采用了完全不同的策略，这是一种经典的**“空间换时间”**与**“计算换精度”**的非对称设计。

- **物品塔（离线 & 静态）：**
  - **处理方式**：离线计算所有物品向量 -> 存入向量数据库（Milvus/Faiss） -> 构建索引（ANN）。
  - **逻辑依据**：
    1.  **量级巨大**：物品库（如小红书笔记）高达几亿，线上实时计算不仅算力成本无法承受，延迟也是灾难性的。
    2.  **特征稳定**：物品发布后，其内容特征（B）短期内相对固定，不需要频繁重算。
- **用户塔（在线 & 动态）：**
  - **处理方式**：不存储，用户发起请求时 -> 实时调用神经网络计算。
  - **逻辑依据**：
    1.  **量级可控**：每次请求只需计算 1 个用户向量。
    2.  **兴趣多变**：用户的兴趣是流动的（秒级变化）。如果预存向量，就无法捕捉用户上一秒的点赞行为，推荐的时效性会大打折扣。

**一针见血的总结：** 所有的技术选型都是为了解决**“海量候选集检索”**与**“毫秒级实时响应”**之间的矛盾。

---

### 2. 模型更新机制：“全量+增量”的混合策略

推荐系统的灵魂在于“快”和“准”。为了兼顾这两点，工业界采用了一套组合拳。

#### A. 全量更新（基石）

- **频率**：天级别（通常在凌晨）。
- **数据**：昨天全天的数据。
- **操作**：基于前一天的模型参数（Warm Start），跑 **1 个 Epoch**。
- **关键动作**：**Random Shuffle（随机打乱数据）**。
- **产出**：发布新的全套模型参数，并**全量刷新向量数据库中的物品向量**。

#### B. 增量更新 (Online Learning)（补丁）

- **频率**：分钟级/小时级。
- **数据**：实时流式数据（从早到晚的时间序）。
- **操作**：
  - **只更新 Embedding 层**（用户 ID 等）。
  - **锁死全连接层 (MLP)**：为了工程稳定性和速度，不更新深层网络参数。
- **目的**：捕捉用户**几分钟前**的行为产生的最新兴趣（例如刚点了一篇猫咪笔记，马上推猫咪周边）。

---

### 3. 核心难点解析：为什么不能只做增量更新？

这是本节课最精彩的逻辑分析点。很多人会问，既然增量更新最快，为什么还要费力气每天做全量更新？

**根本原因：数据分布偏差（Data Distribution Bias）。**

1.  **时间序数据的偏差**：增量更新的数据是按时间顺序来的（Streaming）。早上的用户行为模式和晚上在大排档撸串时的行为模式截然不同。如果只用最近几十分钟的数据训练，模型会迅速**过拟合**到当前时间段的特定模式，遗忘全局规律。
2.  **随机打乱的必要性**：全量更新强制对一天的数据进行 **Random Shuffle**。这打破了时间相关性，让模型看到的是数据的统计学全貌（无偏估计），从而保证模型参数的稳健性。

**结论**：

- **全量更新**保“下限”和“稳定性”，消除偏差。
- **增量更新**冲“上限”和“时效性”，捕捉热点。

### 4. 总结与避坑指南

| 环节         | 关键动作          | 避坑/注意事项                                      |
| :----------- | :---------------- | :------------------------------------------------- |
| **物品向量** | 离线算好存 DB     | 必须建索引（HNSW 等），否则暴力搜索太慢            |
| **用户向量** | 线上即时算        | 别预存用户向量，否则推荐会“反应迟钝”               |
| **全量训练** | 每天一次，Shuffle | 必须基于昨天的模型继续练，**不要随机初始化**       |
| **增量训练** | 字/分级，流式     | **必须锁住全连接层**，只更 Embedding，防止模型跑飞 |

这节课揭示了推荐系统在算法之外的一面：**强大的系统工程能力**。一个优秀的推荐算法工程师，不仅要懂模型结构，更要懂数据流、懂 Serving 架构、懂偏差消除。

---

- 我能否重新构建架构，使其并行使用 4 个两塔模型，并在其上添加一个 arg-max？ 如果我以这种方式构建，能否可以提高推荐能力，并使 4 个两塔模型关注不同的特性？
  训练和推理要花钱的呀亲……这个得 justify 你这个模型是否比直接把双塔变大的收益高。

- 全量更新以天为单位是否会有以小时做增量更新一样的问题，导致出现对用户的 embeding 出现偏差？如果在一个更大的时间范围内（例如一个月）做一次全量更新，是不是能更准确的反映一个用户？
  机器跑不动啊。一个月的数据得在集群上跑几天才能过 one epoch，时间来不及。

- 所谓”昨天的数据“，应该是昨天为最后一天的数据吧，里面涉及到用户的 last-n 天/次的交互？否则只有 1 天的数据，分布就跟原来模型的数据不一样了
  其实就只有一天的数据。计算资源不足以支持全量数据。
