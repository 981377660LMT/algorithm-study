这节课介绍几种重要性稍低的召回通道。地理位置召回包括 GeoHash 召回和同城召回。作者召回包括关注作者、有交互作者、相似作者。缓存召回是储存精排打分高、而且未曝光的笔记。

---

这份内容是王树森老师针对推荐系统中**“非核心但必要”的召回通道**进行的补充讲解。如果说协同过滤（ItemCF）和双塔模型是推荐系统的“主菜”，那么这节课介绍的**地理位置、作者维度、缓存回收**则是必不可少的“配菜”，它们填补了主流模型难以覆盖的特定场景（LBS、社交关系、计算资源利用）。

以下是对这节课内容的逻辑分析与深度拆解：

### 1. 核心逻辑：为什么需要这些“边缘”召回？

主流召回（如双塔、ItemCF）主要解决**“用户对什么内容感兴趣”**的问题。而本节课介绍的通道解决了三个特殊维度的问题：

1.  **时空维度（LBS）**：解决“用户对身边发生的事情感兴趣”的需求。
2.  **社交/创作维度（Author）**：解决“用户对人的信任和粘性”以及“兴趣泛化”的需求。
3.  **系统效率维度（Cache）**：解决“算力浪费”问题，回收高分但未曝光的资源。

---

### 2. 地理位置召回 (Location-Based Retrieval)

这一类召回的核心在于**牺牲部分个性化，换取地理相关性**。

- **GeoHash 召回**
  - **原理**：利用 GeoHash 算法将二维经纬度转换为字符串（代表地图上的矩形区域）。
  - **索引结构**：`GeoHash -> List<High_Quality_Notes>` (按时间倒排)。
  - **关键策略**：
    - **去个性化**：因为只看位置，不看用户兴趣，所以必须只召回**高热度/高品质**且**最新**的笔记。如果不通过“高品质”筛选，纯地理位置的低质内容会严重损害体验。
    - **兜底逻辑**：既无个性化又无质量保证的笔记会在排序阶段被过滤，因此召回源头必须把控质量。
- **同城召回**
  - **原理**：粒度比 GeoHash 更粗，扩大到城市级别。覆盖“当前所在城市”和“常驻/生活过的城市”。

### 3. 作者维度召回 (Author-Based Retrieval)

这一类召回利用了社交属性和创作者粘性，逻辑链条从**显性关注**延伸到**隐性兴趣**。

- **关注作者召回 (Follow)**
  - **性质**：**强社交信号**。这是带有社交属性的产品（如小红书、微博）的基础。
  - **链路**：`User ID -> Followed Authors -> Latest Notes`。
- **有交互的作者召回 (Interaction)**
  - **性质**：**弱社交信号/隐性兴趣**。用户没关注，但有点赞/收藏/转发，说明对该作者的内容风格认可。
  - **场景**：用户可能不关注垂直领域（如玉石加工），但喜欢看该作者的具体内容。
  - **维护**：索引 `User ID -> Interacted Authors` 需要定期清理（如只保留最近交互），防止兴趣漂移。
- **相似作者召回 (Look-alike/Author CF)**
  - **性质**：**兴趣泛化/扩展**。
  - **计算**：基于粉丝重合度计算作者相似性（类似 ItemCF）。
  - **链路**：`User -> Interested Authors (Followed/Interacted) -> Similar Authors -> Latest Notes`。
  - **规模**：$N$ 个感兴趣作者 $\times K$ 个相似作者，能显著扩充召回候选集。

### 4. 缓存召回 (Cache Retrieval)

这是工程架构上的优化，目的是**减少算力浪费（Computational Waste）**并提升系统效率。

- **背景痛点**：
  - 推荐链路是漏斗状：召回 -> 粗排 -> 精排 -> 重排（Re-rank）。
  - **精排（Fine Ranking）** 是最耗时的步骤，打分了前几百篇，结果重排阶段为了多样性（DPP 算法）只选了几十篇曝光。
  - **浪费**：那些精排分很高（Top 50）但运气不好没被选中的笔记，如果直接丢弃，之前的计算资源就白费了。
- **解决方案**：
  - 建立用户维度的缓存队列，存入“高精排分、未曝光”的笔记。
  - 在下一次刷新时，不需重新计算，直接从缓存取回作为一路召回。
- **退场机制 (Eviction Policy)**：
  - **曝光即删**：避免重复展示。
  - **FIFO/LRU**：缓存满（如 100 篇）则挤出最早的。
  - **次数限制**：尝试被召回 N 次（如 10 次）仍未曝光，说明可能有其他问题，丢弃。
  - **时间限制 (TTL)**：如超过 3 天，丢弃（保证优鲜度）。
  - **策略调整**：可对低曝光笔记延长缓存时间，给予更多流量扶持。

---

### 5. 总结与代码化梳理

我们可以将这节课的召回策略整理为以下伪代码逻辑，以便在开发中理解其位置：

```python
# 推荐系统召回层伪代码逻辑示意

def get_recall_candidates(user_id, user_location, user_history):
    candidates = []

    # 1. 核心召回 (之前课程内容)
    # candidates.extend(item_cf_recall(user_id))
    # candidates.extend(two_tower_recall(user_id))

    # 2. 地理位置召回 (补全本地生活/周边需求)
    # 逻辑：位置 -> GeoHash -> 热门且新的笔记
    current_geohash = encode_geohash(user_location)
    candidates.extend(get_high_quality_notes_by_geohash(current_geohash, limit=50))
    # city_id = get_city(user_location)
    # candidates.extend(get_notes_by_city(city_id, limit=50))

    # 3. 作者维度召回 (社交与兴趣延伸)
    # A. 关注的作者
    followed_authors = get_user_follows(user_id)
    for author in followed_authors:
        candidates.extend(get_latest_notes(author, limit=5))

    # B. 有交互但未关注的作者 (隐性兴趣)
    interacted_authors = get_recent_interacted_authors(user_history)
    for author in interacted_authors:
        candidates.extend(get_latest_notes(author, limit=5))

    # C. 相似作者 (兴趣扩展)
    # 逻辑：User -> Author -> Similar Author -> Note
    for author in (followed_authors + interacted_authors):
        similar_authors = get_similar_authors_index(author, top_k=5)
        for sim_author in similar_authors:
             candidates.extend(get_latest_notes(sim_author, limit=2))

    # 4. 缓存召回 (系统效率优化)
    # 逻辑：复用上次精排被淘汰的高分笔记
    cached_notes = get_user_cache(user_id)
    # 应用退场规则(TTL, 曝光次数等)
    valid_cached_notes = apply_eviction_rules(cached_notes)
    candidates.extend(valid_cached_notes)

    return candidates
```

**一针见血的结论**：
这节课展示了工业界推荐系统的**完整性**。只有核心召回通道是不够的，必须配合 LBS 捕捉场景，配合 Graph/Author 捕捉社交，配合 Cache 提升系统效能，才能构成一个无死角的推荐系统。
