这节课的内容是通过改进粗排和精排模型涨指标。这节课的内容分 5 部分：

1. 精排模型的改进
2. 粗排模型的改进
3. 用户行为序列建模
4. 在线学习
5. 老汤模型

---

这节课是“推荐系统涨指标”系列的**排序模型篇**。
王树森老师深入剖析了在**精排 (Fine Ranking)** 和 **粗排 (Pre-Ranking)** 阶段，工业界有哪些实用的提分手段。
他还重点讨论了两个极具工业特色的难题：**在线学习的资源瓶颈**以及**“老汤模型”的迭代困境**。

以下是对这节课内容的深度逻辑拆解与总结：

### 1. 精排模型 (Fine Ranking) 的改进

精排模型通常是“基座 (Base) + 多目标头 (Heads)”的结构。

- **基座 (Base) 改进**：
  - **加宽加深**：全连接网络通常参数量很小（相比 Embedding 层），适当加宽加深可以缓解 Underfitting。
  - **特征交叉**：引入 Bilinear, LHUC 等自动特征交叉结构。
  - **特征工程**：引入统计特征、多模态内容特征（BERT/ResNet 提取的向量）。
- **多目标预估 (Multi-Task heads) 改进**：
  - **增加新目标**：除了点击、点赞，还可以预测评论、转发、完播、进入主页等。这是涨指标最直接的手段。
  - **模型结构**：尝试 MMoE 或 PLE（虽然经验表明不一定总有效）。
  - **Debias**：消除 Position Bias（位置偏差）。_注：王老师提到虽然理论上应该有效，但工业界实践中很难成功。_

### 2. 粗排模型 (Pre-Ranking) 的改进

粗排面临的挑战是打分量大（比如 5000 个），单个物品算力预算低（是精排的 1/10）。

- **模型结构升级**：
  - 从双塔模型升级为 **三塔模型 (Three-Tower)**，这是目前工业界比较先进且有效的做法。
- **粗精排一致性 (Consistency) —— _提分利器_**：
  - **原理**：利用精排模型（Teacher）来蒸馏粗排模型（Student）。
  - **Pointwise 蒸馏**：Label = Mean(用户真实行为 $y$, 精排预测分 $p$)。比只用真实 Label 效果更好。
  - **Pairwise/Listwise 蒸馏**：使用 Learning to Rank (LTR)，让粗排去拟合精排产生的**序 (Order)**，而不是具体的绝对分数。
  - _风险_：如果精排挂了或有 Bug，会污染粗排的训练数据，导致“一损俱损”。

### 3. 用户行为序列建模 (User Behavior Sequence)

这是目前排序侧涨指标最核心的赛道。

- **演进路线**：Avg Pooling $\to$ DIN (Attention) $\to$ **SIM (Search-based Interest Model)**。
- **核心方向**：**增加序列长度 (Long Sequence)**。
  - 从几十个扩展到几千甚至上万个历史行为。
- **工程难题与解法**：
  - 直接把 100 万个历史行为塞进 Attention 计算量扛不住。
  - **解法 (Hard Search)**：先通过“类目”或“内容聚类 ID”进行快速筛选，把 100 万个行为过滤到几千个相关行为，再喂给 Attention 层。

### 4. 在线学习 (Online Learning)

- **机制**：
  - T-2 天数据全量训练 $\to$ T-1 天全天分钟级增量更新 $\to$ T-0 实时推理。
- **代价**：**算力吞噬者**。
  - 每个实验组都需要一套独立的在线学习资源链。
  - _后果_：如果公司资源有限（比如只有 4 套资源），线上只能同时跑 2 个新模型实验。**在线学习虽然能大幅涨指标，但会严重降低模型迭代和 AB 测试的并发效率（被锁死）**。

### 5. “老汤模型”问题 (The "Old Soup" Model Problem)

这是一个非常经典且让人头疼的实际问题。

- **现象**：线上的老模型（Base）跑了半年，看了海量数据，像一锅熬了很久的老汤，极其“鲜美”。新设计的模型（New），结构更优，但因为只能训练几十天，效果往往打不过老模型。
- **痛点**：
  1.  **无法判断**：新结构到底好不好？（没打过是因为结构差，还是因为练得不够久？）
  2.  **难以追平**：如何让新模型快速赶上老模型的水平？
- **解决方案**：
  1.  **公平对比 (For Validation)**：新老模型都**随机初始化**，只跑 N 天（如 10 天）。如果此时新模型优于老模型，说明结构确实有效。
  2.  **加速追赶 (For Production)**：
      - **复用参数**：Embedding 层不要随机初始化，直接继承老模型的 Embedding（它是知识的结晶）。
      - **蒸馏 (Distillation)**：在训练初期，用老模型作为 Teacher 指导新模型收敛。

### 总结

这节课揭示了工业界排序模型优化的真相：
不是一味地堆 Transformer 层数，而是做 **粗精排一致性蒸馏**、**超长用户序列工程优化**，以及解决 **新老模型迭代的“卡脖子”问题**。
