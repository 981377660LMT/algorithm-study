这节课继续讲解推荐系统中的用户行为序列建模。这节课介绍 SIM 模型，它的主要目的是保留用户的长期兴趣。SIM 的原理是对用户行为序列做快速筛选，缩短序列长度，使得 DIN 可以用于长序列。

---

这节课的内容从 **短期兴趣 (Short-term Interest)** 的 DIN 模型，升级到了 **长期兴趣 (Long-term Interest)** 的 **SIM (Search-based Interest Model)**。

核心逻辑在于：用户的最近行为（DIN 处理的 LastN, $N \approx 50 \sim 100$）固然重要，但用户过去半年甚至一年的历史行为（$N \approx 1000 \sim 10000$）里其实藏着更深层、更稳定的兴趣模式。然而，由于计算资源有限，我们没法直接把这么长的序列塞进 DIN。SIM 就是用来解决这个矛盾的。

以下是对这节课内容的深度逻辑拆解与总结：

### 1. 核心矛盾：序列长度 vs 计算量

- **DIN 的瓶颈**：DIN 的 Attention 计算复杂度是 $O(N)$。序列越长，计算越慢。
  - 如果 $N=50$，DIN 没问题。
  - 如果 $N=10000$（长序列），DIN 直接卡死，或者使得线上 latency 无法接受。
- **长序列的价值**：实验证明，序列越长，模型见得越多，推荐越准。因为长序列能捕捉到那些“`低频但稳定”`的兴趣（比如你一年只会在春天买一次露营装备，如果只看最近 50 次点击，这个兴趣就被丢掉了）。
- **SIM 的思路**：**两阶段处理 (Two-Stage)**。
  - 既然 10000 个里只有 100 个是和当前候选物品相关的，那就先把这 9900 个无关的快速扔掉，只留 100 个给 Attention 算。

### 2. SIM 架构拆解

#### Stage 1: GSU (General Search Unit) —— 快速海选

目的：从 $N$（长序列，如 10000）中筛选出 Top $K$（短序列，如 100）个最相关的物品。

- **Hard Search (硬查找)**：**工业界主流选择**。
  - _逻辑_：基于规则。最常用的是 **类目匹配 (Category Match)**。
  - _例子_：候选物品是“AJ 球鞋”（类目：鞋靴）。直接去 10000 个历史记录里把所有“鞋靴”类目的记录捞出来。
  - _优点_：极快，可以用倒排索引实现，几乎没有计算量。
- **Soft Search (软查找)**：
  - _逻辑_：基于向量检索 (ANN)。
  - _例子_：把历史记录都转成向量建索引。拿候选物品的向量去搜最近的 Top K。
  - _优缺点_：精度高一点，但工程太复杂，资源消耗大。除非基建极强，否则不推荐。

#### Stage 2: ESU (Exact Search Unit) —— 精细加权

目的：对筛选出来的 Top $K$ 个物品，进行精细的 Attention 计算。

- _逻辑_：其实就是一个标准的 **DIN**。
- _输入_：Hard Search 出来的 $K$ 个物品。
- _计算_：拿着 Candidate Item 去和这 $K$ 个物品算 Attention Score，然后加权求和。

### 3. 关键 Trick：时间信息 Embedding

(类比：位置编码 Positional Encoding)

这是 SIM 模型中一个非常重要的细节。

- **为什么需要？**
  - 在 DIN (短序列) 中，物品都是最近发生的，时间差异不大，可以忽略。
  - 在 SIM (长序列) 中，捞出来的 Top K 物品，可能一个是昨天的，一个是去年的。显然昨天的参考价值更大。因此**必须要告诉模型这个行为发生了多久**。
- **怎么做？**
  - 计算时间差 $\Delta t = \text{Now} - \text{Time}_{action}$。
  - **离散化 (Discretization)**：把时间差分桶（如 <1h, 1~24h, 1~7d, ... >1y）。
  - **Embedding**：把分桶后的 ID 转成一个向量 $E_{time}$。
  - **Concat**：把 Item Embedding 和 Time Embedding 拼起来 ($[E_{item}, E_{time}]$)，作为一个整体输入 Attention 层。

### 4. 总结与评价

| 特性           | DIN (短序列)            | SIM (长序列)                       |
| :------------- | :---------------------- | :--------------------------------- |
| **序列长度**   | $N \approx 50 \sim 100$ | $N \approx 1000 \sim 10000+$       |
| **核心机制**   | Attention               | **Search (Retrieval) + Attention** |
| **计算复杂度** | $O(N)$                  | $O(1)$ (Hard Search 索引) + $O(K)$ |
| **时间特征**   | 通常不需要              | **必须需要** (区分近期与远期行为)  |
| **工程难度**   | 中                      | 高 (需要维护长序列存储和索引系统)  |

**一针见血的结论**：
SIM 的本质就是**用“搜索引擎”的思路做“推荐系统”的历史行为提取**。不仅快，而且能把过去很久以前的沉睡兴趣给“搜”出来，从而大幅提升推荐的惊喜度和精准度。这是目前大厂（阿里、美团、小红书等）处理长用户行为序列的标准范式。
