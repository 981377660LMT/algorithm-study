## 通信

### 核心观点

在构建分布式系统时，**并发（Concurrency）** 是一个无法回避的核心问题，因为程序需要同时处理多个独立的任务（如响应多个客户端请求，或向多个服务器发起请求）。Go 语言通过其内建的 **Goroutine（轻量级线程）** 和 **RPC（远程过程调用）** 库，为解决并发问题提供了两种主要的设计模式。第一种是传统的**共享内存/锁（Shared Memory/Locks）**模型，即多个 Goroutine 通过访问同一个内存区域（如一个共享的 map）来协作，但必须使用**互斥锁（Mutex）**来防止因并发读写导致的**竞争条件（Race Condition）**。第二种是 Go 更推崇的**通信/通道（Communicating/Channels）**模型，其哲学是“不要通过共享内存来通信，而要通过通信来共享内存”，即不同的 Goroutine 之间不直接访问共享数据，而是通过一个名为**通道（Channel）**的管道来安全地传递信息。虽然这两种模式都能解决问题，但通道模型往往能带来更清晰、更不易出错的代码结构，因为它从根本上避免了对锁的复杂管理。

---

### 逻辑梳理

#### 1. 为何需要并发？为何选择 Go？

- **并发的必然性：** 分布式系统天然是并发的。
  - **I/O 并发：** 一个程序需要同时等待多个网络回复或磁盘操作。使用线程（Goroutine）可以让一个任务在等待时，其他任务继续执行，从而提高效率。
  - **多核并行：** 利用多核 CPU 同时执行计算密集型任务，提升吞吐量。
- **Go 的优势：**
  - **Goroutine:** 极度轻量级的线程，创建成千上万个也很廉价。
  - **内置 RPC:** 方便地实现跨机器通信。
  - **内存安全与垃圾回收 (GC):** 杜绝了 C++ 中常见的内存错误。特别是 GC 与线程的结合，极大地简化了共享对象的生命周期管理，程序员无需再手动进行引用计数。

#### 2. 并发编程的核心挑战

当多个线程同时运行时，主要会遇到三大挑战：

1.  **竞争条件 (Race Condition):**

    - **问题：** 当多个线程在没有同步的情况下读写共享数据时，最终结果取决于它们执行的精确时序，这会导致不可预测的、错误的行为。经典的例子是 `n = n + 1`，这个操作并非原子性的，它实际上是“读-改-写”三步。两个线程可能同时读取旧值，导致其中一次递增丢失。
    - **Go 的工具：** Go 提供了 `-race` 标志，这是一个强大的动态分析工具，可以在程序运行时检测出潜在的竞争条件，即使它们在那次运行中没有真正引发错误。

2.  **协调 (Coordination):**

    - **问题：** 线程之间需要有意地互相等待。例如，主线程需要等待所有它派生的工作线程都完成后才能退出。
    - **Go 的工具：** `sync.WaitGroup` 是一个常用的协调原语。通过 `Add()` 增加等待任务的数量，`Done()` 表示一个任务完成，`Wait()` 会阻塞直到所有任务都完成。

3.  **死锁 (Deadlock):**
    - **问题：** 两个或多个线程形成一个等待环路，每个线程都在等待另一个线程释放它所持有的资源（通常是锁）。例如，线程 A 持有锁 L1 并等待 L2，而线程 B 持有锁 L2 并等待 L1。

#### 3. 两种并发模式的实战对比：Web 爬虫

讲座通过实现一个并发 Web 爬虫，生动地对比了两种模式。

- **模式一：共享内存 + 锁 (Shared Memory with Mutexes)**
  - **思路：** 所有 Goroutine 共享一个全局的 `map`，用于记录哪些 URL 已经被抓取过。
  - **实现：**
    1.  在访问这个共享的 `map` 之前，必须先获取一个**互斥锁 (Mutex)**。
    2.  检查 `map` 中是否存在该 URL，如果不存在，则将 URL 加入 `map`。
    3.  释放锁。
    4.  为从页面中解析出的每个新 URL 启动一个新的 Goroutine。
  - **关键点：** 检查和更新 `map` 的操作（“读-改-写”）必须被包裹在同一个锁的保护之下，成为一个**原子操作**，否则就会产生竞争条件。
