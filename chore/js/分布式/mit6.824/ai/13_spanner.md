## Spanner

### 核心观点

Spanner 是一个革命性的全球分布式数据库，它通过两大核心创新，成功地将**强一致性事务**的便利性与**全球分布式系统**的可扩展性和容错性结合起来。

1.  对于**读写事务**，它采用“**2PC over Paxos**”的架构，即用 Paxos/Raft 协议将两阶段提交中的协调者和参与者都复制成高可用的集群，从而解决了传统 2PC 致命的“单点阻塞”问题。
2.  对于**只读事务**，它利用一种名为 **TrueTime** 的高精度、带不确定性边界的时钟服务，结合**快照隔离（Snapshot Isolation）**，实现了无锁、可从任意本地副本读取的、极其高效的只读操作，同时依然保证了严格的**外部一致性（External Consistency）**。

Spanner 的设计哲学是：接受读写事务的高昂代价以换取其正确性和可用性，同时通过创新的时间同步机制，将性能优化的重点放在了占据绝大多数的只读事务上。

---

### 逻辑梳理

#### 1. Spanner 的目标与架构

- **目标：** 在全球分布的数据上提供可序列化和外部一致性的事务。
- **架构：**
  - **分片 (Sharding):** 数据按 Key 范围切分成多个分片，以实现并行处理和高吞吐。
  - **复制 (Replication):** 每个分片的数据被复制到多个地理位置分散的数据中心，形成一个独立的 **Paxos/Raft 集群**。
  - **目的：** 复制是为了**容错**（数据中心故障）和**低延迟**（数据靠近用户）。

#### 2. 读写事务：如何解决 2PC 的阻塞问题

- **方法：** 采用标准的**两阶段锁 (2PL)** + **两阶段提交 (2PC)**。
- **核心创新 (2PC over Paxos)：**
  - 协议中的**协调者**和**参与者**不再是单个服务器，而是它们各自对应的 **Raft 集群**。
  - 当一个事务需要跨越多个分片时，客户端会选择其中一个分片的 Raft 集群作为**协调者**。
  - 所有的协议状态（如 `prepare`, `commit`）都会作为一条日志记录被提交到相应 Raft 集群的**多数派**副本中。
  - **效果：** 如果协调者集群的 Leader 崩溃，Raft 协议会自动选举出新的 Leader。新 Leader 可以从复制的日志中恢复事务状态，并继续执行 2PC 协议。这从根本上消除了因协调者单点故障而导致的无限期阻塞问题。
- **代价：** 依然非常慢，涉及多轮跨数据中心的通信和多次 Raft 共识。

#### 3. 只读事务：如何实现高效与强一致的统一

这是 Spanner 最具突破性的部分，其目标是避免 2PL 和 2PC 的高昂开销。

- **基本思想：快照隔离 (Snapshot Isolation)**

  - 为每个事务分配一个**时间戳 (Timestamp)**。
  - 数据库保留数据的**多个版本**，每个版本都关联着写入它的事务的时间戳。
  - 只读事务在它自己的时间戳上读取数据“快照”，即读取所有版本时间戳小于等于自身时间戳的最新数据。
  - **效果：** 这保证了事务的所有读操作都发生在一个逻辑上的时间点，避免了“不可重复读”等问题，从而实现了**可序列化**。

- **核心挑战：如何保证外部一致性？**

  - **外部一致性要求：** 如果事务 T1 在真实时间上先于 T2 完成，那么 T2 必须能看到 T1 的写入。
  - **问题根源：**
    1.  **时钟不同步：** 如果 T2 的时钟慢了，它可能会被分配一个比 T1 更早的时间戳，从而读到 T1 之前的数据，违反外部一致性。
    2.  **副本延迟：** T2 可能从一个尚未同步到 T1 写入的本地副本读取数据。

- **Spanner 的解决方案：TrueTime API + 两条规则**

  1.  **TrueTime API：** Spanner 不依赖完美的时钟同步，而是使用一个能返回**时间区间 `[earliest, latest]`** 的 API。它保证真实的“墙上时间”一定落在这个区间内。这个不确定性区间（`epsilon`）非常小（通常是几毫秒）。

  2.  **规则一：为事务选择时间戳 (Start Rule)**

      - 读写事务在**开始提交时**，将其时间戳 `ts` 设为 `TT.now().latest`。
      - 只读事务在**开始时**，将其时间戳 `ts` 设为 `TT.now().latest`。
      - **目的：** 选择区间的右边界，确保时间戳**不早于**事务开始的真实时间。

  3.  **规则二：提交等待 (Commit Wait Rule)**
      - 一个读写事务在选择了时间戳 `ts` 后，**必须等待**，直到 `TT.now().earliest > ts`。
      - **目的：** 这是最关键的一步。它强制事务的**物理提交时刻**一定晚于其**逻辑时间戳**。这意味着，当一个事务提交完成时，它的时间戳 `ts` 已经**确定无疑地成为了过去时**。

- **如何协同工作以保证外部一致性：**

  - 假设事务 T1 在真实时间 `t_commit` 完成提交。根据“提交等待”规则，我们知道 `t_commit > T1.ts`。
  - 事务 T2 在真实时间 `t_start` 开始，且 `t_start > t_commit`。
  - T2 会选择自己的时间戳 `T2.ts = TT.now().latest`。因为 `t_start` 时的真实时间已经大于 `T1.ts`，所以 `TT.now()` 区间一定在 `T1.ts` 之后，因此可以保证 `T2.ts > T1.ts`。
  - 由于 `T2.ts > T1.ts`，根据快照隔离的机制，T2 在读取数据时必然能看到 T1 的写入。
  - **结论：** “提交等待”规则巧妙地利用了 TrueTime 的不确定性，将逻辑时间戳与真实世界的时间顺序绑定，从而在没有锁的情况下保证了外部一致性。

- **如何解决副本延迟问题 (Safe Time)：**
  - 当只读事务向本地副本请求时间戳 `ts` 的数据时，该副本必须确保自己已经应用了所有时间戳 `<= ts` 的日志。如果还没有，它必须等待，直到从 Leader 那里同步到足够新的日志。这保证了即使从本地副本读取，也不会读到过时的数据。
