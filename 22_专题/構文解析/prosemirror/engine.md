好的，我们来详细拆解这份“手写正则引擎”的代码。它完美地复刻了经典的正则表达式编译理论，整个过程分为四个核心阶段：

1.  **词法分析 (Lexing)**: 将输入的字符串表达式分解成一个个有意义的“标记 (Token)”。
2.  **语法分析 (Parsing)**: 将标记流转换成一个能体现语法结构的“抽象语法树 (AST)”。
3.  **NFA 构造**: 将 AST 转换成一个“非确定性有限自动机 (NFA)”。
4.  **DFA 构造**: 将 NFA 转换成一个高效的“确定性有限自动机 (DFA)”，也就是我们最终的 `MatchState`。

---

### 阶段一：词法分析 (Lexing) - `TokenStream`

**目标**：将字符串 `"a (b|c)+"` 变成一个标记数组 `["a", "(", "b", "|", "c", ")", "+"]`。

`TokenStream` 类就是我们的词法分析器。

```typescript
class TokenStream<T extends Term> {
  pos = 0
  tokens: string[]

  constructor(readonly string: string, readonly terms: { readonly [name: string]: T }) {
    // 核心逻辑在这里
    this.tokens = string.split(/\s*(?=\b|\W|$)/)
    // ... 清理首尾的空字符串 ...
  }
  // ...
}
```

- **`constructor`**: 它的核心是 `string.split(/\s*(?=\b|\W|$)/)`。这是一个精巧的正则表达式：
  - `\s*`: 匹配任意数量的空白字符。
  - `(?=...)`: 这是一个**正向先行断言 (Positive Lookahead)**。它匹配一个位置，这个位置后面必须跟着括号里的内容，但它**不消耗**这些内容。
  - `\b`: 单词边界。
  - `\W`: 非单词字符（例如 `(`, `|`, `*` 等）。
  - `$`: 字符串结尾。
  - **组合起来**：这个 `split` 的意思是“在每个空白字符、以及每个单词边界或特殊符号**之前**的位置进行分割”。这确保了像 `(b|c)` 这样的字符串会被正确地分割成 `["(", "b", "|", "c", ")"]`，而不是错误地粘连在一起。
- **`next`**: 返回当前将要处理的标记。
- **`eat(tok)`**: 如果 `next` 标记是我们期望的 `tok`，就“吃掉”它（即 `pos++`）并返回 `true`。这是语法分析器向前推进的主要方式。

---

### 阶段二：语法分析 (Parsing) - `parse...` 函数

**目标**：将标记流 `["a", "(", "b", "|", "c", ")", "+"]` 转换成一个树状结构（AST），以反映运算的优先级和嵌套关系。

这个过程采用的是经典的**递归下降解析 (Recursive Descent Parsing)** 方法。我们为语法的每个层级编写一个函数。

1.  **`parseExpr` (处理 `|` 选择)**

    - 这是最低优先级的操作。它会不断调用 `parseExprSeq` 来获取由更高优先级操作组成的部分，然后用 `|` 将它们连接成一个 `choice` 节点。

2.  **`parseExprSeq` (处理连接)**

    - 处理并列的序列，例如 `a b c`。它会不断调用 `parseExprSubscript` 来获取带后缀的表达式，然后将它们组成一个 `seq` 节点。

3.  **`parseExprSubscript` (处理 `*`, `+`, `?`, `{...}` 后缀)**

    - 处理量词。它首先调用 `parseExprAtom` 获取一个基础单元（如 `a` 或 `(...)`），然后检查后面是否跟着 `*`, `+`, `?` 等，并相应地将基础单元包裹成 `star`, `plus`, `opt` 等节点。

4.  **`parseExprAtom` (处理基础单元)**
    - 这是最高优先级的操作。它处理两种情况：
      - 遇到 `(`：递归调用 `parseExpr` 来解析括号内的所有内容。
      - 遇到名称（如 `a`, `b`）：通过 `resolveName` 在词汇表中查找对应的 `Term` 对象，并创建一个 `name` 节点。

**最终产物 (AST)**：对于 `"a (b|c)+"`，最终生成的 AST 结构大致如下：

```json
{
  "type": "seq",
  "exprs": [
    { "type": "name", "value": { "name": "a" } },
    {
      "type": "plus",
      "expr": {
        "type": "choice",
        "exprs": [
          { "type": "name", "value": { "name": "b" } },
          { "type": "name", "value": { "name": "c" } }
        ]
      }
    }
  ]
}
```

---

### 阶段三：NFA 构造 - `nfa()`

**目标**：将 AST 转换成一个非确定性有限自动机 (NFA)。

**为什么先转成 NFA？** 因为从 AST 直接构造 NFA 非常直观和简单。NFA 允许“空转换”（即不需要消耗任何输入就能跳转到下一个状态），这使得连接不同的表达式部分变得容易。

- **数据结构**：NFA 被表示为一个图：`NFAEdge<T>[][]`。`nfa[i]` 是状态 `i` 的所有出边（`NFAEdge`）的列表。
- **`compile(expr, from)` 函数**：这是核心的递归函数，它为 AST 中的每种节点类型定义了如何生成对应的 NFA 片段。
  - **`choice` (选择 `|`)**: 从同一个 `from` 状态为每个选项 `expr` 创建一个分支。所有分支的终点都连接到同一个后续状态。
  - **`seq` (序列)**: 将前一个表达式的终点连接到后一个表达式的起点。
  - **`star` (`*`)**: 创建一个循环。可以跳过它（空转换），也可以进入它，在里面转任意圈，然后出来。
  - **`plus` (`+`)**: 类似 `star`，但必须至少进入循环一次。
  - **`name`**: 创建一个消耗对应 `term` 的边。

---

### 阶段四：DFA 构造 - `dfa()`

**目标**：将 NFA 转换成一个确定性有限自动机 (DFA)，即我们的 `MatchState`。

**为什么需要 DFA？** NFA 的匹配过程可能需要回溯，效率较低。而 DFA 对于任何一个状态和任何一个输入，都有**唯一**的下一状态，匹配过程非常快（一个简单的循环）。

这个过程使用的是经典的**子集构造法 (Subset Construction)**。

- **核心思想**：DFA 的每一个状态，都对应 NFA 中的一个**状态集合**。
- **`nullFrom(nfa, node)`**: 这是一个关键的辅助函数。它计算从 NFA 的 `node` 状态出发，只通过“空转换”能够到达的所有状态的集合。这被称为 **ε-闭包 (epsilon closure)**。
- **`explore(states)` 函数**:
  1.  `states` 参数是 NFA 的一个状态集合，它将成为 DFA 的一个新状态。
  2.  **计算出边**：遍历 `states` 集合中的每一个 NFA 状态。对于每个状态的**非空**出边（例如，消耗 `a` 到达状态 `j`），我们计算 `j` 的 `nullFrom` 集合。我们将所有消耗 `a` 能到达的 `nullFrom` 集合合并起来，这就构成了 DFA 在消耗 `a` 之后要进入的下一个 NFA 状态集。
  3.  **创建 DFA 状态**：为当前的 `states` 集合创建一个新的 `MatchState` 实例。
      - `validEnd` 的判断：如果这个 `states` 集合中包含了 NFA 的最终状态，那么这个 DFA 状态就是一个合法的终点。
  4.  **递归构建**：对于上一步计算出的每个新的 NFA 状态集，递归调用 `explore` 来为它们创建对应的 DFA 状态，并连接边。
  5.  **缓存 (`labeled`)**：使用一个对象 `labeled` 来缓存已经创建的 DFA 状态（以 NFA 状态集的字符串作为键），避免重复构建，并处理图中的循环。

**最终产物 (DFA)**：一个由 `MatchState` 实例组成的、高度优化的图。`compile` 函数返回这个图的起始状态。当你调用 `startState.matchTerm(A)` 时，它只是在 `next` 数组中进行一次查找，然后返回下一个 `MatchState`，这是一个 O(N) 操作（N 是出边的数量），非常高效。
