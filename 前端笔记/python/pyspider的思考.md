如何构建一个通用的垂直爬虫平台？
爬虫主要分为两大类：

通用爬虫（搜索引擎）
垂直爬虫（特定领域）

我们的爬虫平台包括的模块有：

配置服务：包括抓取页面配置、解析规则配置、数据清洗配置
采集服务：只专注网页的下载，并配置防爬策略:发现 pyspider 符合我们的需求
代理服务：持续提供稳定、可用的代理 IP
清洗服务：针对爬虫采集到的数据进行进一步清洗和规整
数据服务：爬虫数据的展示，以及业务系统对接

最后，分享一下做爬虫时候的一些技巧，从整体上来说，其实核心思想就一个：尽可能地模拟人的行为。
主要包括以下几方面：

随机 UserAgent 模拟不同的客户端（github 有 UserAgent 库，非常全面）
随机代理 IP（高匿代理 + 代理调度策略）
Cookie 池（针对需要登录的采集行为）
JavaScript 渲染页面（使用无界面浏览器加载网页获取数据）
验证码识别（OCR、机器学习）

当然，做爬虫是一个相互博弈的过程，有时没必要硬碰硬，遇到问题换个思路也是一种解决办法。例如，对方的移动客户端防抓厉害，那去看一看对方的 PC 站可不可以搞一下？WAP 端是否可以尝试一下？在有限的成本拿到数据才是爬虫的目的。
