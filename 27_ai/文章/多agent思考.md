1. planact 和 多 agent 联系与区别
   在模型工程（AI Engineering）领域，**Plan-and-Act (PlanAct)** 和 **Multi-Agent (多智能体)** 是两种不同的架构模式，它们解决的是不同复杂度的问题。

   简单来说：**PlanAct 是“一个人的工作流”，而 Multi-Agent 是“一个团队的协作流”。**

   以下是详细的联系与区别：

   ### 1. 核心概念定义

   - **Plan-and-Act (PlanAct)**

     - **定义**：通常指**单体智能体（Single Agent）**的一种行为模式。模型在执行任务前，先生成一个计划（Plan），然后一步步执行（Act），并根据执行结果调整下一步。
     - **典型代表**：ReAct (Reason + Act)、AutoGPT（早期版本）、BabyAGI。
     - **核心逻辑**：感知 -> 思考(规划) -> 行动(调用工具) -> 观察结果 -> 循环。
     - **关注点**：如何让**一个** LLM 能够逻辑严密地完成长链条任务。

   - **Multi-Agent (多智能体)**
     - **定义**：由**多个**拥有不同角色、技能或目标的智能体组成的系统。它们通过特定的通信协议协作来解决复杂问题。
     - **典型代表**：MetaGPT、AutoGen、CrewAI、ChatDev。
     - **核心逻辑**：角色定义(Role) -> 协作流程(SOP) -> 消息路由(Communication) -> 任务分发与合并。
     - **关注点**：如何组织**一群** LLM（通常扮演不同角色，如产品经理、架构师、测试员）来分工协作。

   ### 2. 主要区别

   | 维度           | PlanAct (单体循环)                                                           | Multi-Agent (群体协作)                                                                               |
   | :------------- | :--------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------- |
   | **执行主体**   | **单个** LLM 实例（或同一个 System Prompt）。                                | **多个** LLM 实例（不同的 System Prompt/角色）。                                                     |
   | **上下文窗口** | 容易遇到上下文（Context Window）爆炸的问题，因为所有步骤都在一个历史记录里。 | 上下文被分散在不同 Agent 之间，每个 Agent 只关注自己的任务，缓解了上下文压力。                       |
   | **能力侧重**   | 侧重于**通用问题解决**能力（Generalist）。                                   | 侧重于**专业分工**（Specialist），每个 Agent 可以在特定领域（如写代码、写文档）做深度优化。          |
   | **纠错机制**   | 依赖模型自我反思（Self-Reflection），容易陷入死循环或幻觉。                  | 依赖**交互纠错**（Peer Review），例如“测试 Agent” 驳回 “开发 Agent” 的代码，类似人类团队的代码审查。 |
   | **复杂度**     | 适合线性、步骤明确的中等复杂度任务。                                         | 适合非线性、极其复杂、需要多视角（如软件开发全流程）的任务。                                         |

   ### 3. 紧密联系

   尽管它们是不同的架构，但它们是**包含与被包含**的关系，或者是**微观与宏观**的关系：

   1. **`PlanAct 是 Multi-Agent 的原子单元`**：

      - 在多智能体系统中，**每一个独立的 Agent 内部通常都在运行一个 PlanAct 循环**。
      - 例如，在 MetaGPT 中，“工程师 Agent” 在接到写代码的任务时，它内部依然是先规划（Plan）代码结构，然后执行（Act）写入文件。

   2. **演进关系**：

      - PlanAct 是 Agent 的基础形态。当单体 PlanAct 无法处理过长的上下文或过于复杂的逻辑分支时，工程师通常会将任务拆解，演进为 Multi-Agent 架构。

   3. **工具使用（Tool Use）的共性**：
      - 两者都高度依赖工具调用（Function Calling）。PlanAct 是自己决定用什么工具；Multi-Agent 可能是 A 让 B 去调用工具，或者 A 把工具作为一种资源传递给 B。

   ### 4. 最佳实践建议（结合你的 workspace）

   在你的 `chat-bot-sdk` 和 `lander-app` 项目中：

   - **何时使用 PlanAct?**

     - 当用户的一个请求可以被明确拆解为 `搜索 -> 总结 -> 回答` 这种线性逻辑时。
     - 例如：你的 `chat-bot-sdk` 中的基础对话机器人，如果集成了 Google Search 或 数据库查询功能，它就是一个典型的 PlanAct 系统。

   - **何时使用 Multi-Agent?**
     - 当你需要处理复杂的业务流，且需要“角色扮演”来保证质量时。
     - 例如：如果 `lander-app` 需要一个功能是“自动生成营销文案并审核合规性”。
       - Agent A (文案写手): 负责创意生成。
       - Agent B (合规审核): 负责检查是否违规。
       - Agent C (排版): 负责格式化。
     - 这种场景下，单体模型很难同时兼顾创意和严谨的合规检查，拆分成两个 Agent 互相博弈效果更好。

   **总结：PlanAct 解决的是“`怎么做`”的问题（执行力），Multi-Agent 解决的是“谁来做”和“怎么配合”的问题（组织力）。**

2. 大多数时候智能体之间其实是有状态依赖的，而不是无状态或者完全共享状态
3. 多 agent 适合读任务
   读写锁，最多一个写，读的子协程可以并发
