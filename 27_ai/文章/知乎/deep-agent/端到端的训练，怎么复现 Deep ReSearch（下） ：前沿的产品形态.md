这篇文章是 Deep Research 复现系列的完结篇（下篇）。在前两篇讨论了基础搜索（Deep Search）和单体 Agent 循环（Jina 模式）的基础上，本篇聚焦于**商业级产品的架构逻辑**以及**模型训练的核心难点**。

以下是对该文章核心内容的深度剖析：

### 1. 架构演进：从“单体循环”到“分治与套娃”

文章指出，单纯依赖 Jina 式的 `Search -> Visit -> Reflect` 循环存在效率低和上下文受限的问题。商业级产品（如 Gemini, Genspark）采用了更高级的架构：

- **最小单元化**：将 Jina 的完整闭环（搜索-阅读-反思-回答）视为一个“最小执行单元”。
- **拆分与套娃 (Split + Nesting)**：
  1.  **Planner（规划者）**：首先调用擅长规划的模型，将大问题拆解为章节或子问题（甚至多级目录）。
  2.  **Parallel Execution（并行执行）**：对每个子章节独立调用“最小执行单元”进行并行研究。
  3.  **Synthesizer（综合者）**：最后由擅长长文本写作的模型汇总生成报告。
- **优势**：解决了长上下文遗忘问题，利用并行计算大幅提升了速度，且实现了模型能力的解耦（规划、搜索、写作各司其职）。

### 2. 竞品技术逆向分析

作者通过观察交互模式，推测了各家产品的技术路径：

- **Genspark**：引入了 `initial_plan` 阶段，支持对多个 Gaps（缺口）进行**并行搜索**。
- **Grok**：流程类似 Genspark，侧重推理和搜索，但似乎缺乏显式的“反思”和“自我评估”环节。
- **Gemini (Google)**：最为成熟。
  - **动态调度**：能智能判断哪些子任务并行，哪些串行。
  - **批判性写作 (Critical Writing)**：在生成报告阶段，不仅是拼接，还会进行自我审查和重写（这也是其耗时较长但质量较高的原因）。

### 3. 工程形态：端到端 vs. 工作流的折中

文章提出了一个关键洞见：目前的 Deep Research 产品并非纯粹的“端到端”（如豆包深度思考那样的单条思维链），而是**端到端与工作流的中间形态**。

- **形态**：类似于“多轮对话系统”。每个 Step 由模型根据上下文决定 Action（工具调用），但整体框架受限于预设的 Plan。
- **设计哲学**：**Less Control, More Tools (适度控制 + 工具赋能)**。
- **理由**：
  - **可控性**：通过强制的 Plan 和 Reflect 环节保证深度。
  - **扩展性**：易于接入各类 MCP（Model Context Protocol）工具。
  - **分工**：允许不同规模和特性的模型协同工作（如小模型规划，大模型推理）。

### 4. 训练的核心：定义问题比解决问题更难

文章最后探讨了最核心的训练问题，指出当前的瓶颈不在于 RL（强化学习）方法本身，而在于**Reward（奖励）的设计**。

- **难点**：Deep Research 是开放性任务，很难量化“好报告”的标准（流畅度 vs. 引用丰富度）。
- **OpenAI 的策略**：
  - **混合数据**：结合“有标准答案的客观任务”和“开放式任务”。
  - **Rubrics (评分规则)**：对于开放任务，使用详细的评分细则，并利用思维链模型作为 Grader（评分器）。
- **训练建议**：
  - **Rule-based Reward**：用于客观任务，提供细粒度信号，防止 Reward Hacking。
  - **Reward Model**：用于开放任务，提供粗粒度信号。
  - **混合训练**：结合上述两者进行 PPO 或其他 RL 训练。

### 总结

复现 Deep Research 的终极形态不仅仅是训练一个超级模型，而是构建一个**多模型协作的系统**。它需要：

1.  **工程上**：实现“规划-并行执行-反思-综合”的流水线。
2.  **算法上**：通过混合规则奖励和模型奖励的 RL，让模型学会“如何做研究”而不仅仅是“如何回答问题”。
