20260209
友商
动态
OpenAI
2月5日，发布GPT-5.3-Codex

- GPT-5.3-Codex 更好的 Token 效率 和更快的推理速度，是此次发布的最大亮点。GPT-5.3-Codex完成相同任务所需的token数量不到 5.2-Codex 的一半，而且每个token的速度提升超过 25%
- GPT-5.3-Codex 是第一个在创造自身过程中发挥关键作用的模型。Codex 团队利用早期版本来调试其自身的训练，管理其自身的部署，并诊断测试结果和评估
- GPT-5.3-Codex现已加入ChatGPT付费计划，覆盖Codex所有应用场景：App、CLI、IDE扩展及Web端
- https://openai.com/index/introducing-gpt-5-3-codex/
  2月2日，推出全新的macOS版Codex应用，大幅提升开发者能力
- Codex app是一个强大的新界面，旨在轻松管理多个智能体、并行运行工作，并与智能体协作完成长时间任务。具体可以做到以下几点：
  - 多任务并行切换，毫不费力：同时调用多个AI智能体开展工作，并通过「工作树」（worktrees）实现变更隔离，互不干扰
  - 创建并调用Skills：将工具和开发规范封装成可复用的能力
  - 设置自动化流程：通过后台定时工作流，把那些重复性的琐事统统交给Codex处理
- https://openai.com/zh-Hans-CN/index/introducing-the-codex-app/
  Anthropic
  2月5日，Claude Opus 4.6发布，在前一代Opus 4.5的基础上，大幅提升了编码技能
- Claude Opus 4.6的规划更缜密，能更持久地执行AI Agent任务，在超大规模代码库中运行也更加可靠
- 在多项基准测试中，Claude Opus 4.6编程实力几乎全方位领先，Gemini 3 Pro、GPT-5.2望尘莫及
- 这款新模型同时在Excel、PPT中的Claude，以及Claude Code、API中同步上线
- 在API上
  - Claude可以用「上下文压缩」来总结其上下文，从而在不触及限制的情况下，执行运行时间更长的任务
  - 引入了「自适应思考」（adaptive thinking）——模型可以根据上下文线索感知何时需要使用扩展思考
  - 以及，全新的Effort（思考力度）控制，让开发者对智能、速度和成本拥有更多掌控权
  - 是首款支持100万Token上下文的Opus级别模型
- https://www.anthropic.com/news/claude-opus-4-6
  代号Fennec的Claude Sonnet 5即将发布
- 多条信息显示，Claude Sonnet 5（代号Fennec）已经存在于谷歌基础设施中，在性能上领先谷歌的「Snow Bunny」整整一代
- 它有100万token上下文窗口，定价比Opus 4.5便宜50%，将直接解决开发者对Opus「太慢、太贵」的核心不满
- 在SWE-Bench上，它的成绩超过80.9%，远超当前目前市面上所有的编程大模型
- https://mp.weixin.qq.com/s/dt0fRBK_WupuhO3ovqeFlA
  阿里
  阿里或将在春节期间推出其新一代旗舰模型 Qwen 3.5
- https://mp.weixin.qq.com/s/2_7QsTow-UrLBhDW72_hpQ
  2月4日，推出 Qwen3-Coder-Next，一款专为编程智能体与本地开发设计的开源权重语言模型
- 该模型基于 Qwen3-Next-80B-A3B-Base 构建，采用混合注意力与 MoE 的新架构，通过大规模可执行任务合成、环境交互与强化学习进行智能体训练，在显著降低推理成本的同时，获得了强大的编程与智能体能力。
- https://mp.weixin.qq.com/s/oBxJiwkqz18lQNNctP4Y1A
  2月2日，阿里官宣千问春节大请客，30亿请大家吃喝玩乐；3日，官宣冠名4大地方卫视春晚
- 从2月6日起，将以「免单」的形式，请全国人民吃喝玩乐，淘宝闪购、飞猪、大麦、盒马、天猫超市、支付宝等全部加入
  - https://mp.weixin.qq.com/s/0xJC1Fnobs5H5P0W7MthZA
- 千问独家冠名了东方卫视、浙江卫视、江苏卫视、河南卫视四大马年春节晚会
  - https://mp.weixin.qq.com/s/yIHJoSONDUwfMOy3HTsgjQ
    月之暗面
    2月3日，推出第二期API充值返券活动
- 持续到 2 月 13 日，充值 1000 元以上即可获赠 20%-30% 的代金券。代金券将在次日发放，有效期 90 天
- https://mp.weixin.qq.com/s/q4qSa8n6wT5JcgDwbxeAew
  MiniMax
  MiniMax 上线了 MiniMax Agent 桌面端和专家 Agent 功能
- 在 Mac/Windows 电脑，我们可以选择本地工作文件夹，让 MiniMax Agent读取、分析和批量处理文件，或者描述任务让 Agent 在浏览器中进行自动处理，像完成点击和提交等操作
- https://agent.minimaxi.com/
  智谱AI
  2月3日，发布并开源GLM-OCR
- 以“小尺寸、高精度”实现文档解析能力新标杆。作为一款轻量的专业级OCR模型，其核心亮点如下：
  - 性能SOTA：以94.6分登顶OmniDocBench V1.5，并在公式识别、表格识别、信息抽取的多项主流基准中均取得SOTA表现
  - 场景优化：专攻真实业务痛点，在手写体、复杂表格、代码文档及印章等高难场景中表现稳健
  - 推理高效：仅0.9B参数规模，支持vLLM、SGLang和Ollama部署，显著降低推理延迟与算力开销，适合高并发与边缘部署
  - 开源易用：同步开源完整SDK与推理工具链，环境依赖简单，支持一行命令快速调用，轻松接入现有业务系统
    https://mp.weixin.qq.com/s/TVanw2YyfxMlzoaOrR-Naw
    更多
    可灵
- 2月4日，正式发布可灵3.0，黑金会员享超前体验权益（仅web端），本次更新涵盖：
  - 视频 3.0——叙事与控制深度进化
  - 视频 3.0 Omni——全能参考，音画合一
  - 图片 3.0——自由创作，质感跃升
  - 图片 3.0 Omni——4K超清叙事感，批量生成
- https://mp.weixin.qq.com/s/eX_H8JICU8RyjpFtLc4lVQ

20260202
友商
动态
OpenAI
1月27日，OpenAI正式祭出新一代科研利器——Prism，由GPT-5.2加持，专为写作和协作而生

- 它是一个基于云的「AI原生」LaTeX工作区，不限项目和协作的人数
- 借助最先进的数学与科学推理模型GPT-5.2，OpenAI将起草、修改、协作和出版准备整合进了一个单一的、基于云端的LaTeX原生工作区
- https://openai.com/prism/

Google
Gemini in Chrome 正式发布

- 所有桌面端Chrome浏览器，正式接入Gemini 3，Gemini 3不再是一个需要单独访问的网页，而是直接「住」进了 Chrome里
- Gemini in Chrome 支持 Connected Apps，可以直接调用 Gmail、Calendar、YouTube、Maps、Google Flights
- 目前，MacOS、Windows和Chromebook Plus上的Chrome，已全部上线新功能
- https://blog.google/products-and-platforms/products/chrome/gemini-3-auto-browse/
  1月29日，Genie 3世界模型，开启公测
- 去年8月，谷歌预告了Genie 3的消息，这款通用世界模型，能生成多样化的交互环境。即使仍在早期阶段，特邀测试者就创造了各种令人惊叹的体验
- 而今天，Project Genie正式向美国Google AI Ultra订阅用户（18 岁以上） 开放试用
- 它是一个由Genie 3、Nano Banana Pro和Gemini驱动的网页应用，整个体验围绕三件事展开——世界草图绘制，世界探索，和世界二创
- https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/

DeepSeek
1月27日，DeepSeek又探索新架构了，开源 DeepSeek-OCR 2

- DeepSeek-OCR 2 通过引入 DeepEncoder V2 架构，实现了视觉编码从「固定扫描」向「语义推理」的范式转变
- 具体来说，该研究的核心创新在于将原本基于 CLIP 的编码器替换为轻量级语言模型（Qwen2-500M），并引入了具有因果注意力机制的「因果流查询」
- https://github.com/deepseek-ai/DeepSeek-OCR-2
  阿里
  阿里或将在春节期间推出其新一代旗舰模型 Qwen 3.5
- https://mp.weixin.qq.com/s/2_7QsTow-UrLBhDW72_hpQ
  2月2日，阿里官宣千问春节大请客，30亿请大家吃喝玩乐
- 2月6日公布细节，从有限的信息看，大概率为千问引导消费的免单活动
- https://mp.weixin.qq.com/s/0xJC1Fnobs5H5P0W7MthZA
  1月30日，正式推出了首个桌面 Agent 工具QoderWork
- Qoderwork 主打零门槛和无需部署。在获得对应文件权限后，用户只需要通过自然语言指令，就可让 AI 直接调用已授权的本地应用，完成从文件整理到内容创作的复杂任务
- 目前 Mac 用户可抢先体验，Windows 版本也将很快上线
- https://www.qoder.com/qoderwork
  1月29日，开源Qwen3-ASR系列模型
- Qwen3-ASR 系列模型包括两个强大且全面的语音识别模型 Qwen3-ASR-1.7B 与 Qwen3-ASR-0.6B，以及一个创新的语音强制对齐模型 Qwen3-ForcedAligner-0.6B
- Qwen3-ASR 系列的语音识别模型支持 52 个语种与方言的语种识别与语音识别。
- https://mp.weixin.qq.com/s/gE0D-oKWQuES31FVriFDrg
  1月28日，开源微调更友好的Z-Image模型
- 模型尺寸为6B，不同于追求极致速度的蒸馏版本，Z-Image 是专为高质量创作与开发者生态设计的非蒸馏图片生成基座模型。
- https://mp.weixin.qq.com/s/ZOtEIXvDUesoPebmWfOocw
  1月26日，正式发布千问旗舰推理模型Qwen3-Max-Thinking
- 该模型总参数量超万亿（1T），预训练数据量高达36T Tokens，是目前阿里规模最大、能力最强的千问推理模型
- 千问新模型通过总参数、强化学习、推理计算的极致规模扩展，实现了性能的大幅飞跃，在多项关键性能基准测试中刷新全球新纪录
- https://mp.weixin.qq.com/s/kkpblUFmiS2WeBUxWQAICw
  月之暗面
  1月27日，发布并开源 Kimi K2.5 模型，带来全新视觉理解、代码和 Agent 集群能力
- 它是 Kimi 迄今最智能的模型，在 Agent、代码、图像、视频及一系列通用智能任务上取得开源 state-of-the-art 表现
- 也是 Kimi 迄今最全能的模型，原生的多模态架构设计，同时支持视觉与文本输入、思考与非思考模式、对话与 Agent 任
- https://mp.weixin.qq.com/s/Bhn43P1GnGXsvsh5MnN47Q
  定价（提供 Turbo 级别速度的同时，大幅降低了价格）
  运营活动（7 天的充值赠送活动）
  MiniMax
  MiniMax 上线了 MiniMax Agent 桌面端和专家 Agent 功能
- 在 Mac/Windows 电脑，我们可以选择本地工作文件夹，让 MiniMax Agent读取、分析和批量处理文件，或者描述任务让 Agent 在浏览器中进行自动处理，像完成点击和提交等操作
- https://agent.minimaxi.com/
  更多
  Clawdbot相关：
- 腾讯
  - 腾讯云率先支持Clawdbot云端极简部署：腾讯只推了轻量应用服务器，都没推自家的MaaS
- 阿里
  - 刚刚，阿里云上线Clawdbot全套云服务！：阿里推了轻量应用服务器/无影云电脑 + 百炼模型
    蚂蚁：
- 蚂蚁旗下的具身智能公司灵波科技开源比肩Genie 3的世界模型 LingBot-World
- https://mp.weixin.qq.com/s/BvS6320C-_A3cOa9dx8ACQ
  Vidu：
- 周一，Vidu 正式开启全球创想周，一连五天，Vidu 更新了主体社区、Q2 参考生 Pro、Vidu Q3，以及 Vidu Agent 1.0 等多款模型和工具
- https://mp.weixin.qq.com/s/JwHBqS5JQ6H-FNV1vHbpZQ
  可灵
- 1月31日， 可灵3.0超前内测中，此次更新一口气带来了图片 3.0、视频 3.0 以及视频 3.0 Omni 三个版本
- https://mp.weixin.qq.com/s/OyfKwvg7A0VP-cFIYzqj4w
  阶跃星辰
- 阶跃也推出了 AI 桌面助手，同样是在 Claude Cowork 爆火的一周之后
- https://www.stepfun.com/download
  清程极智
- 推出AI Ping，7×24小时持续评测的客观性能和模型精度榜单，支持智能路由动态匹配
- https://mp.weixin.qq.com/s/7kl8TExEUfmUnC2qRc2kBg

20260126
重点关注：

- 新模型重点关注
  - 谷歌 D4RT（4D 世界模型），速度较 SOTA 快 18-300 倍，Veo 3.1支持4K竖屏直出，开源TranslateGemma，支持 55 种语言 + 多模态图像文本翻译，移动端可部署
  - 智谱 GLM-Image，文字渲染开源 SOTA，尤其擅长汉字生成，GLM-4.7-Flash，30B总参3B激活，相同尺寸模型取得开源SOTA分数，其MaaS平台免费调用
  - 阿里开源Qwen3-TTS全系列模型；美团开源LongCat-Flash-Thinking-2601，引入了重思考模式
- 应用侧重点关注
  - 苹果宣布与Google达成多年期战略合作，下一代苹果基础模型将基于Gemini模型及云技术构建
  - OpenAI低调发布了翻译产品ChatGPT Translate
  - 开源AI 助手 Clawdbot 空前爆火，一天涨星 9k，当前21.2k Star
  - 阿里千问大版本更新，深度整合电商、本地生活业务，实现从“聊天”到“办事”的转变
  - 元宝推出春节特别运营活动，打开元宝APP一键预约分10亿现金红包
    友商
    动态
    OpenAI
    1月24日，奥特曼预告一周后，OpenAI将陆续释放与Codex相关的一系列新能力
- 奥特曼表示，它们已经十分强大，甚至危险
- 强大到可以在数秒内定位人类多年未发现的安全缺陷，危险到同样能被用来复现历史上几乎所有的网络攻击
- 因此，这些模型的网络安全风险评级，将首次达到「高」（High）级别，再往上就是最高的「关键」（Critical）等级了
- 而OpenAI也不得不对这些模型严加防范，组织用户利用它们实施网络犯罪，比如抢银行，窃取资金等等
- https://x.com/sama/status/2014733975755817267
  OpenAI低调发布了翻译产品ChatGPT Translate
- 近日，OpenAI首次挑战谷歌翻译，一款名为ChatGPT Translate的独立翻译工具，低调上线了。OpenAI 几乎没有任何公开宣传
- 该工具支持超过 50 种语言，基础界面与谷歌翻译高度相似，但在功能逻辑上，ChatGPT翻译引入了生成式AI的核心优势，最大亮点在于翻译后的「二次加工」能力：用户可以通过预设的提示词选项，一键调整译文的语气，如「更流利」、「商务正式」、「儿童易懂」或「学术风格」，从而实现针对不同受众的精准表达。
- 然而，作为初版产品，它目前在功能完整性上仍落后于谷歌，暂不支持文档、网页及手写翻译、图片翻译功能。
- https://chatgpt.com/zh-Hans-CN/translate/
  Google
  1月22日，谷歌 DeepMind 发布 4D世界模型 D4RT，比现有 SOTA技术快了 18 到 300 倍
- 谷歌 DeepMind 发布 D4RT（Dynamic 4D Reconstruction and Tracking），彻底颠覆了动态 4D 重建范式。它抛弃了复杂的传统流水线，用一个统一的「时空查询」接口，同时搞定全像素追踪、深度估计与相机位姿。
- 不仅精度屠榜，速度更比现有 SOTA 快出 300 倍。这是具身智能与自动驾驶以及 AR 的新基石，AI 终于能像人类一样，实时看懂这个流动的世界
- https://deepmind.google/blog/d4rt-teaching-ai-to-see-the-world-in-four-dimensions/
- https://d4rt-paper.github.io/
  1月15日，开源TranslateGemma模型，支持55种语言，12B参数超越27B基线，手机端轻松运行
- 基于Gemma 3，谷歌发布了开源翻译模型TranslateGemma：
  - 支持55种语言，并在近500种附加语言对上进行了训练，以供进一步研究
  - 效率出色：12B模型超越了27B基线模型，在参数数量不到一半的情况下实现了更优的性能
  - 保留多模态能力：能够翻译图像中的文本，而无需特定的多模态训练
  - 灵活的部署选项：4B适用于移动设备/边缘设备，12B适用于消费级笔记本电脑，27B适用于云GPU/TPU
- https://blog.google/innovation-and-ai/technology/developers-tools/translategemma/

1月13日，谷歌Veo 3.1终于迎来重磅升级，角色0变形，4K竖屏直出引爆AI短视频革命

- 这一次，谷歌特别优化了移动端体验。只需上传一些「素材图片」（ingredient images），就能轻松创作出更有趣、更有创意、画质极佳的视频：
  - Veo 3.1「素材生视频」，一致性超强
  - 支持原生竖屏输出（肖像模式）
  - 业界领先的1080p、4K超分辨率
- 增强版Veo 3.1「素材生视频」和原生竖屏格式支持正陆续向Flow、Gemini API、Vertex AI和Google Vids推送。其中，1080p和4K分辨率选项也已在Flow、API和Vertex AI上可用。
- https://blog.google/innovation-and-ai/technology/ai/veo-3-1-ingredients-to-video/
  Anthropic
  1月22日，Anthropic 开源了全新的《Claude 宪法》，可以指导模型，什么是好，什么是坏
- Anthropic 正式公布了一份长达 84 页的特殊文档——《Claude 宪法》（Claude's Constitution）
- 这份文件并非通常意义上的技术白皮书或用户协议，而是一份直接面向 AI 模型本身「撰写」的价值观宣言
- 这份文件不仅以知识共享（CC0）协议向全球开源，更重要的是，它被设定为 Claude 行为的终极权威，它不仅指导 Claude 如何回答问题，更定义了它是谁，它该如何看待自己，以及它应该如何在这个充满不确定性的世界中自处
- https://www.anthropic.com/news/claude-new-constitution
  DeepSeek
  1月20日，DeepSeek Github的一个存储库进行更新，引用了一个全新的「model 1」模型，疑似为春节前发布的新模型
- 在DeepSeek的开源项目FlashMLA库代码片段明确引用了「MODEL1」，并且伴随针对KV缓存的新优化，和576B步幅的稀疏FP8解码支持
- FlashMLA是DeepSeek为Hopper架构GPU（如H800）优化的MLA（Multi-head Latent Attention）解码内核
- 在推理层代码中提及新模型ID，往往意味着该新模型（代号为Model1）将继续复用或改进现有的MLA架构
- https://github.com/deepseek-ai
- https://mp.weixin.qq.com/s/h80fcYkTMX6BN_bQlAUNZA

1 月 12 日，梁文锋署名的DeepSeek新论文又来了。这一次，他们提出全新的Engram模块，解决了Transformer的记忆难题，让模型容量不再靠堆参数

- 这一次，他们联手北大直接瞄准了「记忆」，是Transformer最致命的关键难题
- 如今，MoE成为大模型主流架构，但本质仍是Transformer，因其缺少原生「知识查找」机制，很多检索能力被迫用大量计算去模拟。
- 33页论文中，团队提出了 MoE 互补的「条件记忆」稀疏轴，并通过一种全新的Engram模块去实现：将经典哈希N-gram嵌入现代化，提供近似O(1)的确定性知识查找。
- 论文地址：https://github.com/deepseek-ai/Engram/blob/main/Engram_paper.pdf
- https://mp.weixin.qq.com/s/ZdZzksl3iJyUHn9W-6nv5Q
  阿里
  1月22日，Qwen3-TTS全家桶开源上线
- Qwen3-TTS是由Qwen开发的一系列功能强大的语音生成，全面支持音色克隆、音色创造、超高质量拟人化语音生成，以及基于自然语言描述的语音控制
- Qwen3-TTS 多码本全系列模型均已开源，包含1.7B和0.6B两种尺寸，1.7B可以达到极致性能，具有强大的控制能力，0.6B均衡性能与效率。模型覆盖 10 种主流语言（中文、英文、日语、韩语、德语、法语、俄语、葡萄牙语、西班牙语、意大利语）及多种方言音色，满足全球化应用需求
- https://mp.weixin.qq.com/s/96-RgV4jAimmvREYaM9N3Q
  1月15日，千问大版本更新：买东西、点外卖，追求有用，而不是仅娱乐
- 正式上线不到 2 个月的千问 App，进行了上线以来最大规模的一次版本更新。这次更新分为两大方向：
  - 生活，千问主聊天界面接入了阿里业务。淘宝闪购、支付宝、淘宝、飞猪、高德 5 个业务第一批接入。这些功能是 15 日开放测试，几天后就会全量开放。淘票票和大麦等阿里其他业务也将在后续接入
  - 办事，千问 App 首页左下角上线了 “胶囊” 形式的 “任务助理”，能够处理复杂任务，需要像人一样完成多步骤的工作，包括但不限于打电话订餐厅、调研报告、处理财务文件、开发网站等， 目前该功能采用定向邀测
- https://mp.weixin.qq.com/s/ar7GIHUWGNyWjolYLqUmkg
  1月14日，通义 DeepResearch 团队联合高德开源了 ArenaRL，专为开放域智能体设计的对比式强化学习方法
- ArenaRL 要解决的核心问题是：在没有标准答案的复杂任务中，如何让智能体持续进化？
- 核心技术突破速览：
  - 范式转变：从“打分”到“排序”，创新性地引入锦标赛机制。
  - 高效赛制：独创 “种子单败淘汰赛”，以线性计算复杂度逼近理想评估效果。
  - 过程评估：不仅比结果，更评估思维链逻辑与工具调用的合理性。
- 为了全面评估 ArenaRL 的效果，通义在Open-Travel（复杂出行规划）、Open-DeepResearch（深度信息检索）以及通用写作三大类任务上进行了系统评测
- https://mp.weixin.qq.com/s/A5rw5CXZiXpx-2aLi_80wg

智谱AI
1月20日，GLM-4.7-Flash正式发布并开源

- GLM-4.7-Flash是一个混合思考模型，总参数量为30B，激活参数量为3B
- GLM-4.7-Flash将替代GLM-4.5-Flash，在智谱开放平台BigModel.cn上线，并供免费调用
- 在SWE-bench Verified、τ²-Bench等主流基准测试中，GLM-4.7-Flash的综合表现超过gpt-oss-20b、Qwen3-30B-A3B-Thinking-2507，在相同和近似尺寸模型系列中取得开源SOTA分数
- https://mp.weixin.qq.com/s/JDyyRbMmSLDDGuepJ-Y56w
  1月14日，智谱联合华为开源新一代图像生成模型GLM-Image
- 模型基于昇腾Atlas 800T A2设备和昇思MindSpore AI框架完成从数据到训练的全流程，是首个在国产芯片上完成全程训练的SOTA多模态模型
- GLM-Image采用自主创新的「自回归+扩散解码器」混合架构，实现了图像生成与语言模型的联合，是我们面向以Nano Banana Pro为代表的新一代「认知型生成」技术范式的一次重要探索
- 文字渲染开源SOTA：在CVTG-2K（复杂视觉文本生成）和LongText-Bench（长文本渲染）榜单获得开源第一，尤其擅长汉字生成任务。
- 高性价比与速度优化：API调用模式下，生成一张图片仅需0.1元，速度优化版本即将更新
- https://mp.weixin.qq.com/s/bMxg8o8iWV1jXwkV-baFcA

GLM-Image在文字渲染的权威榜单中达到开源SOTA水平
更多
Runway

- 更新Gen-4.5，真正实现电影级可控
- https://mp.weixin.qq.com/s/GmQw8u3AHWKg_peu5lCxrA
  Clawdbot
- GitHub 上一款 AI 助手 Clawdbot 空前爆火，一天涨星 9k Star，当前21.2k
- Clawdbot = 带了双手的 Claude + 住在你硬盘里的贾维斯
- https://github.com/clawdbot/clawdbot
  腾讯
- 元宝推出春节特别运营活动，打开元宝APP，一键预约分10亿现金红包
- https://mp.weixin.qq.com/s/v3ocA1cnuQhkRzP_WMBqeg
  百川智能
- 1月13日，发布并开源全球最强医疗模型 Baichuan-M3，在全球最权威的医疗 AI 评测 HealthBench 中以 65.1 分的综合成绩位列全球第一
- https://mp.weixin.qq.com/s/pFIjeFbHtewWTAHL14eaXw
  美团
- 1月15日，美团重磅更新LongCat-Flash-Thinking-2601，拥有 5600 亿个参数，引入了重思考模式（Heavy Thinking Mode），能够同时启动 8 路思考并最终总结出一个更全面、更可靠的结论
- https://mp.weixin.qq.com/s/4CWGglF95Knyrc-ERzgI2w
  苹果
- 1月12日，苹果宣布与Google达成多年期战略合作，下一代苹果基础模型将基于Gemini模型及云技术构建。同时，今年即将发布的新版AI Siri将由Google提供技术支持
- https://blog.google/company-news/inside-google/company-announcements/joint-statement-google-apple/
  20260119
  友商
  动态
  OpenAI
  OpenAI低调发布了翻译产品ChatGPT Translate
- 近日，OpenAI首次挑战谷歌翻译，一款名为ChatGPT Translate的独立翻译工具，低调上线了。OpenAI 几乎没有任何公开宣传
- 该工具支持超过 50 种语言，基础界面与谷歌翻译高度相似，但在功能逻辑上，ChatGPT翻译引入了生成式AI的核心优势，最大亮点在于翻译后的「二次加工」能力：用户可以通过预设的提示词选项，一键调整译文的语气，如「更流利」、「商务正式」、「儿童易懂」或「学术风格」，从而实现针对不同受众的精准表达。
- 然而，作为初版产品，它目前在功能完整性上仍落后于谷歌，暂不支持文档、网页及手写翻译、图片翻译功能。
- https://chatgpt.com/zh-Hans-CN/translate/
  Google

1月15日，开源TranslateGemma模型，支持55种语言，12B参数超越27B基线，手机端轻松运行

- 基于Gemma 3，谷歌发布了开源翻译模型TranslateGemma：
  - 支持55种语言，并在近500种附加语言对上进行了训练，以供进一步研究
  - 效率出色：12B模型超越了27B基线模型，在参数数量不到一半的情况下实现了更优的性能
  - 保留多模态能力：能够翻译图像中的文本，而无需特定的多模态训练
  - 灵活的部署选项：4B适用于移动设备/边缘设备，12B适用于消费级笔记本电脑，27B适用于云GPU/TPU
- https://blog.google/innovation-and-ai/technology/developers-tools/translategemma/

1月13日，谷歌Veo 3.1终于迎来重磅升级，角色0变形，4K竖屏直出引爆AI短视频革命

- 这一次，谷歌特别优化了移动端体验。只需上传一些「素材图片」（ingredient images），就能轻松创作出更有趣、更有创意、画质极佳的视频：
  - Veo 3.1「素材生视频」，一致性超强
  - 支持原生竖屏输出（肖像模式）
  - 业界领先的1080p、4K超分辨率
- 增强版Veo 3.1「素材生视频」和原生竖屏格式支持正陆续向Flow、Gemini API、Vertex AI和Google Vids推送。其中，1080p和4K分辨率选项也已在Flow、API和Vertex AI上可用。
- https://blog.google/innovation-and-ai/technology/ai/veo-3-1-ingredients-to-video/
  DeepSeek
  1 月 12 日，梁文锋署名的DeepSeek新论文又来了。这一次，他们提出全新的Engram模块，解决了Transformer的记忆难题，让模型容量不再靠堆参数
- 这一次，他们联手北大直接瞄准了「记忆」，是Transformer最致命的关键难题
- 如今，MoE成为大模型主流架构，但本质仍是Transformer，因其缺少原生「知识查找」机制，很多检索能力被迫用大量计算去模拟。
- 33页论文中，团队提出了 MoE 互补的「条件记忆」稀疏轴，并通过一种全新的Engram模块去实现：将经典哈希N-gram嵌入现代化，提供近似O(1)的确定性知识查找。
- 论文地址：https://github.com/deepseek-ai/Engram/blob/main/Engram_paper.pdf
- https://mp.weixin.qq.com/s/ZdZzksl3iJyUHn9W-6nv5Q
  阿里
  1月14日，通义 DeepResearch 团队联合高德开源了 ArenaRL，专为开放域智能体设计的对比式强化学习方法
- ArenaRL 要解决的核心问题是：在没有标准答案的复杂任务中，如何让智能体持续进化？
- 核心技术突破速览：
  - 范式转变：从“打分”到“排序”，创新性地引入锦标赛机制。
  - 高效赛制：独创 “种子单败淘汰赛”，以线性计算复杂度逼近理想评估效果。
  - 过程评估：不仅比结果，更评估思维链逻辑与工具调用的合理性。
- 为了全面评估 ArenaRL 的效果，通义在Open-Travel（复杂出行规划）、Open-DeepResearch（深度信息检索）以及通用写作三大类任务上进行了系统评测
- https://mp.weixin.qq.com/s/A5rw5CXZiXpx-2aLi_80wg

1月15日，千问大版本更新：买东西、点外卖，追求有用，而不是仅娱乐

- 正式上线不到 2 个月的千问 App，进行了上线以来最大规模的一次版本更新。这次更新分为两大方向：
  - 生活，千问主聊天界面接入了阿里业务。淘宝闪购、支付宝、淘宝、飞猪、高德 5 个业务第一批接入。这些功能是 15 日开放测试，几天后就会全量开放。淘票票和大麦等阿里其他业务也将在后续接入
  - 办事，千问 App 首页左下角上线了 “胶囊” 形式的 “任务助理”，能够处理复杂任务，需要像人一样完成多步骤的工作，包括但不限于打电话订餐厅、调研报告、处理财务文件、开发网站等， 目前该功能采用定向邀测
- https://mp.weixin.qq.com/s/ar7GIHUWGNyWjolYLqUmkg
  智谱AI
  1月14日，智谱联合华为开源新一代图像生成模型GLM-Image
- 模型基于昇腾Atlas 800T A2设备和昇思MindSpore AI框架完成从数据到训练的全流程，是首个在国产芯片上完成全程训练的SOTA多模态模型
- GLM-Image采用自主创新的「自回归+扩散解码器」混合架构，实现了图像生成与语言模型的联合，是我们面向以Nano Banana Pro为代表的新一代「认知型生成」技术范式的一次重要探索
- 文字渲染开源SOTA：在CVTG-2K（复杂视觉文本生成）和LongText-Bench（长文本渲染）榜单获得开源第一，尤其擅长汉字生成任务。
- 高性价比与速度优化：API调用模式下，生成一张图片仅需0.1元，速度优化版本即将更新
- https://mp.weixin.qq.com/s/bMxg8o8iWV1jXwkV-baFcA

GLM-Image在文字渲染的权威榜单中达到开源SOTA水平
更多
百川智能

- 1月13日，发布并开源全球最强医疗模型 Baichuan-M3，在全球最权威的医疗 AI 评测 HealthBench 中以 65.1 分的综合成绩位列全球第一
- https://mp.weixin.qq.com/s/pFIjeFbHtewWTAHL14eaXw
  美团
- 1月15日，美团重磅更新LongCat-Flash-Thinking-2601，拥有 5600 亿个参数，引入了重思考模式（Heavy Thinking Mode），能够同时启动 8 路思考并最终总结出一个更全面、更可靠的结论
- https://mp.weixin.qq.com/s/4CWGglF95Knyrc-ERzgI2w
  苹果
- 1月12日，苹果宣布与Google达成多年期战略合作，下一代苹果基础模型将基于Gemini模型及云技术构建。同时，今年即将发布的新版AI Siri将由Google提供技术支持
- https://blog.google/company-news/inside-google/company-announcements/joint-statement-google-apple/
  20260112
  重点关注：
- 新模型重点关注
  - 预计DeepSeek春节前后发布V4模型，内部测试显示其代码能力卓越；阿里推出的Qwen3-VL-Embedding在MMEB-V2上达到SOTA，开源的 Qwen-Image-2512在AI Arena处于第一梯队；蚂蚁开源100B参数医疗SOTA模型
- 创业公司瞄准RL
  - 潞晨云开放兼容 Tinker 的 Serverless 精调 SDK，并支持按Token计费，降低RL应用门槛；Mind Lab新推出的MinT平台实现CPU环境即可支持万亿参数模型高效训练，比Tinker更早实现了 1T LoRA-RL，支持K2、Qwen3-VL等开源模型
    友商
    动态
    英伟达
    1月5日，黄仁勋CES放出大杀器：下一代Rubin架构推理成本降10倍
- 在拉斯维加斯 CES 2026 展会现场，老黄分享了下一代加速计算与人工智能将如何变革每一个行业，并一一介绍了英伟达在芯片、人工智能模型、开源开放等领域的最新进展，主要包括如下：
  - 下一代 Rubin 平台，六款全新芯片，一台划时代 AI 超算，大幅缩短训练时间，降低推理 Token 成本
  - 全新的视觉 - 语言 - 动作模型（VLA）——Alpamayo 1
  - 面向物理 AI 的新开放模型、框架和 AI 基础设施
- https://mp.weixin.qq.com/s/uQCugka35P32-JxklLi3ag
  Anthropic
  1月9日，Claude Code2.1新版本更新
- 2.1主要更新： Skills系统全面升级、会话传送功能、更智能的权限管理、Shift+Enter终于可用、多语言响应
- https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md
- https://mp.weixin.qq.com/s/93WmfW8SYfJRTGLASpupug
  DeepSeek
  1 月 9 日，《The Information》报道，DeepSeek 计划于 2 月推出聚焦编程能力的新一代 V4 模型
- DeepSeek 内部员工进行的测试显示，V4 在代码相关任务上的表现，可能超过 Anthropic 的 Claude 以及 OpenAI 的 GPT 系列等竞争对手
- 此外，最新的 V4 模型在处理和理解，超长代码提示（long coding prompts）方面取得了突破，这一能力有望为从事复杂软件项目的开发者带来明显优势
- https://mp.weixin.qq.com/s/TrxLExFaE6-rve8k5WzN5w
  1月6日，DeepSeek悄无声息地把R1的论文更新了，从原来22页「膨胀」到86页
- 这一次的更新，直接将原始论文升级为：一份开源社区完全可复现的技术报告
- 论文中，DeepSeek-R1新增内容干货满满，信息含量爆炸：
  - 精确的数据配方：明确给出数据规模（2.6万道数学题，1.7万条代码），以及具体的创建流程
  - 基础设施说明：vLLM/DualPipe设置的示意图
  - 训练成本拆解：总计约29.4万美元（R1-Zero使用了198小时的H800GPU）
  - 「失败尝试」复盘：深入解释PRM为什么没有成功
  - 模型对比：与DS-V3、Claude、GPT-4o系统性比较（此前只包含o1）
  - 10页安全性报告：详细说明安全评估与风险分析
- 论文地址：https://arxiv.org/abs/2501.12948
  2026新年第一天，DeepSeek发表了梁文锋署名的重磅新论文
- 2026新年第一天，DeepSeek发表了梁文锋署名的重磅新论文，提出了一种名为「mHC（流形约束超连接）」的新架构，在27B参数模型上，仅增加约6.7%的训练时间开销，即可实现显著性能提升
- 论文链接：https://arxiv.org/abs/2512.24880
  阿里
  12月31日，发布并开源 Qwen-Image-2512 ：更细腻，更真实
- 相较于 8 月发布的 Qwen-Image 基础模型，本次聚焦于三大核心能力的飞跃式提升：更真实的人物质感、更细腻的自然纹理、更复杂的文字渲染，让生成的图像无限接近真实世界。
- 在 AI Arena 超过 1 万局的用户盲测中，数据显示 Qwen-Image-2512 在开源模型中表现最优，并在与多款闭源模型的对比中依然展现出显著竞争力
- https://mp.weixin.qq.com/s/XstyCJEsNJ4h4BfcN-nF_Q
  1月8日，Qwen3-VL-Embedding系列上新：探索统一多模态表征与排序
- 推出Qwen家族的最新成员：Qwen3-VL-Embedding和Qwen3-VL-Reranker模型系列。
- 这些模型基于Qwen最近开源的Qwen3-VL模型构建，专为多模态信息检索和跨模态理解场景设计。
- Qwen3-VL-Embedding-8B模型在MMEB-V2上取得了业界领先的结果，超越了所有先前的开源模型和闭源商业服务
  https://mp.weixin.qq.com/s/67WSr8wreKDrY7W4tRsIwA
  腾讯
  1月3日，微信炼出扩散语言模型，实现vLLM部署AR模型3倍加速，低熵场景超10倍
- 腾讯微信 AI 团队提出 WeDLM（WeChat Diffusion Language Model），通过在标准因果注意力下实现扩散式解码，在数学推理等任务上实现相比 vLLM 部署的 AR 模型 3 倍以上加速，低熵场景更可达 10 倍以上，同时保持甚至提升生成质量。
- 项目主页：https://wedlm.github.io
- GitHub：https://github.com/tencent/WeDLM
  更多
  Meta & Manus
- Meta12月30日，以数十亿美元正式收购AI智能体初创Manus，创始人肖弘直接出任Meta副总裁
- https://mp.weixin.qq.com/s/uo87ZcKKJFiVloyD-Vw7Qg
  Google
- 谷歌DeepMind研究员重磅预测刷屏全网：2026年，将会成为「持续学习」之年
- https://mp.weixin.qq.com/s/a4tmYibC6mfNT8xn-DAjYA
  Mind Lab
- 一群由 95 后青年科学家组成的团队做出了足以对标甚至超越 Tinker 的竞品，成为世界第一家能够对标 Thinking Machines Lab 的公司
- 1 月 1 日，他们发布了亮相以来的第一款产品——Mind Lab Toolkit（MinT）。这是一个用 CPU 的机器就能高效训练万亿参数模型的后训练平台，且成本优化了十倍，一天即可轻松完成一轮训练。此外，它比 Thinking Machines 更早实现了 1T LoRA-RL，是业界在万亿参数模型上进行高效强化学习的第一个成果。
- 目前，MinT 已支持 Kimi K2 Thinking（万亿参数级别的 MoE 推理模型）、Qwen3-VL 系列视觉语言模型等前沿开源模型，并全面兼容 Tinker API
- https://mp.weixin.qq.com/s/PF4XVyAq8S-xIBvWyISknw
  Mind Lab 官网：https://macaron.im/mindlab
  相关文档：https://mint.macaron.im/doc
  潞晨云
- 潞晨云微调 SDK 正式开放上线：基于 Thinking Machine Lab 开源的 Tinker SDK 构建，作为国内首个兼容 Tinker 范式且全面开放的 Serverless 微调平台，为复杂昂贵的强化学习提供更具成本优势的工业级解法，推行 “按 Token 计费” 的商业模式，将微调场景的算力服务切分到了最细的颗粒度：
  - 为价值付费： 就像使用推理 API 一样，用户只需为 Prefill (输入)、Sample (推理输出) 和 Train (训练) 产生的有效计算 Tokens 量付费。
  - 其他环节全免费： 本地代码调试、环境配置、数据预处理、模型 Checkpoint 保存…… 这些在传统租卡模式下分秒必争的环节，在潞晨云全部免费。
- https://mp.weixin.qq.com/s/wQMKxRcDTwHSkrYzQBNMDw
  蚂蚁
- 蚂蚁集团联合浙江省卫生健康委正式开源其自研的蚂蚁·安诊儿医疗大模型（AntAngelMed），是迄今为止参数规模最大的开源医疗模型（100B 总参数）
- 在由 OpenAI 主导、全球 262 名医生参与构建的 HealthBench 评测中，AntAngelMed 在 HealthBench 上的评分达到开源模型第一
- https://mp.weixin.qq.com/s/KLZS4AGrnkaqfxUkPNxG0w
  20260105
  友商
  动态
  DeepSeek
  2026新年第一天，DeepSeek发表了梁文锋署名的重磅新论文
- 2026新年第一天，DeepSeek发表了梁文锋署名的重磅新论文，提出了一种名为「mHC（流形约束超连接）」的新架构，在27B参数模型上，仅增加约6.7%的训练时间开销，即可实现显著性能提升
- 论文链接：https://arxiv.org/abs/2512.24880
  阿里
  12月31日，发布并开源 Qwen-Image-2512 ：更细腻，更真实
- 相较于 8 月发布的 Qwen-Image 基础模型，本次聚焦于三大核心能力的飞跃式提升：更真实的人物质感、更细腻的自然纹理、更复杂的文字渲染，让生成的图像无限接近真实世界。
- 在 AI Arena 超过 1 万局的用户盲测中，数据显示 Qwen-Image-2512 在开源模型中表现最优，并在与多款闭源模型的对比中依然展现出显著竞争力
- https://mp.weixin.qq.com/s/XstyCJEsNJ4h4BfcN-nF_Q
  腾讯
  1月3日，微信炼出扩散语言模型，实现vLLM部署AR模型3倍加速，低熵场景超10倍
- 腾讯微信 AI 团队提出 WeDLM（WeChat Diffusion Language Model），通过在标准因果注意力下实现扩散式解码，在数学推理等任务上实现相比 vLLM 部署的 AR 模型 3 倍以上加速，低熵场景更可达 10 倍以上，同时保持甚至提升生成质量。
- 项目主页：https://wedlm.github.io
- GitHub：https://github.com/tencent/WeDLM
  更多
  Meta & Manus
- Meta12月30日，以数十亿美元正式收购AI智能体初创Manus，创始人肖弘直接出任Meta副总裁
- https://mp.weixin.qq.com/s/uo87ZcKKJFiVloyD-Vw7Qg
  Google
- 谷歌DeepMind研究员重磅预测刷屏全网：2026年，将会成为「持续学习」之年
- https://mp.weixin.qq.com/s/a4tmYibC6mfNT8xn-DAjYA
  Mind Lab
- 一群由 95 后青年科学家组成的团队做出了足以对标甚至超越 Tinker 的竞品，成为世界第一家能够对标 Thinking Machines Lab 的公司
- 1 月 1 日，他们发布了亮相以来的第一款产品——Mind Lab Toolkit（MinT）。这是一个用 CPU 的机器就能高效训练万亿参数模型的后训练平台，且成本优化了十倍，一天即可轻松完成一轮训练。此外，它比 Thinking Machines 更早实现了 1T LoRA-RL，是业界在万亿参数模型上进行高效强化学习的第一个成果。
- 目前，MinT 已支持 Kimi K2 Thinking（万亿参数级别的 MoE 推理模型）、Qwen3-VL 系列视觉语言模型等前沿开源模型，并全面兼容 Tinker API
- https://mp.weixin.qq.com/s/PF4XVyAq8S-xIBvWyISknw
  Mind Lab 官网：https://macaron.im/mindlab
  相关文档：https://mint.macaron.im/doc

20251229
重点关注：

- 友商近期集中发力编码与效率优化：
  - OpenAI 推 GPT-5.2-Codex ，专为复杂的实际软件工程而设计，GPT Image 1.5 实现 “指哪改哪” 与 4 倍提速；Google Gemini 3 Flash 速度超 2.5 Pro 3 倍，部分编程任务反超 Pro 且成本降 75%；智谱 GLM-4.7、MiniMax M2.1、小米 MiMo-V2-Flash 重点强化编码能力，均开源
- 通过限时优惠等手段抢占用户：
  - 谷歌、OpenAI、Anthropic几乎同一时间宣布圣诞限时优惠；Coding Plan，智谱为订阅用户推出「体验卡」礼包，可邀请多位新用户免费体验7天套餐权益，Minimax 首月 9.9 活动返场并推出裂变活动
    友商
    动态
    OpenAI
    12月18日，发布GPT-5.2-Codex ，专为复杂的实际软件工程而设计
- GPT-5.2-Codex 是 GPT-5.2 的升级版本，提高了指令遵循能力、对长远语境的理解能力，它针对 Codex 中的智能体编码进行了进一步优化，包括通过上下文压缩改进长期工作
- GPT-5.2-Codex 在重构和迁移等大型代码变更中表现更佳，在 Windows 环境下性能更优，同时网络安全能力也显著增强
- 与 GPT-5.2 相比，5.2-Codex 在编码任务的词元效率方面也有显著提升，尤其是在中等和高推理水平下
- 在开发者社区人们认为，如果说 Claude Code 擅长「原始代码」，那么 Codex/GPT5.x 在仔细、系统地查找「问题」（无论是代码问题还是数学问题）方面则是无可匹敌的
  https://openai.com/index/introducing-gpt-5-2-codex/
  12月16日，，全新GPT Image 1.5重磅出世，拿下榜单双料第一
- 新一代旗舰图像模型ChatGPT Images正式登场：
  - 精准操控： 指令理解力大幅提升，真正做到「指哪改哪」
  - 细节狂魔： 画面细节保留完整，质感细腻
  - 极速生成： 速度较前代提升了整整4倍
- 在LMArena竞技场上
  - 文生图：以1264 Elo分登顶榜首，力压谷歌Nano Banana Pro（NBP）
  - 图像编辑：chatgpt-image-latest以3分优势险胜NBP夺冠，而GPT Image 1.5紧随其后位列第4
    https://openai.com/index/new-chatgpt-images-is-here/
    Google
    12月17日，Gemini 3 Flash正式发布，速度快3倍，甚至在编程和逻辑推理上反超了Pro大哥
- 3倍于Gemini 2.5 Pro的速度，却拥有超越Pro级的推理能力
- 至此，Gemini 3家族成为完全体：Flash、Pro和Deep Think
- Gemini 3 Flash在某些复杂的Agentic Coding（智能体编程）任务上，甚至直接超越了Gemini 3 Pro，比如Flash在MMMU Pro（多模态理解和推理）上取得了81.2%，反超Gemini 3 Pro的81.0%
- Flash模型已经全面上线Gemini APP、AI Studio、Google Antigravity和Gemini CLI，用户打开Gemini就是默认Gemini 3 Flash版本，免费使用
- API成本来看，相比Gemini 3 Pro，Flash成本直接砍到了四分之一:
- https://blog.google/products/gemini/gemini-3-flash/
  阿里
  12月16日，新一代万相2.6系列模型（文生图、文生视频、图生视频、参考生视频）正式发布
- 该系列模型面向专业影视制作和图像创作场景进行了全面升级，全新的万相2.6是国内首个支持角色扮演功能的视频模型
- 该模型同时支持音画同步、多镜头生成及声音驱动等功能，是全球功能最全的视频生成模型
- 万相官网：https://tongyi.aliyun.com/wan/
- 阿里云百炼API：https://bailian.console.aliyun.com/?tab=model#/model-market/all?providers=wan
  12 月 22 日，阿里宣布开源全新图像生成模型 Qwen-Image-Layered：图片分层 指哪改哪
- 首次在模型内实现 PS 级的图层理解与图像生成
- 新模型采用自研创新架构，可将图片“拆解”成多个图层，可类比为使用 Photoshop 分层作图修图，号称能够实现几乎“零漂移”的 AI 图像精准编辑，彻底解决 AI 生图的一致性难题，加速大模型在专业设计领域的现实落地
- https://mp.weixin.qq.com/s/3yXOWhUuzVajlyySg7J9Hw
  12月25日，全新的Qwen-Image-Edit-2511正式开源：画得像！改得准！
- 2511版本中着重进行了包括一致性提升在内的多项增强，新版本的整体生成质量、尤其是人物生成质量，得到显著提升，主要特性：
  - 提升了角色一致性
  - 集成了Lora能力，例如打光、多场景
  - 提升了工业设计能力
  - 提升了几何推理能力
    https://mp.weixin.qq.com/s/y69Renz5woFTCVIvBIF_hg
    12月26日，Qwen Code 更新至v0.5.0 版本：让 AI 编程跳出命令行
- 在 v0.5.0 版本中，正式推出了 Qwen Code VSCode 插件
- 为应用开发者准备的 TypeScript SDK，让开发者能够以编程的方式集成 Qwen Code 的智能能力
- 开源项目：https://github.com/QwenLM/qwen-code
- 完整介绍：https://mp.weixin.qq.com/s/GScWRLFZDNciEIYXGb9KJQ
  智谱
  12月23日，GLM-4.7上线并开源：更强的编码
- 新版本面向Coding场景强化了编码能力、长程任务规划与工具协同，并在多项主流公开基准测试中取得开源模型中的领先表现
- GLM-4.7在编程、推理与智能体三个维度实现突破：更强的编程能力、前端审美提升、更强的工具调用能力、推理能力提升、通用能力增强
- 目前，GLM-4.7已通过BigModel.cn提供API，并在z.ai全栈开发模式中上线Skills模块，支持多模态任务的统一规划与协作
- 定价
- GLM Coding Plan已更新GLM-4.7
  - 所有购买套餐的用户将获得「体验卡」礼包，可邀请3–7位新用户免费体验7天套餐权益
    https://mp.weixin.qq.com/s/tGKf-PQV9xerbAyRew3MHQ
    Code Arena：全球百万用户参与盲测的专业编码评估系统，GLM-4.7位列开源第一、国产第一，超过GPT-5.2
    在主流基准测试表现中，GLM-4.7的代码能力对齐Claude Sonnet 4.5
    MiniMax
    12月23日，发布并开源MiniMax M2.1
- 在 M2.1 中，MiniMax致力于提升真实世界复杂任务中的表现：重点聚焦于更多编程语言和办公场景的可用性，并在这个领域做到最好的水平
- MiniMax M2.1 具体模型亮点如下：
  - 卓越多编程语言能力：系统性提升了 Rust / Java / Golang / C++ / Kotlin / JavaScript 等语言的能力，覆盖从底层系统到应用层开发的完整链路
  - WebDev 与 AppDev：针对业界普遍存在的移动端开发短板，M2.1 显著加强了原生 Android / iOS 开发能力
  - 复合指令约束提升，办公场景变为可能：作为开源模型中率先系统性引入 Interleaved Thinking 的模型系列，关注模型对“复合指令约束”的整合执行能力
  - 更简洁高效的回复：M2.1 的模型回复以及思维链更加简洁，响应速度显著提升，Token 消耗明显下降
  - 出色的 Agent / 工具脚手架泛化能力：M2.1 在各类编程工具与 Agent 框架中均有出色表现。在 Claude Code、Cline等工具中展现一致且稳定的效果
  - 高质量对话和写作：M2.1 不再只是“代码能力更强”，在日常对话、技术说明与写作场景中，也能提供更具细节与结构性的回答
    定价：
    https://mp.weixin.qq.com/s/QOv0GLq5-T--gKGIF912RQ
    在软件工程相关场景的核心榜单上，尤其是在多语言场景上，接近 Claude Opus 4.5
    在 VIBE 综合榜单中表现卓越，以平均 88.6 分的成绩展现了接近 Claude Opus 4.5 的全栈构建能力
    12月26日，Coding Plan 9.9 返场，邀请赚Credits活动发布
- Coding Plan 首月最低 9.9 活动返场，持续至2026.1.15
- 邀请好友，双向福利：好友得折扣，邀请人赚Credits

小米
12月17日，正式发布并开源新模型 MiMo-V2-Flash

- MiMo-V2-Flash 总参数 3090 亿，活跃参数 150 亿，采用专家混合架构 (MoE)
- 推理速度拉到了 150 tokens/秒，成本压到了每百万 token 输入 0.1 美元、输出 0.3 美元
- 基准测试成绩显示，AIME 2025 数学竞赛和 GPQA-Diamond 科学知识测试中，MiMo-V2-Flash 都排在开源模型前两名
- 编程能力更是亮眼，SWE-bench Verified 得分 73.4%，超越所有开源模型，直逼 GPT-5-High
- 智能体任务，MiMo-V2-Flash 在τ²-Bench 分类得分中，通信类 95.3 分，零售类 79.5 分，航空类 66.0 分，BrowseComp 搜索代理得分 45.4，启用上下文管理后直接飙到 58.3
  http://aistudio.xiaomimimo.com
  http://hf.co/XiaomiMiMo/MiMo-V2-Flash
  http://github.com/XiaomiMiMo/MiMo-V2-Flash/blob/main/paper.pdf
  更多
  谷歌、OpenAI、Anthropic、Cognition，几乎同一时间宣布圣诞限时优惠
- 谷歌：半价 AI Pro，6 人共享
  - 领取地址：https://one.google.com/ai-nye
  - 只限特定地区，只限新用户
- OpenAI：Codex 额度翻倍到元旦
  - Codex 重置所有用户的用量，且 1 月 1 日之前使用限额提升到 2 倍
- Anthropic：Claude Pro 和 Max 额度翻倍一周
  - 12 月 25 日到 31 日，Pro 和 Max 用户的使用额度翻倍（Team 和企业版除外）
  - 和 Codex 一样，活动开始时周限额直接重置
- Cognition：Windsurf SWE-1.5 免费三个月
  - 「Wave 13」更新把 SWE-1.5 对所有用户免费开放三个月

20251222
友商
动态
OpenAI
12月18日，发布GPT-5.2-Codex ，专为复杂的实际软件工程而设计

- GPT-5.2-Codex 是 GPT-5.2 的升级版本，提高了指令遵循能力、对长远语境的理解能力，它针对 Codex 中的智能体编码进行了进一步优化，包括通过上下文压缩改进长期工作
- GPT-5.2-Codex 在重构和迁移等大型代码变更中表现更佳，在 Windows 环境下性能更优，同时网络安全能力也显著增强
- 与 GPT-5.2 相比，5.2-Codex 在编码任务的词元效率方面也有显著提升，尤其是在中等和高推理水平下
- 在开发者社区人们认为，如果说 Claude Code 擅长「原始代码」，那么 Codex/GPT5.x 在仔细、系统地查找「问题」（无论是代码问题还是数学问题）方面则是无可匹敌的
  https://openai.com/index/introducing-gpt-5-2-codex/
  12月16日，，全新GPT Image 1.5重磅出世，拿下榜单双料第一
- 新一代旗舰图像模型ChatGPT Images正式登场：
  - 精准操控： 指令理解力大幅提升，真正做到「指哪改哪」
  - 细节狂魔： 画面细节保留完整，质感细腻
  - 极速生成： 速度较前代提升了整整4倍
- 在LMArena竞技场上
  - 文生图：以1264 Elo分登顶榜首，力压谷歌Nano Banana Pro（NBP）
  - 图像编辑：chatgpt-image-latest以3分优势险胜NBP夺冠，而GPT Image 1.5紧随其后位列第4
    https://openai.com/index/new-chatgpt-images-is-here/
    Google
    12月17日，Gemini 3 Flash正式发布，速度快3倍，甚至在编程和逻辑推理上反超了Pro大哥
- 3倍于Gemini 2.5 Pro的速度，却拥有超越Pro级的推理能力
- 至此，Gemini 3家族成为完全体：Flash、Pro和Deep Think
- Gemini 3 Flash在某些复杂的Agentic Coding（智能体编程）任务上，甚至直接超越了Gemini 3 Pro，比如Flash在MMMU Pro（多模态理解和推理）上取得了81.2%，反超Gemini 3 Pro的81.0%
- Flash模型已经全面上线Gemini APP、AI Studio、Google Antigravity和Gemini CLI，用户打开Gemini就是默认Gemini 3 Flash版本，免费使用
- API成本来看，相比Gemini 3 Pro，Flash成本直接砍到了四分之一:
- https://blog.google/products/gemini/gemini-3-flash/
  阿里
  12月16日，新一代万相2.6系列模型（文生图、文生视频、图生视频、参考生视频）正式发布
- 该系列模型面向专业影视制作和图像创作场景进行了全面升级，全新的万相2.6是国内首个支持角色扮演功能的视频模型
- 该模型同时支持音画同步、多镜头生成及声音驱动等功能，是全球功能最全的视频生成模型
- 万相官网：https://tongyi.aliyun.com/wan/
- 阿里云百炼API：https://bailian.console.aliyun.com/?tab=model#/model-market/all?providers=wan
  小米
  12月17日，正式发布并开源新模型 MiMo-V2-Flash
- MiMo-V2-Flash 总参数 3090 亿，活跃参数 150 亿，采用专家混合架构 (MoE)
- 推理速度拉到了 150 tokens/秒，成本压到了每百万 token 输入 0.1 美元、输出 0.3 美元
- 基准测试成绩显示，AIME 2025 数学竞赛和 GPQA-Diamond 科学知识测试中，MiMo-V2-Flash 都排在开源模型前两名
- 编程能力更是亮眼，SWE-bench Verified 得分 73.4%，超越所有开源模型，直逼 GPT-5-High
- 智能体任务，MiMo-V2-Flash 在τ²-Bench 分类得分中，通信类 95.3 分，零售类 79.5 分，航空类 66.0 分，BrowseComp 搜索代理得分 45.4，启用上下文管理后直接飙到 58.3
  http://aistudio.xiaomimimo.com
  http://hf.co/XiaomiMiMo/MiMo-V2-Flash
  http://github.com/XiaomiMiMo/MiMo-V2-Flash/blob/main/paper.pdf
  快手
  12月18日，可灵 2.6、视频 O1 模型重磅三连更
- 本周更新了
  - 可灵视频O1新增720p模式，首尾帧支持3-10秒自由叙事
  - 可灵视频2.6模型上线音色控制和动作控制功能
  - 会员现每日登录可得随机免费灵感值
- https://mp.weixin.qq.com/s/EN6exaRNYrqUSY8awFiPWw
  20251215
  重点关注：
- OpenAI的GPT-5.2与谷歌Gemini 3 Deep Think在复杂推理上树立新标杆
- 阿里Qwen3-Omni-Flash重磅升级，在全模态交互基础上重点强化语音体验，快手可灵O1系列实践了生成任务的“引擎统一”，行业不再满足于单点突破，而是追求覆盖感知、理解、生成与交互的端到端能力
- AWS推出全生命周期Agent解决方案，智谱GLM-4.6V将Function Call原生融入视觉理解模型，DeepSeek-V3.2实现思考与工具调用的结合，AI正从响应指令的助手，向能自主规划、执行复杂工作流的“虚拟同事”演进
  友商
  动态
  OpenAI
  12月12日，OpenAI发布GPT-5.2的三款模型：GPT‑5.2 Instant、GPT‑5.2 Thinking、GPT‑5.2 Pro
- 作为地表最强通用模型，GPT-5.2专为解决那些让人头秃的「高难度知识型工作」而生，相比上一代，GPT-5.2在通用智能、超长文本理解、Agent工具调用以及视觉能力上，都实现了无死角的全面进化，在OpenAI公布的基准测试中，它几乎对Gemini 3 Pro实现了全方位碾压：
  - SWE-Bench Pro：狂砍55.6%高分
  - LMArena代码竞技场：仅次于Claude Opus 4.5，稳坐全球第二把交椅
  - ARC-AGI-2：GPT-5.2 Pro以52.9%的绝对优势登顶全球第一
  - GDPval：覆盖44种职业知识，表现直接超越人类行业专家
- 除了更强的能力之外，GPT-5.2还有更长的上下文，以及更新的知识：
  - 40万上下文窗口：轻松吞吐超长文本与复杂对话
  - 12.8万最大输出长度：深度长文生成不再中断
  - 知识库更新至2025年8月31日：掌握最新世界动态
  - 推理Token支持：专攻复杂逻辑与多步推理
- 定价：
  - 相比GPT-5/5.1，GPT-5.2的输入输出价格贵了整整40%
  - 输入：$ 1.75/百万tokens，输出：$ 14/百万tokens
    https://openai.com/zh-Hans-CN/index/introducing-gpt-5-2/

12月13日，开源0.4B新模型，基于Circuit Sparsity技术实现，99.9%的权重为0

- 以原生稀疏设计实现功能解耦与可解释性，破解传统大模型黑箱问题，直指 MoE 模型缺陷
- 该模型算力成本极高、能力未达顶尖，MoE 短期仍是主流。未来团队将通过提取稀疏电路、优化训练机制推进技术落地
- https://openai.com/zh-Hans-CN/index/understanding-neural-networks-through-sparse-circuits/
  12月11日，迪士尼与 OpenAI 签署三年授权协议，成为 Sora 首个重大内容授权方
- 用户可使用超过 200 个迪士尼、漫威、皮克斯、星球大战的动画及虚拟角色在 Sora 上生成短视频，ChatGPT Images 也可生成相关图片。精选用户创作内容将登陆 Disney+ 流媒体平台，预计 2026 年初上线
- 迪士尼同时向 OpenAI 投资 10 亿美元并获得额外认股权证，还将成为 OpenAI 大客户：为员工部署 ChatGPT，并利用 API 为 Disney+ 开发新产品
- 值得注意的是，迪士尼同日向谷歌发出停止侵权函，指控其大规模侵犯迪士尼版权
  Google
  12月12日，谷歌推出全新版Gemini Deep Research Agent
- 谷歌对Gemini深度研究进行了重新构想，使其比以往任何时候都更加强大
  - 新版Deep Research Agent基于Gemini 3 Pro构建
  - 通过多步强化学习训练，提高准确性并减少幻觉
  - 它能够处理海量上下文，并提供引用来源验证提出的每一个观点
- 除了Deep Research Agent功能更新，还放出了另外两项全新能力：
  - 开源新网络研究Agent基准DeepSearchQA，验证智能体在网络研究任务中的全面性；
  - 推出全新交互API（Interactions API）
    https://blog.google/technology/developers/deep-research-agent-gemini-api/
    12月14日，谷歌发布Gemini 2.5 Flash Native Audio原生音频模型
- 不仅能保留语调进行实时语音翻译，更让AI在复杂指令和连续对话中像真人一样自然流畅
- 这一更新标志着AI从简单的「文本转语音」跨越到了真正的「拟人化交互」时代
- https://blog.google/products/gemini/gemini-audio-model-updates/
  阿里
  12月9日，发布Qwen3-Omni-Flash升级版 ：音色扩展至 49 种，首次开放人设自定义
- 该模型在 Qwen3-Omni 基础上进行了全面升级，支持文本、图像、音视频的无缝输入与实时流式输出
- 新版本支持 49 种音色——较前代 17 种扩展近 3 倍，首次开放 System Prompt 自定义，可设置人设风格，语速、停顿与韵律自适应调节
- 模型支持 119 种文本语言、19 种语音识别和 10 种语音合成语言
- 在客观性能指标上，Qwen3-Omni-Flash-2025-12-01全模态能力全面跃升，各项能力均显著超越Qwen3-Omni-Flash
  https://mp.weixin.qq.com/s/EIHRk4joXUvznFxTrOTung
  阿里百炼，上周应用广场上架 26 个模板
- 包括ChatPDF 企业知识库问答、拍照搜题、尺码信息提取、真人换模特、AI换装-短剧等
  智谱
  12月8日，发布并开源GLM-4.6V 系列多模态大模型：GLM-4.6V、GLM-4.6V-Flash
- 两款模型：
  - GLM-4.6V（106B-A12B）：面向云端与高性能集群场景的基础版
  - GLM-4.6V-Flash（9B）：面向本地部署与低延迟应用的轻量版
- 作为 GLM 系列在多模态方向上的一次重要迭代，GLM-4.6V 将训练时上下文窗口提升到 128k tokens，在视觉理解精度上达到同参数规模 SOTA，并首次在模型架构中将 Function Call（工具调用）能力原生融入视觉模型，打通从「视觉感知」到「可执行行动（Action）」的链路，为真实业务场景中的多模态 Agent 提供统一的技术底座
- 定价：
  - GLM-4.6V 系列相较于 GLM-4.5V 降价 50%。同时，GLM-4.6V-Flash 免费供大家使用
    https://mp.weixin.qq.com/s/cHV6gDqxQrq34ZxWFDIAzA
    除此之外，智谱多模态开源周还发布了其他模型：
- 12月9日，AutoGLM开源：每台手机，都可以成为AI手机
  - 在“豆包手机”现象级爆火后，迅速推出其32个月的Agent探索结果并开源
  - 业内首个完整开源的 Phone Use 方案，支持微信、淘宝等 50+ 中文 App，可完成外卖点单、机票预订等复杂流程
- 12月10日，开源GLM-ASR系列语音识别模型，并推出基于该系列模型打造的桌面端智谱AI输入法
  - GLM-ASR-2512：全球领先的云端语音识别模型
  - GLM-ASR-Nano-2512：参数量仅1.5B的开源SOTA端侧语音模型
  - 智谱AI输入法：将语音识别与大模型深度融合的桌面端效率工具
- 12月11日，开源 GLM‑TTS 工业级语音合成系统，3秒复刻，情绪万变
  - 只需 3 秒语音样本，GLM‑TTS 即可学习说话人的音色和说话习惯
  - 在通用朗读、情感配音、教育评测、电子书、有声客服等场景中，实现自然流畅、贴近真人的语音
- 12月12日，开源四项面向视频生成的核心技术成果：SCAIL、RealVideo、Kaleido与SSVAE
  - 它们对准当前视频生成领域的三大难点：精细化可控生成、复杂时空结构建模，以及大规模训练成本控制
    20251208
    友商
    动态
    OpenAI
    据The Verge 12月5日爆料，熟悉OpenAI计划的消息人士透露，OpenAI将在下周（12月9号）发布GPT-5.2，首次对Gemini 3做出正面回应
    https://mp.weixin.qq.com/s/VXfyiMdW1bwYt7Uhsi_2lA
    Google
    12月5日，谷歌DeepMind放出了IMO最强金牌模型——Gemini 3 Deep Think
- 在基准测试中，Deep Think全面碾压Gemini 3 Pro，尤其是在HLE上，未用工具拿下了41%高分。同时在ARC-AGI-2上，以45.1%成绩领跑全球
- Gemini 3 Deep Think已在Gemini App上线，所有Ultra用户即可体验
  AWS
  AWS re:Invent 2025 大模型相关概要：
- AI 模型生态建设（以 Amazon Bedrock 为核心）：
  - Amazon Nova 2 系列：Light/Pro/Sonic
  - Nova 2 Omni：业界首个支持文本、图像、视频、音频四模态输入的统一推理模型，可生成文本与图像
  - Nova Forge：引入 “开放训练模型” 概念，允许客户获取 Nova 模型不同训练阶段的Checkpoint ，融合企业私有数据（如产品文档、制造约束）与 AWS 通用数据集，解决传统微调 “灾难性遗忘” 问题；案例：Reddit 融入社区内容安全数据，训练出精准识别违规内容的专属模型，已全面可用
- AI Agent 全生命周期解决方案：
  - 开发者专属 Agent 工具：
    - Kiro Autonomous Agent：“虚拟同事”，可长期运行、自主规划、并行执行复杂开发任务
    - AWS Security Agent：实现 “安全左移”，主动审查设计文档、扫描代码提交漏洞、按需发起一键式渗透测试
    - AWS DevOps Agent：7x24 小时运维 Agent，快速定位告警根因，提出修复与预防建议
  - 企业级 Agent 支撑能力：- AWS Transform Custom：帮助消灭技术债，支持创建自定义代码转换 Agent - Policy in AgentCore：解决 Agent 失控问题，支持用自然语言定义策略，自动转化为安全的 Cedar 策略语言 - AgentCore Evaluations：解决 Agent 不可信问题，提供13 种预置评估器
    完整纪要：2025AWS re:Invent-12.1-5
    DeepSeek
    12月1日，发布 DeepSeek-V3.2 和 DeepSeek-V3.2-Speciale
- DeepSeek-V3.2
  - 目标是平衡推理能力与输出长度，适合日常使用，例如问答场景和通用 Agent 任务场景。在公开的推理类 Benchmark 测试中，DeepSeek-V3.2 达到了 GPT-5 的水平，仅略低于 Gemini-3.0-Pro；相比 Kimi-K2-Thinking，V3.2 的输出长度大幅降低，显著减少了计算开销与用户等待时间
- DeepSeek-V3.2-Speciale
  - 目标是将开源模型的推理能力推向极致，探索模型能力的边界。V3.2-Speciale 是 DeepSeek-V3.2 的长思考增强版，同时结合了 DeepSeek-Math-V2 的定理证明能力。该模型具备出色的指令跟随、严谨的数学证明与逻辑验证能力，在主流推理基准测试上的性能表现媲美 Gemini-3.0-Pro
- 思考融入工具调用
  - 不同于过往版本在思考模式下无法调用工具的局限，DeepSeek-V3.2 是我们推出的首个将思考融入工具使用的模型，并且同时支持思考模式与非思考模式的工具调用。我们提出了一种大规模 Agent 训练数据合成方法，构造了大量「难解答，易验证」的强化学习任务（1800+ 环境，85,000+ 复杂指令），大幅提高了模型的泛化能力

https://huggingface.co/deepseek-ai/DeepSeek-V3.2
https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Speciale
快手
12月1日，可灵AI视频 O1 模型正式上线

- 全球首个统一多模态视频大模型，创新引入MVL（多模态视觉语言）交互架构，单一输入框内无缝融合多种任务
- 打破了传统单一视频生成任务的模型边界，将参考生视频、关键帧生视频、文生视频、视频内容增删、视频修改、视频风格重绘等多个单一任务，彻底融合于同一个全能引擎之中
- https://app.klingai.com/cn/release-notes/vaxrndo66h

12月2日，可灵图片O1模型全新上线

- 模型兼具多模态指令理解能力及丰富的世界知识，可精准响应复杂指令，确保超高图像质量
- 模型具备四大核心优势：特征高度保持让主体元素稳定不偏差，细节修改精准响应让每一处调整都符合预期，风格调性准确把控让画面氛围始终统一，超丰富想象力让创意呈现更具张力，真正实现“所想即所得”
- https://app.klingai.com/cn/release-notes/exv6o36sxa
  12月3日，可灵首个「音画同出」模型可灵视频2.6上线
- 实现单次生成同时产出 画面 + 自然语音 + 匹配音效 + 环境氛围，打通“音”、“画”两个世界
- 在创作流程上，可灵2.6提供两条高效创作路径
  - 文生音画：从一句话到一条完整音视频
  - 图生音画：让静态画面开口说话、动起来
    https://app.klingai.com/cn/release-notes/c605hp1tzd
    12月4日，可灵数字人 2.0 功能正式上线
- 上传角色图·添加配音内容·描述角色表现，三步即可生成
- 本次更新针对旧版，带来了三大突破性改变：表现力拉满、手部及口型精准控制、支持最长5分钟
  https://mp.weixin.qq.com/s/IbHKzsWYyVUxO_flqo400g
  12月5日，可灵 O1 主体库&对比模板全新上线
- 「主体库」，上传多角度参考图，轻松构建专属角色、道具和场景
- 「对比模板」，一键呈现前后效果，Prompt、参考图、主体等所有输入与成品马上呈现，实现 Before & After 高效同框对比
  https://mp.weixin.qq.com/s/mwQgTCt79yU2o78F5BRYgQ
  20251201
  趋势小结：
- 长周期能力持续深化：
  - OpenAI GPT-5.1-Codex-Max 凭 “压缩机制” 实现 24 小时自主开发；Google Gemini 3和Anthropic Claude Opus 4.5均强化长程规划能力，标志着模型从单轮问答向持续自主任务演进
- 多模态成为核心战场：
  - Google Gemini 3 Pro 霸榜多模态基准，推出推理式图像模型Nano Banana Pro；阿里6B生图模型Z-Image以小博大，夸克AI眼镜正式面世，核心战场已逐步迈向复杂场景的视觉-语言协同决策
- 模型天花板持续突破：
  - 随着众多SOTA模型发布（Gemini 3 Pro、GPT-5.1-Codex-Max、Grok 4.1、Claude Opus 4.5），国内创业公司开源模型的能力天花板进一步提升（doge狗头）
    友商
    动态
    OpenAI

11月20日，正式发布GPT-5.1 Pro和GPT-5.1-Codex-Max

- GPT-5.1-Codex-Max
- 专为「长时间、高强度」的开发任务而设计，能连续自主工作超24小时，一口气处理数百万token，直接交付成果
- 是OpenAI首个「原生支持压缩」机制的模型，可以跨越多个上下文工作。在Codex中，当接近上下文上限时，GPT-5.1-Codex-Max会自动执行会话压缩，刷新上下文，并多次重复这一过程直到任务完成
- 已在Codex 中支持CLI、IDE 扩展、云端和代码审查使用，API接口也将很快上线
- https://openai.com/index/gpt-5-1-codex-max/
- GPT-5.1 Pro
  - 官网暂无独立博客介绍，为内测阶段，一些反馈 - HyperWrite AI的CEO Matt Shumer：- 对于大多数日常工作，Gemini 3更好；毕竟在一个独立的界面中等待10分钟才能得到答案显然并不理想。- 但对于任何需要深入思考、规划和研究的任务，以及任何必须一次性做对的事情，GPT-5.1 Pro更好。- https://shumer.dev/gpt51proreview
    11月26日，美国黑五购物季前夕，ChatGPT发布了Shopping Research（购物研究）功能，支持货比三家
- Shopping Research 背后的模型是 GPT-5 mini 的一个特殊版本，OpenAI 专门用强化学习训练它做购物研究，让它学会：
  - 读懂可靠的零售网站
  - 引用可信来源
  - 跨多个网站整合信息
- 在产品准确率测试中，Shopping Research 得分 64%
- https://openai.com/index/chatgpt-shopping-research/

11月22日，OpenAI与Anthropic联手推出MCP Apps提案，规范对交互式用户界面（UI）的支持，使 MCP 服务器能够直接向主机提供可视化的操作界面

- 具体来说，MCP Apps Extension 引入了一种标准化的模式，用于声明 UI 资源、将它们链接到工具，并实现嵌入式接口和主机应用之间的双向通信
- https://blog.modelcontextprotocol.io/posts/2025-11-21-mcp-apps/
  Google
  11 月 19 日谷歌重磅发布Gemini 3 Pro，LMArena（综合能力排行榜） 1501 分，全球第一
- 模型基础信息：
  - 输入输出类型：
    - 输入：文本、图片、视频、音频和 PDF
    - 输出：文本
  - 上下文窗口：
    - 输入：1000K
    - 输出：64K
  - 定价（美元/百万tokens）：
    - <200K，输入 2，输出12
    - > 200K，输入 4，输出18
- 模型评测：
  - 霸榜LMArena（1501分）和WebDev（1487分）
  - 人类最后考试（HLE）刷出45.8%最高分，人类博士级推理
  - 长程任务规划Vending-Bench 2上的王者
- 同步推出Gemini 3 Deep Think深度思考模式（ARC-AGI-2 创 45.1% 新高）及智能体开发平台Google Antigravity
  https://blog.google/products/gemini/gemini-3/
  11月21日，发布Nano Banana Pro（Gemini 3 Pro Image），基准测试中，相较于上一代性能显著提升
- 与传统图像模型不同，Gemini 3 Pro Image 是一款「推理模型」：它会在生成图像前进行内部推理，就像思考如何最好地完成任务一样。这带来了显著提升的图像质量、更高的准确性，以及更好的多语言长文本渲染能力。
- 专为解决最具挑战性的图像生成任务而设计，特别擅长：复杂的多轮次图像生成与编辑、需要高事实准确性的创意工作、多语言环境下的长文本渲染、需要最新知识支持的图像创作
- 基础信息：
  - 上下文窗口：64K 输入 token，32K 输出 token
  - 分辨率支持：可输出 1K、2K、4K 分辨率图像
  - 多轮编辑：支持对话式、多轮次的图像编辑工作流
  - 多图像合成：最多可将 14 张输入图像组合为 1 张输出图像
  - 搜索增强：集成 Google 搜索能力，提供更精确、最新的知识支持
    https://blog.google/technology/developers/gemini-3-pro-image-developers/
    https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemini-3-pro-image-preview?pli=1
    应用方向
- 推出AI原生IDE产品Antigravity （详细调研：Gemini Antigravity IDE 评测&调研 by @张洋 ）
- NotebookLM，推出“一键生成幻灯片”功能，效果惊艳（https://mp.weixin.qq.com/s/A2DOsQLxGMtXU9h-rwJWlQ）
  X AI
  11 月 18 日发布Grok 4.1，LMArena（综合能力排行榜） 1483 分，短暂全球第一（19日Gemini 3发布后跌至第二）
- 共发布了两个版本：Grok 4.1 Thinking和Grok 4.1
  - Grok 4.1 Thinking：推理增强版，主打复杂问题解决（如数学、逻辑分析），适合专业场景
  - Grok 4.1：非推理版，默认 “快速路径”，输出 Token 数从约 2300 降至 850，侧重轻量化即时响应（如日常问答、简单查询）
- 在核心基准测试中表现炸裂，LMArena 排行榜包揽冠亚军（Thinking 版 1483 、非推理版 1465 ，超 Gemini 2.5 Pro）【备注：仅霸榜一天】
- 具备了更高的情绪智能、共情能力和人际互动能力，在EQ-Bench3上，Grok 4.1拿下了1586 Elo高分
- 已在网页端和iOS、Android中免费上线，目前，还是beta版本

https://x.ai/news/grok-4-1
Anthropic
11月25日，发布Claude Opus 4.5，相较4.1版本降价至1/3，编程能力刷新Sota（SWE-Bench Verified）

- 在编码基准SWE-Bench Verified上首次突破80%大关，并在工具使用和推理方面刷新纪录
- 增加effort参数：支持high、medium、low三档，同时影响思考、回复、工具调用
- 已通过App、API及三大主流云平台开放使用，API定价（美元/百万tokens）：
  - 输入：5，输出：25
  - 相比Opus4/4.1大幅降价到1/3
- 随Opus 4.5的发布，Claude Code推出两大新功能：
  - 计划模式（Plan Mode）现在能生成更精准的执行计划并全面落地，Claude会先主动确认需求细节，再生成可编辑的 plan.md文件后执行操作
  - Claude Code现已登陆桌面端应用，支持并行运行多个本地及远程会话，也就是说，可同时安排一个智能体修复漏洞，一个检索GitHub，另一个更新文档
- https://www.anthropic.com/news/claude-opus-4-5
  Anthropic API 公测2个新工具和功能：
- Programmatic Tool Calling：通过代码来调用业务工具，而不是每一步都由模型发起单独的 tool call。工具调用逻辑（循环、条件分支、多工具编排等）内嵌在代码中执行，模型只在关键节点与代码执行环境交互。这样可以减少多轮模型调用，降低延迟和 token 使用量。https://platform.claude.com/docs/en/agents-and-tools/tool-use/programmatic-tool-calling
- Tool Search Tool ：允许 Claude 在一个大型工具目录（包括 MCP 工具等）中按需搜索和加载工具，而不需要在每次请求时把所有工具定义全部塞进上下文。https://platform.claude.com/docs/en/agents-and-tools/tool-use/tool-search-tool
  微软
  11月18日微软Ignite大会，完整记录：2025Microsoft Ignite-1118
- 开场部分主要发布了微软Agent Factory，统一入口，整合运用 Work IQ、Boundary IQ 与 Fabric IQ 的全部能力，并且追踪Agent开发全流程，衡量Agent成果与ROI（强调全栈可观测性）
- Scott演讲的部分以介绍基础设施为主，并介绍了Foundry Agent Service支持众多模型：OpenAI、Anthropic、Meta、X AI、Llama AI，特别强调了Claude模型的入驻
- AI Agents分论坛，介绍了一下Agentic AI的变化趋势，并Demo了一个销售Agent的构建过程
  DeepSeek
  11月28日，发布DeepSeekMath-V2新模型，一举夺下IMO 2025金牌
- 在IMO-ProofBench中，DeepSeekMath-V2展现出强大的定理证明能力
  - IMO 2025：破解5题（共6题），达到了金牌水平；
  - CMO 2024（中国数学奥林匹克）：达到金牌水平；
  - Putnam 2024：得分118接近满分（120分），超越人类参赛者最高分（90分）。
- 在ProofBench-Basic上，DeepSeekMath-V2的实力碾压谷歌金牌模型——Gemini Deep Think；在ProofBench-Advanced上直追谷歌
  https://github.com/deepseek-ai/DeepSeek-Math-V2
  Minimax
  11月21日系列更新
- MiniMax Coding Plan 已支持图像理解及联网搜索MCP
  - https://platform.minimaxi.com/docs/guides/coding-plan-mcp-guide
- MiniMax最新发布并开源 MiniMax-Provider-Verifier，可用于验证第三方部署M2模型的正确性与可靠性
  - https://github.com/MiniMax-AI/MiniMax-Provider-Verifier
- 大模型体验官招募开启
  阿里
  11月17日，发布AI 助理「千问 APP」 （前身 通义千问 APP）
- 继 AI 基建、淘宝闪购后，阿里今年宣布的又一个集团战略项目，负责人是阿里巴巴智能信息事业群总裁吴嘉
- 除了会聊天，千问项目团队还在联合包括淘宝、高德、闪购、支付宝等产品的团队联合开发，希望更深嵌入相关产品，解决用户的实际问题
- https://mp.weixin.qq.com/s/OzuBtWoXfIRfHIel-FfTag
  11月26日，夸克全面升级为更强大的AI浏览器
- 直接把千问AI助手焊进了浏览器，并发布六大千问AI套件（千问读屏、快捷框、悬浮球、侧边栏、划词、截屏）；无需切换标签或应用，支持任意场景唤起千问
  11月27日，开源 Z-Image，6B 参数打出 20B 效果，16G 显存可跑
- 官方称视觉质量接近 20B 级别的闭源模型。核心是单流 DiT 架构，把文本和图像 token 塞进同一个 Transformer 处理，省掉了双流模型的重复参数开销。蒸馏版 Z-Image Turbo 只需 8 步采样即可出图，H800 上实现亚秒级生成，16GB 显存的 RTX 30 系列也能流畅运行。发布首日下载量超 50 万
- 模型分三个版本：Turbo 主打快速生成和中英双语文字渲染，Base 供社区微调，Edit 专攻自然语言指令编辑
- https://github.com/Tongyi-MAI/Z-Image
  11月27日，夸克AI眼镜S1正式面世
- 一个月前，阿里旗下的夸克 AI 眼镜 S1 正式在各大电商平台开启了预售，迅速成为了外界的关注焦点。11月27日，阿里夸克AI眼镜S1正式面世
- 带显示的夸克 AI 眼镜 S1 标准套装首发价为 3999 元
- https://mp.weixin.qq.com/s/0QCXpWiimAoI9C9zTZkdbA
  阿里百炼
- 模型上新
  - Qwen3-ASR-Flash-Filetrans（大文件转录版本）、Fun-ASR-2025-11-07（端到端语音识别大模型）、CosyVoice-V3-Flash（高性能语音合成大模型）、Qwen-VL-OCR-2025-11-20（OCR模型更新）
- 运营活动
  - 继续上线11月电商专题活动，自动提取商品图像信息，将平铺图智能生成真实场景或模特穿戴效果图。https://developer.aliyun.com/special/sfm-ootd-agent
    智谱
    11月21日，GLM Coding Plan升级：新速度、新能力、依旧大容量
- 速度进一步提升：根据近一周的速度实测，智谱编程套餐所有测试平均超 140 tokens/s，90% 以上的请求速度超 95 tokens/s
- 新增“网页获取”MCP：用户可以快速获取网页信息，便捷地针对内容进行抓取和翻译；我们也为 Lite 用户开放 MCP 调用尝鲜礼包，让所有套餐用户都能体验专属 MCP 工具的便捷
- https://zhipuaishengchan.datasink.sensorsdata.cn/t/cH
  更多
  蚂蚁
- 11月18日，蚂蚁也正式加入AI超级入口战场，发布AI主力「灵光 APP」，首批上线三大功能：“灵光对话”、“灵光闪应用”（自然语言生成应用）、“灵光开眼”（整合了实时理解、看图提问、文生图、文生视频、图生图、图生视频）
- https://mp.weixin.qq.com/s/rduhQZKN3-Untc0H6JWvng
  月之暗面
- 外媒最新消息显示，月之暗面的新一轮融资，已经进入临门一脚的“收尾阶段”。这一轮资金规模被多名知情人士形容为“数亿美元级别”，目标估值则被抬到了约 40 亿美元区间。相比 2024 年 B 轮融资时 30 亿美元出头的定价，又上了一个台阶
- https://mp.weixin.qq.com/s/DsyUKNdFkZW3pEbtrnFNhQ
  Black Forest Labs
- 开源视觉模型FLUX.2上新，这是一款专为现实创意工作流程打造，绝非演示噱头的生产力工具，与前代FLUX.1相比，实现了从「会画」到「懂你要画什么」的跃升
- https://mp.weixin.qq.com/s/htRlHsezFZDIpjFxV1J64A

20251124
友商
动态
OpenAI

11月20日，正式发布GPT-5.1 Pro和GPT-5.1-Codex-Max

- GPT-5.1-Codex-Max
- 专为「长时间、高强度」的开发任务而设计，能连续自主工作超24小时，一口气处理数百万token，直接交付成果
- 是OpenAI首个「原生支持压缩」机制的模型，可以跨越多个上下文工作。在Codex中，当接近上下文上限时，GPT-5.1-Codex-Max会自动执行会话压缩，刷新上下文，并多次重复这一过程直到任务完成
- 已在Codex 中支持CLI、IDE 扩展、云端和代码审查使用，API接口也将很快上线
- https://openai.com/index/gpt-5-1-codex-max/
- GPT-5.1 Pro
  - 官网暂无独立博客介绍，为内测阶段，一些反馈 - HyperWrite AI的CEO Matt Shumer：- 对于大多数日常工作，Gemini 3更好；毕竟在一个独立的界面中等待10分钟才能得到答案显然并不理想。- 但对于任何需要深入思考、规划和研究的任务，以及任何必须一次性做对的事情，GPT-5.1 Pro更好。- https://shumer.dev/gpt51proreview
    Google
    11 月 19 日谷歌重磅发布Gemini 3 Pro，LMArena（综合能力排行榜） 1501 分，全球第一
- 模型基础信息：
  - 输入输出类型：
    - 输入：文本、图片、视频、音频和 PDF
    - 输出：文本
  - 上下文窗口：
    - 输入：1000K
    - 输出：64K
  - 定价（美元/百万tokens）：
    - <200K，输入 2，输出12
    - > 200K，输入 4，输出18
- 模型评测：
  - 霸榜LMArena（1501分）和WebDev（1487分）
  - 人类最后考试（HLE）刷出45.8%最高分，人类博士级推理
  - 长程任务规划Vending-Bench 2上的王者
- 同步推出Gemini 3 Deep Think深度思考模式（ARC-AGI-2 创 45.1% 新高）及智能体开发平台Google Antigravity
  https://blog.google/products/gemini/gemini-3/
  11月21日，发布Nano Banana Pro（Gemini 3 Pro Image），基准测试中，相较于上一代性能显著提升
- 与传统图像模型不同，Gemini 3 Pro Image 是一款「推理模型」：它会在生成图像前进行内部推理，就像思考如何最好地完成任务一样。这带来了显著提升的图像质量、更高的准确性，以及更好的多语言长文本渲染能力。
- 专为解决最具挑战性的图像生成任务而设计，特别擅长：复杂的多轮次图像生成与编辑、需要高事实准确性的创意工作、多语言环境下的长文本渲染、需要最新知识支持的图像创作
- 基础信息：
  - 上下文窗口：64K 输入 token，32K 输出 token
  - 分辨率支持：可输出 1K、2K、4K 分辨率图像
  - 多轮编辑：支持对话式、多轮次的图像编辑工作流
  - 多图像合成：最多可将 14 张输入图像组合为 1 张输出图像
  - 搜索增强：集成 Google 搜索能力，提供更精确、最新的知识支持
    https://blog.google/technology/developers/gemini-3-pro-image-developers/
    https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemini-3-pro-image-preview?pli=1
    X AI
    11 月 18 日发布Grok 4.1，LMArena（综合能力排行榜） 1483 分，短暂全球第一（19日Gemini 3发布后跌至第二）
- 共发布了两个版本：Grok 4.1 Thinking和Grok 4.1
  - Grok 4.1 Thinking：推理增强版，主打复杂问题解决（如数学、逻辑分析），适合专业场景
  - Grok 4.1：非推理版，默认 “快速路径”，输出 Token 数从约 2300 降至 850，侧重轻量化即时响应（如日常问答、简单查询）
- 在核心基准测试中表现炸裂，LMArena 排行榜包揽冠亚军（Thinking 版 1483 、非推理版 1465 ，超 Gemini 2.5 Pro）【备注：仅霸榜一天】
- 具备了更高的情绪智能、共情能力和人际互动能力，在EQ-Bench3上，Grok 4.1拿下了1586 Elo高分
- 已在网页端和iOS、Android中免费上线，目前，还是beta版本

https://x.ai/news/grok-4-1
微软
11月18日微软Ignite大会，完整记录：2025Microsoft Ignite-1118

- 开场部分主要发布了微软Agent Factory，统一入口，整合运用 Work IQ、Boundary IQ 与 Fabric IQ 的全部能力，并且追踪Agent开发全流程，衡量Agent成果与ROI（强调全栈可观测性）
- Scott演讲的部分以介绍基础设施为主，并介绍了Foundry Agent Service支持众多模型：OpenAI、Anthropic、Meta、X AI、Llama AI，特别强调了Claude模型的入驻
- AI Agents分论坛，介绍了一下Agentic AI的变化趋势，并Demo了一个销售Agent的构建过程。
  Minimax
  11月21日系列更新
- MiniMax Coding Plan 已支持图像理解及联网搜索MCP
  - https://platform.minimaxi.com/docs/guides/coding-plan-mcp-guide
- MiniMax最新发布并开源 MiniMax-Provider-Verifier，可用于验证第三方部署M2模型的正确性与可靠性
  - https://github.com/MiniMax-AI/MiniMax-Provider-Verifier
- 大模型体验官招募开启
  阿里
  11月17日，发布AI 助理「千问 APP」 （前身 通义千问 APP）
- 继 AI 基建、淘宝闪购后，阿里今年宣布的又一个集团战略项目，负责人是阿里巴巴智能信息事业群总裁吴嘉
- 除了会聊天，千问项目团队还在联合包括淘宝、高德、闪购、支付宝等产品的团队联合开发，希望更深嵌入相关产品，解决用户的实际问题
- https://mp.weixin.qq.com/s/OzuBtWoXfIRfHIel-FfTag
  智谱
  11月21日，GLM Coding Plan升级：新速度、新能力、依旧大容量
- 速度进一步提升：根据近一周的速度实测，智谱编程套餐所有测试平均超 140 tokens/s，90% 以上的请求速度超 95 tokens/s
- 新增“网页获取”MCP：用户可以快速获取网页信息，便捷地针对内容进行抓取和翻译；我们也为 Lite 用户开放 MCP 调用尝鲜礼包，让所有套餐用户都能体验专属 MCP 工具的便捷
- https://zhipuaishengchan.datasink.sensorsdata.cn/t/cH
  更多
  蚂蚁
- 11月18日，蚂蚁也正式加入AI超级入口战场，发布AI主力「灵光 APP」
- https://mp.weixin.qq.com/s/rduhQZKN3-Untc0H6JWvng
  月之暗面
- 外媒最新消息显示，月之暗面的新一轮融资，已经进入临门一脚的“收尾阶段”。这一轮资金规模被多名知情人士形容为“数亿美元级别”，目标估值则被抬到了约 40 亿美元区间。相比 2024 年 B 轮融资时 30 亿美元出头的定价，又上了一个台阶
- https://mp.weixin.qq.com/s/DsyUKNdFkZW3pEbtrnFNhQ
  20251117
  趋势小结：
- 推理效率优化
  - OpenAI GPT-5.1引入自适应深度思考机制，动态平衡速度与深度。标志模型开始根据任务复杂度动态调整计算资源，可能逐步成为行业标准，推动AI从通用能力向场景化智能演进。
- 多模态生成跃迁
  - 谷歌Nano Banana Pro支持4K生成、World Labs开放3D世界创建平台Marble。多模态技术正从二维平面向三维空间渗透，未来竞争焦点将集中在物理规律模拟、实时交互等维度，为元宇宙、数字孪生提供基础设施。
- Agent企业集成
  - 月之暗面Kimi K2 Thinking实现300步工具调用，百炼推出电商场景Agent及运营活动，钉钉DeepResearch框架针对企业复杂任务设计。预计2026年将出现更多垂直行业的端到端Agent解决方案
    友商
    动态
    OpenAI

11月12日，发布GPT-5.1 系列模型，模型情商智商双核升级，不仅更聪明，而且聊天更有人味了

- 模型版本：
  - GPT-5.1 Instant ：最常用的模型，语气更亲切、更智能，更善于遵循指令。
  - GPT-5.1 Thinking ：先进的推理模型，更易于理解，处理简单任务速度更快，处理复杂任务更具持久力。
  - GPT-5.1 Pro：即将上线
- 关键能力： 首次引入“自适应推理”（Adaptive Reasoning），允许模型在响应前判断是否需要更深度的“思考”，以在保证快速响应的同时，处理复杂问题时能进行更详尽的分析。在数学（AIME 2025）和代码（Codeforces）等基准测试上表现出显著提升。

GPT-5.1 思考在简单任务上花费的时间更少，在困难任务上花费的时间更多
与GPT5.0同价

- https://openai.com/index/gpt-5-1-for-developers/
  Google
  谷歌 Gemini 3 即将发布 ：
- 谷歌 CEO Sundar Pichai 暗示 11 月 22 日前后推出Gemini 3，配套图像模型 Nano Banana Pro 支持 4K 输出
- VertexAI 代码中已经出现 gemini-3-pro-preview-11-2025 字样，标签明确指向 11 月。Google Vids 的产品页面也直接泄露了配套图像模型的名称 —— Nano Banana Pro（而非此前预期的 Nano Banana 2）。“Pro” 的命名说明该模型由 Gemini 3 Pro 而不是 Flash 版本驱动，面向专业创作者，承诺 4K 输出以及更快的生成速度
  Minimax
  11月14日，发布MiniMax Coding Plan，共有Starter、Plus和Max三档，其中最低档套餐首月9.9元
- M2 拥有顶尖编码能力，是OpenRouter上token调用量最大的国产模型
- TPS > 100，是 Claude 的两倍
- 下周初，M2会陆续支持图片理解和搜索MCP
- https://platform.minimaxi.com/subscribe/coding-plan
  百度
  2025百度世界大会，发布文心5.0模型，完整纪要：2025百度世界-1113
- 总参数2.4T（2400B），是目前已知参数量模型中参数量最大的
- LMArena文本排行榜1432分，综合排名并列第2，国产第1
- 全模态支持（文本、图片、音频、视频输入和输出），当前千帆中仅支持图文输入与文本输出
- 定价：
- https://cloud.baidu.com/doc/qianfan/s/wmh4sv6ya
  阿里
  百炼
- MCP广场新上架 2 个云部署 MCP Server。涵盖三方的酒店查询、酒店天气、酒店服务的 Hotel MCP，以及专用于AI智能营销推广，佣金返现的Agentsyun优惠券 MCP。欢迎直接开通体验。MCP市场
- 应用模板本周上架 6 个模板，详情如下。应用模板
- 针对电商场景推出运营活动：https://developer.aliyun.com/special/sfm-agent-ai
  - 电商场景Agent：一键生成主图、详情页、完整图组，智能适配类目风格
    更多
    WorldLabs
- Marble已向所有人开放，Pro版首月仅7元，仅需单张图像、视频片段、文本描述或三维布局即可让任何人创建高保真、持久化的3D虚拟世界
- https://www.worldlabs.ai/blog/marble-world-model
  阿里钉钉
- 钉钉团队提出了 Dingtalk-DeepResearch，一个为复杂、演进的企业任务设计的统一多智能体智能框架，旨在整合深度研究生成、异构表格推理和多模态报告合成，从而提供一个适应性强、可部署、企业级的解决方案
- 在国际权威深度研究评测 DeepResearch Bench 中取得 48.49 高分（全球第二、国内第一）
- https://arxiv.org/abs/2510.24760

20251110
友商
动态
Google
谷歌Nano Banana 2预览版闪现第三方平台Media IO（备注：当前已下线），生成速度飙到10秒、画质拉到4K

- 从网友首测来看，Nano Banana 2更加出色——
  - 分辨率：原生2K，可选4K超分
  - 生成速度更快：复杂场景仅需10秒
  - 文字渲染更锐利，提示词响应更精准
- 输入积分问题的图片，Nano-banana 2就能在白板上解决并提供全部步骤
- 基于纯文本，直接生成Windows桌面+网页浏览器Edge
  https://mp.weixin.qq.com/s/9PSAenw5ne-tk7xZZ6MrEA
  X AI
  11月8日，Grok 4 Fast与Grok Imagine都进行了大升级
- Grok 4 Fast把上下文窗口提高到2M，并把完成率拉到94.1%（推理）与97.9%（非推理）
  - 相较于此前版本，2M上下文意味着Grok 4 Fast可一次性处理相当于数百页文本的信息，适用于法律文书审阅、科研论文综述、大型代码库调试等高负载场景
  - 在保持低延迟和高吞吐特性的前提下，此次扩展进一步模糊了“快速模型”与“强大模型”之间的界限，为开发者在实时交互与深度分析之间提供更灵活的选择。
- Grok Imagine的升级则主要体现在生成质量上——其输出已经到了真假难辨的程度
  月之暗面
  11月6日，发布并开源 Kimi K2 Thinking
- Kimi K2 Thinking 是月暗基于「模型即 Agent」理念训练的新一代 Thinking Agent，它原生掌握「边思考，边使用工具」的能力
- 无需人类干预，即可凭借持续稳定的深度思考能力自主实现高达 300 步的工具调用，从而帮助用户解决更复杂的问题
- 在人类最后的考试（Humanity's Last Exam）、自主网络浏览能力（BrowseComp）、复杂信息收集推理（SEAL-0）等多项基准测试中表现达到 SOTA 水平，并在 Agentic 搜索、Agentic 编程、写作和综合推理能力等方面取得全面提升
- 支持 256K 上下文，价格与 Kimi K2-0905 相同，每百万 Token 输入 4 元，输出 16 元，命中缓存的输入为 1 元
- https://mp.weixin.qq.com/s/oQp1kFpoYFhYQ8GzbwZLyA

更多
11月4日，OpenAI 与 AWS 官宣建立多年的战略合作伙伴关系，双方合作的总额达到 380 亿美元

- 这项价值 380 亿美元的新协议（未来七年将持续扩大），OpenAI 将使用 AWS 计算资源，其中包括数十万块最先进的 NVIDIA GPU，并具备扩展至数千万个 CPU 的能力，以快速扩展自主式智能体等 AI 工作负载
- https://openai.com/index/aws-and-openai-partnership/
  11月6日，英伟达重磅推出OmniVinci全模态大模型
- 一款能理解多模态世界的全模态大语言模型（Omni-Modal LLM）。该模型实现了视觉、音频、语言在同一潜空间（latent space）中的统一理解， 让 AI 不仅能识别图像、听懂语音，还能推理、对话、生成内容
- 项目地址：https://github.com/NVlabs/OmniVinci
- 开源模型：https://huggingface.co/nvidia/omnivinci

20251103
友商
动态
MiniMax
10月27日，开源并发布了MiniMax M2，专为 Agent 和代码而生，Claude Sonnet 8%价格，2倍速度，限时免费

- 顶级代码能力：专为端到端开发工作流打造，在Claude Code、Cursor、Cline、Kilo Code、Droid 等多种应用中表现卓越
- 强大Agentic表现：出色规划并稳定执行复杂长链条工具调用任务，协同调用Shell、Browser、Python代码执行器和各种MCP工具
- 极致性价比&速度：通过高效的激活参数设计，实现智能、速度与成本的最佳平衡
- https://mp.weixin.qq.com/s/1AK8qNmBFepVYoRIDWBE1g
  10月28日，发布视频生成模型 MiniMax Hailuo 2.3
- 在 Hailuo 02 模型的基础上进一步升级动态表现力，画面更加真实、稳定
- Hailuo 2.3 模型在肢体动作呈现、风格化以及人物微表情方面实现了显著的效果提升，同时对运动指令响应做进一步优化
- https://mp.weixin.qq.com/s/qnnTeGwGRgotm8taqBijfw
  10月30日，发布语音模型 MiniMax Speech 2.6
- 全面升级突破Voice Agent场景，超低延时，专业格式无障碍，更高自然度。
- https://mp.weixin.qq.com/s/RWXK8FYJVS4LhtocKeIxJw
  10月31日，发布音乐模型 MiniMax Music 2.0
- 对音乐的理解与表达实现了真正的跃升：无论是人声的细腻情绪，还是器乐的动态张力，都能被精准捕捉与还原
- https://mp.weixin.qq.com/s/Li0iZ_N1lw9_iKbW1s4xyg
  阿里
  新上线模型
- 上架开源版模型 Qwen3-VL-32B-Thinking，Qwen3-VL-32B-Instruct
  - Qwen3-VL系列 32B 的Dense模型，文档识别与理解、空间感知与万物识别能力、视觉2D检测与空间推理能力均表现出色，适合通用场景下的复杂感知任务
- 上架 Qwen3-Rerank
  - 基于Qwen LLM底座训练的文本排序模型，对输入的Query和候选Docs进行相关性排序，支持100+语种和长文本输入，适用于文本检索、RAG等场景。
- 上架 Qwen2.5-VL-Embedding
  - 基于Qwen2.5-VL底座训练的统一多模态向量模型，支持文本、图片、视频单模态/混合模态输入，输出统一表征向量，适用于跨模态检索、图搜、视频检索、图像聚类、复杂多模态信息检索、打标等场景。
- 上架 GLM-4.6
  新增支持模型单元的推理部署方式
  MCP广场上架更新
- 一方的通义万相2.5-图像视频生成，三方的Vidu AI生视频，视频合成工具箱VideoCreationTools
  更多
  Cursor
- 10月29日，发布Composer（面向软件工程的全新智能代理模型），通过在大型代码库中结合强化学习（RL） 训练，实现了行业前沿的编码任务能力，生成速度比同类模型快四倍
- https://cursor.com/cn/blog/composer
  但疑似为中国开源模型的套壳版本：https://mp.weixin.qq.com/s/YAUI6-pKltinFuq4Z5MjHQ
  北京智源
- 10月30日，发布多模态世界大模型 悟界・Emu3.5，通过 10 万亿的多模态 Token（主要源自互联网视频，总时长约 790 年）上进行端到端预训练，Emu3.5 得以学习并内化了现实物理世界的动态规律
- https://mp.weixin.qq.com/s/wXNDkNzKDG3rx9qZ9GkqgQ
  阿里夸克
- 10月24日，阿里巴巴旗下首款自研旗舰AI眼镜：夸克AI眼镜 S1，正式开启了预售。集成了通义千问大模型+夸克垂类模型，支持复杂指令的分解操作，例如：拍照并识别卡路里、方言识别、可以实时翻译10种语言等AI的功能。
- https://imgs.xinhuanet.com/tech/20251023/2f3aabd1f15748e89a4df67a3e967e0b/c.html

20251027
友商
动态
OpenAI
10月21日，OpenAI发布AI浏览器ChatGPT Atlas

- 以ChatGPT为核心打造的全新浏览器，首发平台 macOS，核心功能如下：
  - 内置ChatGPT：可通过侧边栏在任意页面调用
  - 浏览器记忆：搜索你的浏览记录
  - AI智能体：可在页面上执行操作
    https://openai.com/index/introducing-chatgpt-atlas/
    DeepSeek
    10月20日，开源DeepSeek-OCR，通过少量视觉token解码出10倍以上的文本信息
- 初步验证了「上下文光学压缩」的可行性：从少量视觉token中，模型能够有效解码出超过其数量10倍的文本token
- 在OCR任务上，DeepSeek-OCR有较高实用价值：在OmniDocBench基准测试中，仅用100个视觉token即超越GOT-OCR2.0（每页256token）；以少于800个视觉token的表现，优于MinerU2.0（平均每页6000+token）
  HuggingFace：https://huggingface.co/deepseek-ai/DeepSeek-OCR
  媒体解读：https://mp.weixin.qq.com/s/q4HKX9EQGhpQ_OFCnRfivA
  月之暗面
  10月24日，发布Kimi For Coding包月套餐，开源 Agentic Coding 工具 Kimi CLI 技术预览版
- 通过 Kimi 网页版 (kimi.com) 加入 Kimi 会员计划，即可在已有权益的基础上额外获赠 Kimi For Coding 包月套餐权益
- 与 Kimi For Coding 一起亮相的，还有月之暗面自研的开源 Agentic Coding 工具 Kimi CLI 技术预览版
  https://mp.weixin.qq.com/s/uC9bZX8fPwNj1mYALdv5yQ
  快手
  10月23日，快手KAT-Coder两款核心模型的升级版本 KAT-Coder-Pro V1 与 KAT-Coder-Air V1 正式发布，Air版永久免费
- KAT-Coder-Pro V1
  - 高性能AI编码模型， SWE-Bench 73.4%的解决率
- KAT-Coder-Air V1
  - 为轻量普惠而生，API 永久免费
- 体验地址：https://www.streamlake.com/product/kat-coder
- 除 KAT-Coder 系列模型首次亮相外，快手 StreamLake 也正式推出以“工具+模型+平台”为核心的AI编程产品矩阵，包括智能开发伙伴 CodeFlicker、高性能自研模型 KAT-Coder 以及大模型平台快手万擎

https://mp.weixin.qq.com/s/jRvhJglbC3bPwNV7-1Garw
更多
百川智能

- 10月22日，Baichuan-M2 Plus发布，为业内首个循证增强的医疗大模型，幻觉要比DeepSeek-R1低3倍，可信度比肩资深临床专家
- https://mp.weixin.qq.com/s/qtmx66_4cSxku-TzaIPNCg
  Dexmal 原力灵机
- 10月22日，Dexbotic 开源，Dexbotic作为具身智能VLA模型一站式科研服务平台，可以为VLA科研提供基础设施，加速研究效率。
- https://mp.weixin.qq.com/s/oRM00OZZHi5IoLpM4kOXZg
  Adobe
- 10月25日，发布全新AI工具EditVerse，可将图片和视频编辑整合到一个框架中，让你像P图一样轻松P视频
- https://mp.weixin.qq.com/s/pro0lQenDMKzFRLBpnAdIA
  20251020
  友商
  动态
  Google
  10月16日，发布了旗舰视频生成模型Veo 3.1（Veo 3.1 和 Veo 3.1 Fast）
- 主打更强叙事与音频控制、首尾帧与多图参考等精控
- 接入Gemini API与Vertex AI，Flow与Gemini可用
- 支持输出 720p 或 1080p 分辨率的视频，帧率为 24 帧 / 秒（fps），时长可选 4 秒、6 秒或 8 秒；若使用 Extend 功能，视频最长可扩展至 148 秒
- 定价：标准版 0.4美元/秒；Fast版 0.15美元/秒
- https://developers.googleblog.com/en/introducing-veo-3-1-and-new-creative-capabilities-in-the-gemini-api/
  Anthropic

10 月 17 日发布Agent Skills

- 为 Claude 新增了可自定义的 “技能模块”，能显著提升其在特定任务中的专业性，同时支持跨产品使用，核心特性：
  - 可组合：多个 skills 可以叠加，Claude 自动识别需要哪些
  - 可移植：同一个 skill 在 Claude apps、Claude Code、API 上都能用
  - 高效：只在需要时加载最小必要信息
  - 包含代码：skills 里可以带可执行脚本，不只是文字指令
- https://www.anthropic.com/news/skills
  10月16日，发布了全新升级的小模型Claude Haiku 4.5
- 在核心编码测试中，Haiku 4.5已能与GPT-5和Sonnet 4平起平坐，部分任务甚至实现反超
- 价格对比（美元/百万token）
  - Haiku 4.5：输入1，输出5
  - Sonnet 4：输入3，输出15
  - GPT-5/Codex：输入1.25，输出10
- https://www.anthropic.com/news/claude-haiku-4-5
  更多
  蚂蚁集团
- 10月14日，发布并开源万亿参数深度思考模型Ring-1T
- 在数学竞赛（AIME 25、HMMT 25），代码生成（CodeForces）、逻辑推理（ARC-AGI-v1），Ring-1T取得开源领先水平
- 体验地址：https://ling.tbox.cn/chat
- HuggingFace：https://huggingface.co/inclusionAI/Ring-1T
  爱诗科技
- 10月17日，AI视频企业爱诗科技宣布完成1亿元人民币B+轮融资，年度经常性收入（ARR）超过4000万美元
- https://mp.weixin.qq.com/s/D2SJ5_K4VIQiX3UN9kdMbg
  20251013
  友商
  动态
  OpenAI
  10月6日，OpenAI 2025开发者日，四项重大更新：
- Apps SDK：与外部应用无缝集成，把ChatGPT打造成未来的操作系统
- AgentKit：面向开发者和企业的一整套构建、部署和优化智能体的工具
- Codex：全面可用，不写一行代码，打造爆款APP
- API更新：三大API更新（GPT-5 Pro、gpt-realtime-mini、Sora 2）
  - GPT-5 Pro，400k上下文，272k最大输出，输入价格：15美元/百万token，输出价格：120美元/百万token
  - gpt-realtime-mini，两个月前高级语音模型的缩小版，成本降低了70%，但语音质量和性能保持不变
  - Sora 2，定价：
    https://x.com/OpenAI/status/1975242488056324159
    Google
    爆料谷歌下一代旗舰模型Gemini 3.0全家桶将在10月22日发布
    https://mp.weixin.qq.com/s/ALfH3BKf0HCXFQ66mT0EDw
    阿里
    阿里云百炼推荐大使活动
- 推荐新老用户体验百炼AI智能，可获最高45%返现奖励
- 推广百炼大模型，更有机会瓜分9万元现金激励
  https://dashi.aliyun.com/activity/ydsai
  DeepSeek
  DeepSeek-V3.2相关
- 9月30日，阿里百炼已集成，价格对齐DPSK官方，点击查看
- 10月9日，百度千帆已集成，价格对齐DPSK官方，点击查看
  月之暗面

月之暗面发布K2模型各服务商的工具调用能力评测

https://mp.weixin.qq.com/s/HJOIIUbEle4wp7rsD-S_ng
更多
AMD&OpenAI

- OpenAI宣布与AMD达成战略合作，将共同部署高达6GW的AMD Instinct MI450 GPU集群，首批1GW预计于2026年下半年启用。作为协议的一部分，OpenAI可认购最多1.6亿股AMD普通股，持股比例或达10%。
- https://mp.weixin.qq.com/s/vsF3WMIS_j9OUas55UGcZg
  Vidu
- Vidu即将在本月底升级Vidu Q2参考生视频功能
- https://mp.weixin.qq.com/s/1AcCkAsf-NwTlvIcpVOMvw
  20251006
  友商
  动态
  OpenAI
  10月1日，发布 Sora 2
- 当前可通过sora.com 或 iOS Sora app（上线3天，登顶App Store全美榜首）访问，未来将推出API服务
- 能力，Sora 2首次实现「音画同步」，在物理准确性、逼真度上，一举刷新SOTA，并在一致性、可控性上实现了巨大飞跃
- 玩法，Sora app 引入了“Cameo”（客串）功能，允许用户在平台上通过一次性简短的视频录制验证身份，并捕捉到自己的形象。之后，用户可以授权他人将自己的虚拟形象置入任何AI场景中，创造个性化的“客串视频”；同时，还引入了“Remix”功能，用户通过简单的提示词生成创作内容，将现有的视频素材和创意进行二次创作
- 安全，全流程分层分类拦截审核、全流程分层分类拦截、青少年守护、水印可追溯性等
- 发布公告：https://openai.com/index/sora-2/
- 基本介绍：https://openai.com/index/sora-2-system-card/
  Google
  Gemini 3.0即将发布
- 内部代码流出，Gemini 3.0「家族」目前有Gemini 3.0 Pro、Gemini 3.0 Flash两个版本
- 在人类最后考试基准上，Gemini 3.0拿下了32.4%最高分，性能碾压GPT-5、Grok 4
- 媒体报道：https://mp.weixin.qq.com/s/uM2Y8mosU25MEavc25FRcw
  Anthropic
  9月30日，正式发布了Claude Sonnet 4.5
- 这一版本被Claude定义为全球最强的代码模型，同时在智能体构建、计算机使用、推理和数学能力上展现出显著突破
- 伴随Sonnet 4.5，Anthropic对Claude全线产品进行了大规模更新：
  - Claude Code新增了「检查点」（Checkpoints）功能，可随时保存进度并一键回滚到早先状态；同时更新了终端界面，并推出了原生VS Code插件。
  - Claude API增加了上下文编辑功能和记忆工具，让智能体能运行更久，处理更复杂的任务。
  - Claude apps现已支持在对话中直接执行代码、生成文件（包括表格、幻灯片和文档）。
  - Claude for Chrome扩展对此前等待名单中的Max用户开放。
  - 开发者社区也迎来了新的核心资源：Claude Agent SDK。这套工具包开放了驱动Claude Code的底层基础设施，为所有人打造智能体提供了基础能力。
- 发布公告：https://www.anthropic.com/news/claude-sonnet-4-5
  DeepSeek
  9月29日，DeepSeek-V3.2-Exp 发布，训练推理提效，API 同步降价
- 是一个实验性（Experimental）的版本
- V3.2-Exp 在 V3.1-Terminus 的基础上引入了 DeepSeek Sparse Attention（一种稀疏注意力机制）
- 针对长文本的训练和推理效率进行了探索性的优化和验证
- 在各领域的公开评测集上，DeepSeek-V3.2-Exp 的表现与 V3.1-Terminus 基本持平
- 官方 API 价格也相应下调
- HuggingFace：https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Exp
- 论文：https://github.com/deepseek-ai/DeepSeek-V3.2-Exp/blob/main/DeepSeek_V3_2.pdf

智谱AI
9月30日，发布并开源新一代旗舰模型 GLM-4.6

- GLM-4.6 在多个方面实现了全面提升
  - 高级编码能力：在公开基准与真实编程任务中，GLM-4.6 代码能力对齐 Claude Sonnet 4
  - 上下文长度：上下文窗口由 128K 增加至 200K，适应复杂的代码与智能体任务
  - 推理能力提升，并支持在推理过程中调用工具
  - 增强了模型的工具调用和搜索智能体，在智能体框架中表现更好
  - 更强的写作能力：在文风、可读性与角色扮演场景中更符合人类偏好
- 价格较doubao-seed-1.6贵不少
- HuggingFace：https://huggingface.co/zai-org/GLM-4.6
- 技术博客：https://z.ai/blog/glm-4.6
  新发布概览页，像素级别借鉴方舟
  智谱开放平台
  火山方舟

阿里
百炼控制台部分重点更新

- 1、新增高代码应用：支持基于Python项目结构部署AI后端服务，内置自动化运维、可观测性及日志服务等企业级能力。
- 2、UI设计器全面升级：支持模板配置和快速关联Agent及创建界面。支持企业Agent门户搭建，关联Agent快速构建企业Agent。支持生成类、对话类主流Agent UI界面搭建，风格兼容SparkDesgin。

- 3、控制台改版升级：工单、费用、阿里云账号适配发布。文本模型支持H5体验，体验中心上线，支持模型直接体验，远程设备控制。
  腾讯
  9月28日，腾讯发布并开源的「混元图像3.0」，在10月4日LMArena文生图任务榜单上，排名第一
- 参考：https://x.com/arena/status/1974502371721162982
  更多
  Thinking Machines Lab（OpenAI前CTO创立）
- 推出首款产品「Tinker」，一个专为语言模型微调而生的API。它让开发者能彻底摆脱底层架构的束缚，仅用简单的Python代码便可专注于算法与数据创新
- https://thinkingmachines.ai/blog/announcing-tinker/
  滴滴
- 面向公众内测上线了小滴打车Agent，基于丰富的车辆和司机信息，通过AI智能理解用户需求，提供更精准、更完善、更贴近用户期望的用车方案
- https://mp.weixin.qq.com/s/j3eiODX_kz-EoOqcV1UovA
  20250929
  友商
  动态
  OpenAI
  9月25日，OpenAI 宣布推出 ChatGPT 新功能「Pulse」的预览版，首先向 Pro 订阅用户开放
- ChatGPT 现在会每天晚上主动进行研究，根据用户每天的聊天记录、反馈以及日历等关联应用提供个性化更新。
- 每天清晨，用户都会收到一组自定义生成的，可能感兴趣的内容，出现在手机 App 上
- https://openai.com/index/introducing-chatgpt-pulse/

DeepSeek
9月22日，发布DeepSeek-V3.1-Terminus 版本

- 此次更新在保持模型原有能力的基础上，针对用户反馈的问题进行了改进，包括：
  - 语言一致性：缓解了中英文混杂、偶发异常字符等情况；
  - Agent 能力：进一步优化了 Code Agent 与 Search Agent 的表现
- 新模型在Humanity's Last Exam（人类最后的考试）中，成绩较V3.1提升1/3
- Hugging Face：https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Terminus
  阿里
  9月24日，云栖大会阿里 6款模型上新 + 1个全新品牌发布，覆盖文本、视觉、语音、视频、代码、图像全场景
- Qwen MAX：万亿参数大模型，Coding 与工具调用能力登顶国际榜单
- Qwen3-Omni：新一代原生全模态大模型，真正实现“全模态不降智”
- Qwen3-VL：Agent 和 Coding能力全面提升，真正“看懂、理解并响应世界”
- Qwen-Image：再升级！真正实现“改字不崩脸、换装不走样”。
- Qwen3-Coder：256K上下文修复项目，TerminalBench分数大幅提升
- Wan2.5-Preview：音画同步视频生成，图像支持科学图表与艺术字。
- 通义百聆：企业级语音基座大模型，攻克企业落地语音模型的“最后一公里”
- https://mp.weixin.qq.com/s/O-3bPs3tKXi0glYvFO9Myg
  9月24日，阿里百炼模型广场更新，像素级借鉴方舟
  阿里百炼
  火山方舟
  腾讯
  9月28日开源Hunyuan Image 3.0（多模态生图模型）
- 首个开源商用级原生多模态生图模型，它也是目前参数量最大的开源生图模型，参数规模80B
- 具有基于世界知识推理的原生多模态模型，目前主要开放生图能力
- 可以解析千字级别的复杂语义，生成长文本文字
- 官网：https://hunyuan.tencent.com/image/zh?tabIndex=0
- Huggingface：https://huggingface.co/tencent/HunyuanImage-3.0
  更多
  360
- 北大-360联合实验室发布TinyR1-32B模型，以仅20k数据的微调，实现了安全性能的里程碑式突破
- https://huggingface.co/qihoo360/TinyR1-32B
  苹果
- 9月22日，苹果在 iOS 26.1、iPadOS 26.1 与 macOS Tahoe 26.1 中为 App Intents 引入 MCP 支持
- https://mp.weixin.qq.com/s/gzvSWH0c3vhefZi58i-lrg
  英伟达相关
- 9月24日，云栖大会上，阿里宣布与英伟达开展Physical AI合作
  - 合作覆盖了Physical AI的实践的各个方面，包括数据的合成处理，模型的训练，环境仿真强化学习以及模型验证测试等
  - https://baijiahao.baidu.com/s?id=1844135345085986714
- 9月22日，英伟达宣布向OpenAI投资1000亿美元
  - 英伟达将利用其系统帮助 OpenAI 建设并部署至少 10 吉瓦的 AI 数据中心。这些系统将包含数百万块 GPU，构成 OpenAI 下一代 AI 基础设施，并用于训练和运行通向超级智能的下一代模型。
  - 10 吉瓦的规模相当于 400 万至 500 万块 GPU 的算力。这大约是英伟达今年将出货的数量，并且是「去年的两倍」。
  - https://openai.com/index/openai-nvidia-systems-partnership/
- 9 月 18 日，英伟达宣布将向英特尔投资 50 亿美元
  - 英伟达将成为英特尔最大的股东之一，在发行新股以完成交易后，英伟达可能拥有英特尔 4% 或更多的股份
  - 这项协议达成后，英特尔将打造英伟达定制的 x86 CPU，英伟达将把这些 CPU 集成到其人工智能基础设施平台中，英特尔还将打造一个芯片系统，用于为个人电脑提供动力的英伟达小芯片
  - https://baijiahao.baidu.com/s?id=1843672221440384446
- 黄仁勋于本周接受了Bg2 Pod的专访，2小时重磅访谈内容已发布
  - 黄仁勋集中表达了对英伟达近期包括对OpenAI的千亿美元投资、投资英特尔等一系列大动作的原因，对英伟达的产业角色的定位，对AI产业的发展前的前瞻，以及AI对世界经济格局的彻底重构
  - https://www.youtube.com/watch?v=pE6sw_E9Gh0

20250922
友商
动态
OpenAI
9月16日，重磅推出GPT-5-Codex，专为智能体编程设计，显著提升代码重构、审查和缺陷发现的表现

- 此次发布的GPT-5-Codex属于GPT-5的一个特殊版本，它专为智能体编程（agentic coding）重新设计
- GPT-5-Codex将具备全面的「双模」特长：
  - 即时协作：与开发者实时配合，快速回答问题、修复小bug
  - 独立执行：能长时间自主推进复杂任务（如大规模重构、跨文件调试）
- GPT-5-Codex的交互响应更灵敏，小任务几乎即时，大任务可持续执行数小时。
- OpenAI内部测试可连续7小时完成大规模重构
- https://openai.com/index/introducing-upgrades-to-codex/

9月15日，OpenAI 发布《人们如何使用ChatGPT》报告：周活跃数超 7 亿、73% AI 话题和工作无关

- 报告显示，ChatGPT自2022年11月上线至2025年7月，已经拥有超过7亿周活跃用户，约占全球成年人口的10%。这种扩散速度在科技史上没有先例，比互联网和智能手机的普及更为迅猛
- 用户结构
  - 最初八成用户是男性，但到2025年中，女性用户比例已反超男性，性别差距几乎消失
  - 年龄分布方面，近一半消息来自26岁以下用户，但不同年龄群体的差距在缩小。在中老年群体中，使用率也在逐渐上升
  - 过去一年中，低收入和中等收入国家的用户增长率明显高于高收入国家，显示出ChatGPT的全球下沉效应
- 使用话题
  - 最常见的三大类为「实用指导」、「信息查询」和「写作」，三者合计占所有对话的 78%。其中，写作是工作相关任务的首要用途，占比为 40%。教育用途占所有信息的 10.2%，个人关系咨询不足 2%。其次，73% 的聊天与工作无关，相比较一年前（53%）大幅增加。个人和专业聊天「不断增长，但非工作消息增长更快」
- https://cdn.openai.com/pdf/a253471f-8260-40c6-a2cc-aa93fe9f142e/economic-research-chatgpt-usage-paper.pdf
  Google
  9月16日，谷歌牵头推进Agent支付协议AP2
- 谷歌宣布推出 Agent 支付协议 ——AP2（Agent Payments Protocol ），这是一种开放的共享协议，为 Agent 和商家之间安全合规的交易提供通用语言
- 这一协议是用于 AI Agent 跨平台主导发起与处理的购买支付，为每笔交易提供可追溯的记录。具体来看，AP2 可视为是 A2A 协议和 MCP 协议的扩展。
- https://github.com/google-agentic-commerce/AP2
  Meta
  Meta提出「语言自我博弈」（Language Self-Play，LSP） 方法，无数据也能实现能力飞升
- Meta提出了一个名为「语言自我博弈」（Language Self-Play，LSP）的强化学习（RL）新方法，通过让模型在不依赖额外数据的情况下进行自我改进，从而消除了这种依赖性。
- 在LSP框架中，同一个预训练LLM被赋予两种不同身份，形成动态对抗关系：
  - 「挑战者」 （Challenger）负责生成查询内容，目标是设计更具挑战性的指令，以此「难住」解题者，从而最小化任务奖励。
  - 「解题者」（Solver）则负责对挑战者生成的查询进行响应，目标是给出高质量回答，最大化任务奖励。这里的奖励既可以是基于结果验证的客观评分，也可以是基于人类偏好的主观评价。
- 论文链接：https://arxiv.org/abs/2509.07414
  xAI
  9月19日，发布Grok 4 Fast
- 技术博客中，介绍了Grok 4 Fast所具备的四大核心优势：
  - 行业SOTA级性价比
  - 最强网页与X平台搜索能力
  - 支持200万token的超长上下文
  - 创新统一架构：将推理/非推理「双模式」合一
- 新模型性能直逼Grok 4，但平均节省了40%推理token的消耗，成本直降98%
- 在NYT Connections基准和AA智能指数中表现卓越，超越多家顶级模型：
- https://x.ai/news/grok-4-fast
  阿里
  9月19日，开源Wan2.2-Animate：上传一张图，复刻任何动作，主演任何视频
- Wan-Animate接受一个视频和一个角色图像作为输入，并生成一个“动画”或“替换”模式的视频。
  1. 动画模式：模型生成模仿输入视频中人物动作的角色图像视频。
  2. 替换模式：模型用输入视频替换角色图像。
- 在新的 Wan-Bench 2.0 上将 Wan2.2 与领先的闭源商业模型进行了比较，评估了多个关键维度的性能。结果表明，Wan2.2 在这些领先模型中表现出优越的性能
- https://mp.weixin.qq.com/s/jVmIdzbqJLlyl8MTx3lWuQ
- https://humanaigc.github.io/wan-animate/
  9月17日，开源通义DeepResearch，模型、框架、方案全部开源
- 在人类最后的考试榜单HLE（Humanity's Last Exam）中，拿下了32.9%的最高分，超越DeepSeek-V3.1（29.8%）和OpenAI DeepResearch（26.6%）
- 在OpenAI提出的超高难度BrowseComp榜单上，通义DeepResearch以43.4%的准确率领跑开源榜单
- https://github.com/Alibaba-NLP/DeepResearch（12.1k Star)
  更多

智源

- 发布开源数据集InfoSeek，成为首个面向深度研究（Deep Research）场景的大规模开源数据集
- https://huggingface.co/datasets/Lk123/InfoSeek
  DeepSeek
- 9月17日，DeepSeek-R1登上Nature封面，标志着中国AI技术获得了来自国际的顶级认证
- https://www.nature.com/articles/d41586-025-02979-9
  英伟达/英特尔
- 9 月 18 日，英伟达宣布将向英特尔投资 50 亿美元。英伟达将成为英特尔最大的股东之一，在发行新股以完成交易后，英伟达可能拥有英特尔 4% 或更多的股份
- 这项协议达成后，英特尔将打造英伟达定制的 x86 CPU，英伟达将把这些 CPU 集成到其人工智能基础设施平台中，英特尔还将打造一个芯片系统，用于为个人电脑提供动力的英伟达小芯片
- https://baijiahao.baidu.com/s?id=1843672221440384446
  20250915
  友商
  动态
  OpenAI
  9月10日，ChatGPT支持MCP
- 目前仅Plus和Pro用户可用
- 要开启MCP，你需要在ChatGPT对话页中选择左下角的自己的头像，然后选择：设置->连接器->（滑到最下方）高级设置->开启开发人员模式
- 开启MCP后，ChatGPT原有的其他功能无法同时启用（如画布、搜索等）
- https://x.com/OpenAIDevs/status/1965807401745207708
  Google
  Gemini API
- 9月9日，发布了 Veo 3 和 Veo 3 Fast 正式版，价格更低，并新增了宽高比、分辨率和种子选项， 详细文档
- 定价：
  - Veo 3 0.4美元/秒，Veo 3 Fast 0.15美元/秒
  - 在7月底的版本中，Veo 3 Fast 0.4美元/秒
    Meta

9月12日，发布并开源了MobileLLM-R1，不到1B参数

- 不是通用的聊天模型，而是监督微调 (SFT) 模型，专门针对数学、编程（Python、C++）和科学问题进行训练
- 该系列参数最大的 MobileLLM-R1 950M 模型仅使用约 2T 高质量 token 进行预训练，总训练 token 量少于 5T，但在 MATH、GSM8K、MMLU 和 LiveCodeBench 基准测试中，其性能与使用 36T token 进行训练的 Qwen3 0.6B 相当或更佳
- https://huggingface.co/collections/facebook/mobilellm-r1-68c4597b104fac45f28f448e
  阿里
  9月12日发布并开源了 Qwen3-Next-80B-A3B
- 80B，每次仅激活约3B；训练成本约1/10，32K以上长文本吞吐提升约10倍，原生256K
- 在编程、人类偏好对齐以及综合性能力评测中，Qwen3-Next-Instruct 表现超过了千问的开源旗舰模型，并在包含通用知识、数学推理等核心测评中全面超越了Qwen3-32B
- HuggingFace：https://huggingface.co/collections/Qwen/qwen3-next-68c25fd6838e585db8eeea9d
- 定价：
  9月11日，百炼发布qwen-plus-2025-09-11
- 相较于qwen-plus-2025-07-28，在思考模式下提升了指令遵循能力、总结回复更加精简；在非思考模式下中文理解与逻辑推理能力得到增强
  百度
  9月9日，WAVE SUMMIT深度学习开发者2025大会上，文心大模型X1.1深度思考模型正式发布
- 相较于文心X1，事实性提升34.8%，指令遵循提升12.5%，智能体提升9.6%，64k
- 定价：输入 0.001 元/千tokens ，输出 0.004 元/千tokens
  更多
  腾讯
- 9月12日，开源Youtu-GraphRAG（图检索增强生成），在六个跨领域多语言基准测试中，展现出卓越性能
- https://arxiv.org/pdf/2508.19855
  爱诗科技
- 爱诗科技于9月10日宣布完成6000万美元（约合人民币4.3亿元）B轮融资，由阿里巴巴领投
- https://mp.weixin.qq.com/s/JIrh5jkK9BvVV-DJa5gE6w
  华为
- 9月10日开源openPangu-Embedded-7B-V1.1，具备快慢思考融合与自适应切换能力
- https://ai.gitcode.com/ascend-tribe/openPangu-Embedded-7B-V1.1
  美团
- 9 月 12 日，美团首个 AI Agent 产品「小美」正式开启公测，帮助用户实现「懒人点餐」
- https://mp.weixin.qq.com/s/oISuURyCcBwbmFQyUsddwg
  20250908
  友商
  动态
  OpenAI
  9月3日，OpenAI发布白皮书 《在 AI 时代保持领先：领导力指南》
- 该报告总结了该公司与一系列全球大型知名企业合作的经验，这些企业包括制药巨头 Moderna、化妆品巨头雅诗兰黛、Notion 以及跨国银行 / 金融服务公司 BBVA，最终得到了从战略到治理的五大核心原则
- OpenAI在报告中指出，人工智能的进步速度前所未有：
  - 自 2022 年以来，前沿大规模 AI 模型的发布数量增加了 5.6 倍；
  - 仅仅 18 个月，运行 GPT-3.5 等级的模型的成本就降低了 280 倍；
  - AI 的采用速度比桌面互联网快 4 倍。
    完整报告：https://cdn.openai.com/pdf/ae250928-4029-4f26-9e23-afac1fcee14c/staying-ahead-in-the-age-of-ai.pdf
    Anthropic
    9月5日，Anthropic宣布立即停止向中国资本控股超50%的实体（包括全球子公司及间接控股企业）提供Claude服务，政策全球适用且无过渡期。官方给出的理由是：法律、监管和安全风险。
- https://www.anthropic.com/news/updating-restrictions-of-sales-to-unsupported-regions
  9月3日，Anthropic 宣布已经完成了新一轮 130 亿美元融资，投后估值达 1830 亿美元，约为这家人工智能初创公司 3 月份上次融资时的三倍
- https://www.anthropic.com/news/anthropic-raises-series-f-at-usd183b-post-money-valuation
  月之暗面

9月5日发布 Kimi K2 模型的最新版本 0905，进一步提升其在真实编程任务中的表现：

- Agentic Coding 能力提升：在公开基准测试和真实的编程任务中均展现出更好的性能
- 前端编程体验升级：提升了前端代码的美观度和实用性
- 扩展上下文长度：从 128K 升级到 256K，为复杂长线任务提供更好的支持
- 提供高速版 API：支持高达 60-100 Token/s 的输出速度

技术博客：https://moonshotai.github.io/Kimi-K2/
技术报告：https://arxiv.org/abs/2507.20534
Github：https://github.com/moonshotai/kimi-K2
阿里
9月5日发布Qwen3-Max-Preview ，总参数达到1万亿：

- 支持多模态，上下文长度256K，最大生成长度32K
- 相较于2.5系列，新版本在中英文理解、复杂指令遵循、工具调用等维度实现了显著增强，同时大幅减少了知识幻觉，让模型更智能、更可靠。
- 支持100多种语言，无“深度思考”模式。
- 定价：

20250901
友商
动态
OpenAI
8月28日，发布最新生产级别语音到语音模型（gpt-realtime）和API（Realtime API）

- 新一代语音到语音模型gpt-realtime，在音质、理解力、指令遵循和函数调用上全面提升，语音几乎媲美真人，还能多语种切换与细腻表达
  智能与理解力
  指令遵循
  函数调用
- Realtime API实现语音直接处理，支持图像输入、远程MCP服务器与SIP（会话发起协议SIP：通过实时API的原生支持，将应用连接到公共电话网络、PBX()系统、桌面电话及其他 SIP端点）打电话，极大简化语音智能体构建
  https://openai.com/index/introducing-gpt-realtime/
  Google

8月26日，LMArena平台中的 nano banana （图像生成与编辑模型），正式在Google AI Studio与Vertex AI中发布，模型名：gemini-2.5-flash-image-preview
LMArena 中的评分对比
定价：每张图片的费用大约为 0.039 美元（约 0.28 元）
https://developers.googleblog.com/en/introducing-gemini-2-5-flash-image/
微软
8月28日，发布了微软自研的两个大模型：语音模型MAI-Voice-1和通用模型MAI-1-preview

- MAI-Voice-1语音模型效率极高：单GPU秒出1分钟音频！使用Copilot即可体验
- MAI-1预览版模型是微软AI首个端到端内部训练的自研基础模型
- （在多年依赖OpenAI模型之后，微软AI部门正式与OpenAI及整个行业正面竞争）
- https://microsoft.ai/news/two-new-in-house-models/
  阿里
  百炼
- 8月26日，对通义系列部分模型上下文缓存进行降价，单价从调价前 input_token 单价的 40% 调整到 input_token 单价的 20%

腾讯
8 月 28 日，腾讯混元正式开源端到端视频音效生成模型 HunyuanVideo-Foley，仅需输入视频和文字描述，即可生成电影级高品质音效

- https://github.com/Tencent-Hunyuan/HunyuanVideo-Foley
  更多
  英伟达
- 英伟达发布了一个全新的混合架构语言模型系列 Jet-Nemotron（2B/4B），相比Qwen3、Gemma3、Llama3.2等模型，Jet-Nemotron在数学、代码、常识、检索和长上下文等维度上准确率更高，同时在H100 GPU上推理吞吐量最高提升至53倍。
- https://github.com/NVlabs/Jet-Nemotron
  美团
- 开源自研大模型 LongCat-Flash-Chat，560B 参数，并采用了 MoE 架构。该模型集成了动态计算机制，根据上下文需求激活 186 亿到 313 亿参数（平均约 270 亿）
- https://github.com/meituan-longcat/LongCat-Flash-Chat

20250825
友商
动态
X AI
8月24日，Grok-2.5正式开源，模型信息：

- 巨大的模型规模：总参数量高达9050亿（905B），在推理时，每次会激活其中的1360亿（136B）参数。这使它成为目前最强大的开源模型之一。
- 超长的上下文窗口：支持高达131,072 (128k) token的上下文长度。
- 混合专家架构 (MoE)：这种架构可以在不增加巨大计算成本的前提下，大幅扩展模型规模，提升模型能力。
- 较新的训练数据：其预训练数据覆盖了大量的文本和代码，截止到2024年初。
- https://huggingface.co/xai-org/grok-2
  同时Elon Musk预告，Grok-3将在6个月后开源

DeepSeek
8月21日，发布DeepSeek V3.1，671B参数，上下文长度拓展到128k，本次升级包含以下主要变化：

- 混合推理架构：一个模型同时支持思考模式与非思考模式；
- 更高的思考效率：相比 DeepSeek-R1-0528，DeepSeek-V3.1-Think 能在更短时间内给出答案；
- 更强的 Agent 能力：通过 Post-Training 优化，新模型在工具使用与智能体任务中的表现有较大提升。
  编程
  搜索
  定价
- https://api-docs.deepseek.com/zh-cn/news/news250821
  阿里
  百炼
- 8月21日，发布Qwen-Image-Edit
  - 通义千问系列首个图像编辑模型，成功将Qwen-Image的文本渲染能力拓展到编辑任务上。支持精准的中英双语文字编辑、视觉外观与语义双重编辑、具备强大的跨基准性能表现。可实现复杂的图文编辑。体验入口
  - 价格：0.3元/张，免费额度：100张
- 8月22日，集成deepseek-v3.1、qwen-deep-research（通义千问深入研究模型，它可以拆解复杂问题，结合互联网搜索进行推理分析并生成研究报告） 等模型
  百度
  千帆
- 8月22日，集成GPT-OSS-120B、GPT-OSS-20B、GLM-4.5V
- https://cloud.baidu.com/doc/WENXINWORKSHOP/s/flxu4ej5u
  智谱AI
  8 月 20 日，智谱发布手机 Agent AutoGLM2.0
- Agent+云手机/云电脑的新技术范式，不抢占用户手机和电脑；突破硬件限制，在任何设备、任何场景下运行，帮助用户代理操作；GLM-4.5、GLM-4.5V驱动，具备推理、代码与多模态的全能能力
- 在Device Use基准测试（涵盖手机、电脑和网页操作）中，AutoGLM表现优于ChatGPT Agent、UI-TARS-1.5和Claude Sonnet 4，展现出更强的鲁棒性与通用性
- https://mp.weixin.qq.com/s/j6BGkYXc8sMsh-iOMYTiaw
  更多
  华为
- 云 EI（企业智能）产品线下的盘古大模型相关部门被明确撤销
- https://mp.weixin.qq.com/s/LwQSzhrvKLbcw-ScqNFcQg
  Dynamics Lab
- 全球首款AI原生UGC游戏引擎迎来2.0版本。Mirage 2是一款可在线游玩的实时通用领域生成式世界引擎，能将任何图像（照片、绘画、涂鸦等）转化为可实时互动的3D世界。
- 与谷歌刚刚发布的Genie 3相比，Mirage 2控制的类别更加丰富，生成时长可以长达10+分钟，延迟可控制在200ms。只需要在消费级GPU即可实现，并且可以实时在线游玩。
- https://blog.dynamicslab.ai/
  20250818
  友商
  动态
  Google
  8月16日，最新「0.27B」Gemma 3开源
- 适用于以下场景
  - 任务明确、数据量大的场景：如情感分析、实体识别、查询路由、结构化转换、创意写作和合规检查类任务
  - 预算有限，对响应速度有高要求：模型微调后，可运行在轻量、低成本的本地或终端设备上，能帮你省下大模型的推理成本，速度更快
  - 希望快速迭代和上线：它可以小时级别完成微调实验，远快于大模型的开发周期
  - 需要本地部署，保证隐私：Gemma 3 270M支持完全本地化运行，用户数据无需上传云端
  - 构建多个小模型一起跑：一台设备上部署多个任务专家模型也不吃力，控制预算的同时实现模型能力最大化
- https://developers.googleblog.com/en/introducing-gemma-3-270m/
  8月17日，Gemini APP同样推出了「引导式学习」（Guided Learning）的功能，并针对全美大学生，免费送一年Gemini Pro计划
- https://x.com/GeminiApp/status/1956388218217300085
  阿里
  8月11日，世界机器人大会上，阿里达摩院宣布开源自研的 VLA 模型RynnVLA-001-7B、世界理解模型RynnEC、以及机器人上下文协议RynnRCP，推动数据、模型和机器人的兼容适配，打通具身智能开发全流程
- 机器人上下文协议RynnRCP：https://github.com/alibaba-damo-academy/RynnRCP
- 视觉-语言-动作模型 RynnVLA-001：https://github.com/alibaba-damo-academy/RynnVLA-001
- 世界理解模型 RynnEC：https://github.com/alibaba-damo-academy/RynnEC
- WorldVLA模型：https://github.com/alibaba-damo-academy/WorldVLA
  百炼
- Multimodal-Embedding-V1 预计8月26日正式商业化
  - 定价：- 文本 0.7 元 / 百万Tokens，图片 0.9 元 / 百万Tokens。（由于multimodal-embedding-v1的模型计算逻辑，单张图片统一以128Tokens计算。）- 方舟豆包定价：
- 8月13日，上线Qwen-Image图像生成基础模型
  - 价格：0.25元/张
  - 卓越的文本渲染能力：拥有出色的复杂文本渲染能力，支持多行布局、段落级文本生成以及细粒度细节呈现。中英文，均能实现高保真输出。
  - 一致性的图像编辑能力：历经了增强的多任务训练范式，确保在编辑过程中能出色地保持编辑的一致性。
  - 强大的跨基准性能表现：在多个公开基准测试中的评估表明，Qwen-Image在各类生成与编辑任务中均获得SOTA，特别是在中文文本渲染上，大幅领先现有的最先进模型。
- 8月11日，上线通义万相2.2-图生视频-Flash模型
  - 相比wan2.1，推理速度提升12倍，创作效率跃升，价格低至0.1元/秒。（480P：0.10元/秒、720P：0.20元/秒）
  - 指令遵循能力大幅提升，各种特效提示词直出，运镜精准控制，指令落地更精准。
  - 风格化图像稳定输出，对各类风格化图像均能稳定保持风格，并实现合理自然的动态效果。
    智谱AI
    8月11日，GLM-4.5V视觉推理模型发布并开源
- 在42个公开榜单中41项夺得SOTA，其功能涵盖图像、视频、文档理解、Grounding、地图定位、空间关系推理、UI转Code等
- Github：https://github.com/zai-org/GLM-V
- Hugging Face：https://huggingface.co/collections/zai-org/glm-45v-68999032ddf8ecf7dcdbc102

百川智能
8月11日，第二款医疗增强大模型Baichuan-M2发布并开源

- 技术博客：https://www.baichuan-ai.com/blog/baichuan-M2
- 模型地址：https://huggingface.co/baichuan-inc/Baichuan-M2-32B
  更多
  Cohere
- Cohere获5亿美元融资、估值68亿美元，前Meta FAIR副总裁、PyTorch与Llama重要推手Joelle Pineau加盟出任首席AI官
- https://mp.weixin.qq.com/s/v0LRUpsV4chNNi5t3IrzjA
  20250811
  友商
  动态
  OpenAI
  8月7日，发布GPT-5
  toB
- 通过API可调用3款全新的推理模型：
  - GPT-5
  - GPT-5 mini
  - GPT-5 nano
- 支持回复 API、聊天完成 API，并作为 Codex CLI 的默认模型。API 中的所有 GPT‑5 模型均支持 reasoning_effort 和 verbosity API 参数，以及自定义工具。此外，它们还支持并行工具调用、内置工具（Web 搜索、文件搜索、图像生成等）、核心 API 功能（流式处理、结构化输出等），以及节省成本的功能，如提示缓存和批量 API。
- 定价（美元/百万token）：
  - GPT-5：输入1.25，输出10
  - GPT-5 mini：输入0.25，输出2
  - GPT-5 nano：输入0.05，输出0.4

toC

- 所有Plus、Pro、Team和Free用户，都可以使用GPT-5
- 如果花钱订阅，就可以无限制访问GPT-5和GPT-5 Pro，而免费用户在达到使用限制后，会转换到GPT-5 mini
- GPT-5是一个融合模型（integrated model），未来不再需要人工切换模型，GPT-5会自行决定何时需要更深入地思考
- GPT-5将成为ChatGPT中的默认模型，GPT-4o、o3、o4-mini、GPT-4.1和GPT-4.5都将被它取代

- 与前代模型的对应关系

LMArena

- 在文本、Web开发和视觉领域排名第一
- 在硬提示、编程、数学、创造力、长查询等方面排名第一
- 在代号「summit」的测试下，GPT-5目前持有最高的竞技场分数
  详细介绍：
- https://openai.com/zh-Hans-CN/index/introducing-gpt-5-for-developers/
- https://openai.com/index/gpt-5-system-card/
- https://openai.com/gpt-5/

8月5日，OpenAI发布两款开源模型，「gpt-oss-120b」和「gpt-oss-20b」

- gpt-oss-120b适用于需要高推理能力的生产级和通用型场景
  - 在核心推理基准测试中，120B模型的表现与OpenAI o4-mini相当，并且能在单张80GB显存的GPU上高效运行（如H100）。
- gpt-oss-20b适用于低延迟、本地或专业化场景
  - 在常用基准测试中，20B模型的表现与OpenAI o3-mini类似，并且能在仅有16GB显存的边缘设备上运行。
- 除此之外，两款模型在工具使用、少样本函数调用、CoT推理以及HealthBench评测中也表现强劲，甚至比OpenAI o1和GPT-4o等专有模型还要更强。
- 其他亮点如下：
  - 宽松的Apache 2.0许可证：可自由用于构建，无copyleft限制或专利风险——是实验、定制和商业化部署的理想选择。
  - 可配置的推理投入：可根据用户的具体用例和延迟需求，轻松调整推理投入（低、中、高）。
  - 完整的思维链：可完整访问模型的推理过程，从而简化调试并提升输出结果的可信度。
  - 支持微调：支持参数级微调，可根据您的特定用例对模型进行完全定制。
  - 智能体能力：利用模型原生的函数调用、网页浏览、Python代码执行和结构化输出等能力。
  - 原生MXFP4量化：在训练时，模型的混合专家（MoE）层便采用了原生的MXFP4精度，使得gpt-oss-120b在单张H100 GPU上即可运行，而gpt-oss-20b仅需16GB内存。
- https://openai.com/zh-Hans-CN/index/introducing-gpt-oss/
  Anthropic
  8月5日，发布Claude Opus 4.1
- Claude Opus 4.1是Claude Opus 4 在代理任务、真实世界编码和推理方面的升级版
- Claude Opus 4.1的编码性能在SWE-bench Verified上提升至 74.5% 。它还提升了 Claude 的深入研究和数据分析能力，尤其是在细节追踪和代理搜索方面
- 模型价格
- https://www.anthropic.com/news/claude-opus-4-1
  Google
  8月6日，谷歌DeepMind推出「通用世界模型」Genie 3
- 能以每秒20-24帧速度，实时生成720p画面，模拟数分钟的一致性视频
  启动时间很快，可推广到其他工业和现实世界场景
  会学习物理知识，在没有底层引擎的情况下学习游戏引擎和非刚体物理学。
  对于角色走动的风格化环境非常有效
  逼真的漫游，无人机拍摄效果极好
  全局照明和灯光效果很赞
  视觉记忆非常强大

https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/
腾讯
8月4日，腾讯混元团队开源了 4 款小模型

- 最大的只有 7B，另外还包括 4B、1.8B 和 0.5B 三个型号。
- 这些小语言模型使用「消费级显卡即可运行，适用于笔记本电脑、手机、智能座舱、智能家居等低功耗场景，且支持垂直领域低成本微调」
- 体验地址：https://hunyuan.tencent.com/modelSquare/home/list

小红书
小红书人文智能实验室（Humane Intelligence Lab，hi lab）8月6日低调开源了视觉语言模型dots.vlm1

- dots.vlm1，是小红书hi lab研发并开源的首个多模态大模型
- 模型基于hi lab全自研的12亿参数NaViT视觉编码器和DeepSeek V3的大语言模型构建，在视觉的理解和推理任务上均有不俗的表现，接近了SOTA水平，并且在纯文本任务中仍保持竞争力
- 在主要的视觉评测集上，比如MMMU/MathVision/OCR Reasoning，dots.vlm1的整体表现已接近当前领先模型Gemini 2.5 Pro与Seed-VL1.5 Thinking，显示出较强的图文理解与推理能力。
- 在典型的文本推理任务（如AIME、GPQA、LiveCodeBench）上，dots.vlm1的表现大致相当于DeepSeek-R1-0528，在数学和代码能力上已具备一定的通用性，但在GPQA等更多样的推理任务上仍存在差距。
- https://huggingface.co/rednote-hilab/dots.vlm1.inst

20250804
友商
动态
OpenAI
GPT-5即将发布
持续的相关新闻

- 在macOS ChatGPT应用中，已经有人发现了GPT-5-Auto和GPT-5-Reasoning模型
- GPT-5-Alpha已经由Cursor团队内部测试，几乎能一次性完成任何任务
  LMArena上，已悄然上线了「超大杯」GPT-5-pro，内部代号zenith
- 网友爆料，GPT-5共有4个版本：GPT-5-pro（zenith） 、GPT-5-high（summit） 、GPT-5-mini 、GPT-5-nano（starfish）
  7月29日，ChatGPT发布「Study and Learn」（学习模式）
- 该模式下，ChatGPT不仅仅提供答案，而是逐步引导解决问题
  - 交互式提示：苏格拉底式提问，引导主动学习
  - 分步解答：信息被组织成易于理解的部分，突出主题间关键联系，提供适量上下文，减少复杂主题
  - 个性化支持：根据评估水平和之前的记忆，调整到适合你的水平
  - 知识检查：测验和开放式问题，以及个性化的反馈，追踪你的进度。 灵活性：学习模式可随时开启或关闭
  - https://openai.com/zh-Hans-CN/index/chatgpt-study-mode/
    Google
    8月1日，Gemini 2.5 Deep Think 模型发布，Gemini app可体验，暂未toB
- 是谷歌首个对公众开放的多智能体模型。其核心机制是并行生成多个智能体思考路径，从中筛选最优答案，尽管耗能更大，但推理效果显著提升
- 在Humanity’s Last Exam（HLE）中，Gemini 2.5 Deep Think取得34.8%的高分，领先xAI的Grok 4（25.4%）和OpenAI的o3（20.3%）
- 支持输入类型：文本、图像、音频、视频
- 上下文窗口长度：100万（1M）tokens长度，最大输出长度可达192K tokens
- 在Gemini app，每月支付250美元，通过Gemini Ultra订阅计划使用
- https://blog.google/products/gemini/gemini-2-5-deep-think/
  7月30日，发布了Veo 3 Fast 预览版模型，Vertex AI与Gemeni API中可体验使用
- Gemini API：https://ai.google.dev/gemini-api/docs/pricing?hl=zh-cn#veo-3-fast
  - 支持720P
  - Veo 3 Fast 定价：0.4美元/秒
- Vertex AI：https://cloud.google.com/vertex-ai/generative-ai/docs/models/veo/3-0-fast-generate-001
  - 支持720P与1080P
  - Veo 3 Fast 暂无公开定价
    AWS
    7月17日，推出Bedrock AgentCore
- 面向工程/架构团队，非图形化构建平台，为企业提供 AgentOps 能力（治理、部署、托管），旨在大幅简化和加速高性能 AI 智能体的安全、规模化部署与运营
  网站链接：https://aws.amazon.com/cn/bedrock/agentcore/
  视频链接： https://www.youtube.com/watch?v=2890bEb61qQ
- 详见产品团队调研：企业级Agent平台调研（by @戈沁沁 @潘煜炘 ）
  阿里
  8.1 发布 Qwen-Plus-2025-07-28快照版
- 相较上个版本在中英文能力、工具调用上进行了专用增强
- 首次支持1M上下文长度，按照上下文长度进行阶梯计费。
- 新增上下文长度控制参数，默认开启（限制为128k），可自行选择是否关闭。
  平台功能更新：
- 应用内新增UI设计器，通过可视化的搭建方式，无需编码即可快速构建应用界面，并一键发布为Web App。UI设计器

百度
模型更新

- 8月1日，集成了Kimi-K2
- 7月28日，集成了Qwen3-235B-A22B-Thinking-2507、Qwen3-235B-A22B-Instruct-2507
  20250728
  友商
  动态
  阿里
  7.28 通义万相2.2视频生成发布并开源
- 涉及开源模型：文生视频Wan2.2-T2V-A14B、图生视频Wan2.2-I2V-A14B、统一视频生成Wan2.2-TI2V-5B
  - https://mp.weixin.qq.com/s/ivDFtXenaj4END34YPOFZw
- 百炼也已上架，价格同2.1
  7.23 Qwen3更新发布并开源
- Qwen3-235B-A22B-FP8非思考模式（Non-thinking）的更新版本，命名为：Qwen3-235B-A22B-Instruct-2507-FP8。
- 在GQPA（知识）、AIME25（数学）、LiveCodeBench（编程）、Arena-Hard（人类偏好对齐）、BFCL（Agent能力）等众多测评中表现出色，超过Kimi-K2、DeepSeek-V3等顶级开源模型以及Claude-Opus4-Non-thinking等领先闭源模型。
- https://mp.weixin.qq.com/s/6W2l2GXyrQzKCM7L8J59BA
  7.23 Qwen3-coder发布并开源
- Qwen3-Coder 拥有多个尺寸，今天率先开源当前最强大版本：Qwen3-Coder-480B-A35B-Instruct 模型。
- 它是一个MoE模型，拥有 480B 参数，激活 35B 参数，原生支持 256K 上下文，并可通过 YaRN 扩展到 1M 长度。
- 拥有卓越的代码和Agent能力，在Agentic Coding、Agentic Browser-Use 和 Foundational Coding Tasks 上均取得了开源模型的 SOTA 效果
- https://mp.weixin.qq.com/s/VdxtVNl0Ftr4DvmDuMpCBQ

- 百炼定价，分段计费
- 在部分IDE上免费用（通义灵码AI IDE、VSCode和Jetbrains插件端免费使用）：https://mp.weixin.qq.com/s/V-ZxPxsOBd_ctrt3bNAYsw
  百度
  模型更新
- 集成了Qwen3-235B-A22B-Thinking-2507、Qwen3-235B-A22B-Instruct-2507
  智谱
  7.28 GLM-4.5 发布并开源
- GLM-4.5 在包含推理、代码、智能体的综合能力达到开源 SOTA 水平，在真实代码智能体的人工对比评测中，实测国内最佳
- 采用混合专家（MoE）架构，包括 GLM-4.5：总参数量 3550 亿，激活参数 320 亿；GLM-4.5-Air：总参数 1060 亿，激活参数 120 亿
- 两种模式：用于复杂推理和工具使用的思考模式，及用于即时响应的非思考模式
- 高速、低成本：API 调用价格低至输入 0.8 元/百万tokens、输出 2 元/百万tokens，分段计费；高速版最高可达 100 tokens/秒
- https://mp.weixin.qq.com/s/Dh0r-O-WZAvlKaxQOXjlpQ
  阶跃星辰
  7.26 新一代多模态推理模型Step 3发布并开源
- 模型地址：https://github.com/stepfun-ai/Step3
- 总参数量为 321B，激活参数量为 38B，上下文长度64k，toB平台上分段计费
- 在国产芯片上的推理效率最高可达DeepSeek-R1的300%：https://mp.weixin.qq.com/s/abvxxTefWkdRoddnREnAbg

20250721
友商
动态
OpenAI
7月12日， 奥特曼宣布无限期推迟OpenAI开源模型发布
7月18日， 发布 ChatGPT「统一智能体」

- 可通过其自有虚拟计算机处理任务，能够流畅地在推理与执行之间切换，全程独立完成复杂任务
- 融合了此前三大技术突破的优势：Operator与网站交互的能力，Deep Research整合信息的技巧，以及ChatGPT智能对话优势
- 从智能浏览网页、筛选结果，在需要时提醒安全登录、运行代码、进行分析，还能直出PPT和Excel汇总发现结果
- 了解更多：https://openai.com/index/introducing-chatgpt-agent/
  7月19日，o3-alpha-responses-2025-07-17意外曝光
- 在WebDev Arena上，「o3-alpha-responses-2025-07-17」以「Anonymous-Chatbot」的名称出现
- 从实测来看，「o3-alpha」在前端代码能力达到了领先水平——远胜于Claude Sonnet、o3、Gemini 2.5 Pro。有网友在实测后，大赞o3-alpha，将它称为目前「最佳编码和物理模型」
- 媒体稿：https://mp.weixin.qq.com/s/aqsWN_O0shBfWsZh_L_g8A
  Google
  谷歌Veo 3全新升级，Flow平台可直接试用，上传一张照片即可生成音频和视频，角色一致性达到新高度
- 本次更新需要在Flow平台下进行，选择「Frames to Video」的选项，就能从一张图片开始生成视频
- 媒体稿：https://mp.weixin.qq.com/s/tqS0S6IhrxuZW8eCaul4yA
  xAI
  发布 Grok 4 两款模型，Grok 4（单智能体版本）和Grok 4 Heavy（多智能体版本）
- 发布了两款模型，Grok 4（单智能体版本）和Grok 4 Heavy（多智能体版本），其中后者支持4个智能体并行思考，在推理过程中横向比对、纵向协同，调用更大规模的计算资源以完成更复杂、更精密的任务。
- 在“人类最后考试”上，成为首个突破50%准确率的模型。得益于在训练中原生融入工具，Grok-4找到刷分法门，Grok-4 Heavy达到44.4%，比Gemini-2.5-Pro直接提升将近18个百分点。
- 速度：每秒输出75个token。慢于o3（188 token/s）和Gemini 2.5 Pro（142 token/s），但快于Claude 4 Opus（66 token/s）
- 上下文窗口：256k token。低于Gemini 2.5 Pro的100万token（1m），但优于Claude 4 Sonnet/Opus（200k) 和o3（200k）
- 定价方面，Grok 4延续了Grok 3的策略，即每百万输入/输出token分别为3美元/15美元
  - 这一价位与Claude 4 Sonnet持平，但高于Gemini 2.5 Pro（1.25美元/10美元）和近期降价后的o3（2美元/8美元）。
- 其他关键特性
  - 支持文本和图像输入（多模态能力）
  - 支持函数调用和结构化输出
    英伟达
    7月15日， H20解禁，中国可售
- 媒体稿：https://mp.weixin.qq.com/s/VXltRWYpUY45n6AlV9N-jQ
  阿里
  模型
- 7月17日，上架Moonshot-Kimi-K2-Instruct，价格同月暗官方
- 7月16日，千问新版本更新：qwen-plus-2025-07-14、 qwen-turbo-2025-07-15
  功能
- MCP ，新上架如二方的钉钉mcp，三方的企业工商搜索、招投标等4个云部署 MCP Server
  腾讯
  7月11日，混元新版本更新：hunyuan-t1-20250711
  月之暗面
  发布并开源 Kimi K2 ，擅长代码与 Agentic 任务
- Kimi K2 是一款具备更强代码能力、更擅长通用 Agent 任务的 MoE 架构基础模型，总参数 1T，激活参数 32B。在通用知识推理、编程、数学、Agent 等主要类别的基准性能测试中，K2 模型的性能超过其他主流开源模型
- 上下文长度为 128k，不支持视觉功能，定价（元/百万tokens）：输入 4 ；输出 16
- LMArena 排第五，超越DeepSeek R1 0528
  更多
  全球首个科研LLM竞技场上线
- Ai2耶鲁NYU联合推出了一个科研版「Chatbot Arena」——SciArena。全球23款顶尖大模型火拼真实科研任务，OpenAI o3领跑全场，DeepSeek紧追Gemini挤入前四
- 媒体稿：https://mp.weixin.qq.com/s/zHz55l07BVxs4ik1L3T6Wg
  20250714
  🔥 市场动态
  竞争趋势概览（2025.07.08-2025.7.14）

1. xAI：发布 Grok 4 两款模型，Grok 4（单智能体版本）和Grok 4 Heavy（多智能体版本）
2. Google：谷歌Veo 3升级（立即体验），上传一张照片即可生成音频和视频，角色一致性达到新高度
3. 月之暗面：发布并开源 Kimi K2 ，擅长代码与 Agentic 任务
   > > > 更多内容，请见🌟【AI One Week】市场竞争特征与趋势🌟
   > > > 友商
   > > > 动态
   > > > OpenAI
   > > > 奥特曼宣布无限期推迟OpenAI开源模型发布
   > > > Google
   > > > 谷歌Veo 3全新升级，Flow平台可直接试用，上传一张照片即可生成音频和视频，角色一致性达到新高度

- 本次更新需要在Flow平台下进行，选择「Frames to Video」的选项，就能从一张图片开始生成视频
- 媒体稿：https://mp.weixin.qq.com/s/tqS0S6IhrxuZW8eCaul4yA
  xAI
  发布 Grok 4 两款模型，Grok 4（单智能体版本）和Grok 4 Heavy（多智能体版本）
- 发布了两款模型，Grok 4（单智能体版本）和Grok 4 Heavy（多智能体版本），其中后者支持4个智能体并行思考，在推理过程中横向比对、纵向协同，调用更大规模的计算资源以完成更复杂、更精密的任务。
- 在“人类最后考试”上，成为首个突破50%准确率的模型。得益于在训练中原生融入工具，Grok-4找到刷分法门，Grok-4 Heavy达到44.4%，比Gemini-2.5-Pro直接提升将近18个百分点。
- 速度：每秒输出75个token。慢于o3（188 token/s）和Gemini 2.5 Pro（142 token/s），但快于Claude 4 Opus（66 token/s）
- 上下文窗口：256k token。低于Gemini 2.5 Pro的100万token（1m），但优于Claude 4 Sonnet/Opus（200k) 和o3（200k）
- 定价方面，Grok 4延续了Grok 3的策略，即每百万输入/输出token分别为3美元/15美元
  - 这一价位与Claude 4 Sonnet持平，但高于Gemini 2.5 Pro（1.25美元/10美元）和近期降价后的o3（2美元/8美元）。
- 其他关键特性
  - 支持文本和图像输入（多模态能力）
  - 支持函数调用和结构化输出
    月之暗面
    发布并开源 Kimi K2 ，擅长代码与 Agentic 任务
- Kimi K2 是一款具备更强代码能力、更擅长通用 Agent 任务的 MoE 架构基础模型，总参数 1T，激活参数 32B。
- 在通用知识推理、编程、数学、Agent 等主要类别的基准性能测试中，K2 模型的性能超过其他主流开源模型
- 上下文长度为 128k，不支持视觉功能
- 定价（元/百万tokens）：输入 4 ；输出 16

更多
全球首个科研LLM竞技场上线

- Ai2耶鲁NYU联合推出了一个科研版「Chatbot Arena」——SciArena。全球23款顶尖大模型火拼真实科研任务，OpenAI o3领跑全场，DeepSeek紧追Gemini挤入前四
- 媒体稿：https://mp.weixin.qq.com/s/zHz55l07BVxs4ik1L3T6Wg
  20250707
  🔥 市场动态
  竞争趋势概览（2025.7.1-2025.7.8）
- 阿里：Qwen-Plus/Turbo 模型降价（思考模式输出价格降价50%）
- 百度：发布并开源文心大模型4.5系列模型
- 智谱：发布并开源 GLM-4.1V-9B-Thinking
  > > > 更多内容，请见🌟【AI One Week】市场竞争特征与趋势🌟
  > > > 友商
  > > > 动态
  > > > xAI
  > > > 马斯克发帖称，将在7月4日后发布Grok 4
- 在xAI控制台源代码中发现了2个Grok 4模型：Grok 4和Grok 4 Code
  阿里
  模型
- 模型降价
  - Qwen-Plus、Qwen-Turbo两大旗舰模型输出价格（思考模式）降价50%，输入价格不变。
  - Qwen-Plus的价格基本对齐Doubao-Seed-1.6，输出长度在32k以上会更便宜些
- 开源，发布并开源 WebDancer信息检索Agent，只要输入指令，它就可以帮你上网搜索、做攻略，实现自主信息检索和类似深度研究模型的推理
  平台
- Agent市场生态
  1. 应用模版开启招募，阿里云百炼应用模板上架申请
  2. 上线支付宝AI收功能， 支持为自己的agent生成专属的「赞赏卡片」，Agent应用收到赞赏后，可随机生成10元以内的打赏金额，打赏的金额将全部存入开发者的个人支付宝AI钱包内
     百度

模型

- 发布并开源文心大模型4.5系列模型，共10款，涵盖了激活参数规模分别为47B和3B的混合专家（MoE）模型（最大的模型总参数量为424B），以及0.3B的稠密参数模型。预训练权重和推理代码完全开源。
- 相关模型均已上架至千帆平台：https://cloud.baidu.com/doc/WENXINWORKSHOP/s/4mchtzl8s
- 集成了Qwen3-Embedding-4B、Qwen3-Embedding-0.6B模型
  平台
- 数据增强功能升级：全新重构并推出 “Prompt生成 - Prompt筛选优化 - Response生成” 的全流程增强能力
  智谱AI
- 发布并开源 GLM-4.1V-9B-Thinking 多模态大语言模型
  智源
- 发布并开源统一图像生成模型OmniGen2，全新4B版OmniGen2在继承简洁架构的基础上，大幅提升了上下文理解与指令遵循能力
  20250630
  友商
  动态
  Google
  AI编程工具Gemini CLI开源
- 免费访问Gemini 2.5 Pro，支持100万token的超大上下文窗口
- 每分钟60次请求，每天最多1000次请求，完全免费
  阿里
  百炼
- 新发布text-embedding-v4、qwen-tts-2025-05-22
  开源
- 发布并开源 WebDancer信息检索Agent，只要输入指令，它就可以帮你上网搜索、做攻略，实现自主信息检索和类似深度研究模型的推理
  百度

模型

- 新发布ERNIE-4.5-Turbo-VL-Preview、ERNIE-4.5-VL-28B-A3B、ERNIE-4.5-21B-A3B、ERNIE-4.5-0.3B
  平台
- 数据增强功能升级：全新重构并推出 “Prompt生成 - Prompt筛选优化 - Response生成” 的全流程增强能力
  腾讯
  模型
- 发布并开源Hunyuan-A13B，总参数80B，激活参数仅13B，是混元首个开源推理模型
  - 是腾讯内部应用和调用量最大的大语言模型之一，有超过400+业务用于精调或者直接调用，日均请求超1.3亿
  - 在数学、推理、Agent调用等能力上超越Qwen3-A22B、DeepSeek-R1-0120以及OpenAI-o1-1217
    快手
    模型
- 发布并开源Kwai Keye-VL-8B多模态大语言模型
  月之暗面
  推出了自家第一个智agent工具Kimi-Researcher
- Kimi Researcher是专攻深度研究任务的智能体
- Kimi Researcher内容几乎没什么幻觉，它交的研究报告完成度很高，每个数据、每个案例后面都标着 “来源”
- 数据分析，思维导图，插图排版，元素配色Kimi Researche样样精通啊
  20250623
  友商
  动态
  Google
  6月17日，Gemini 2.5三款模型正式发布
- Gemini 2.5 Pro （正式版，与0605预览版相比无变化）
- Gemini 2.5 Flash（正式版，与0520预览版相比定价有变）
- Gemini 2.5 Flash-Lite（预览版，速度最快，极致性价比，每秒输出的token数接近350个）
  技术报告：https://storage.googleapis.com/deepmind-media/gemini/gemini_v2_5_report.pdf
  发布公告：https://developers.googleblog.com/en/gemini-2-5-thinking-model-updates/
  Midjourney
  6月19日，Midjourney发布其首个视频生成模型V1
- 单次任务默认输出 4 段 5 秒视频，最长可扩展至 21 秒
- 视频功能包含在现有订阅中（10 美元/月），GPU 资源消耗为图像任务的 8 倍。60美元/月起的订阅有无限图和视频生成
  媒体稿：https://mp.weixin.qq.com/s/-REU7RgalLiJPnVhZxxTqw
  Minimax

6月16日，发布并开源MiniMax-M1，1000k上下文（最大输入1000K，最大输出80K），定价完全同
doubao-seed-1.6-thinking，模型已开源：
技术报告：https://github.com/MiniMax-AI/MiniMax-M1/blob/main/MiniMax_M1_tech_report.pdf
Hugging Face：https://huggingface.co/collections/MiniMaxAI/minimax-m1-68502ad9634ec0eeac8cf094
GitHub ：https://github.com/MiniMax-AI/MiniMax-M1
6月18日，发布视频生成模型 Hailuo 02，Artificial Analysis Video Arena上排名全球第二。1080P 6s视频：3.5元，768P 6s视频：2元
6月19日，发布MiniMax Agent：一个能完成长程（Long Horizon）复杂任务的通用智能体，也就是能多步规划出专家级解决方案、能灵活拆解任务需求、并能执行多个子任务从而交付最终结果。
体验地址：https://agent.minimax.io/
6月20日，发布Hailuo Video Agent：一款视频创作Agent，并开放Beta版本。简单输入，Agent将自动分析、构思并生成具有专业水准、富有观看价值的完整视频内容。
体验地址：https://hailuoai.com
月之暗面
6月16日，开源代码模型Kimi-Dev，在SWE-bench Verified上以60.4%的成绩取得开源SOTA。参数量只有72B，但编程水平比最新的DeepSeek-R1还强，和闭源模型比较也表现优异。暂未在其开放平台发布API与定价
项目主页：https://moonshotai.github.io/Kimi-Dev/
GitHub：https://github.com/MoonshotAI/Kimi-Dev
HuggingFace：https://huggingface.co/moonshotai/Kimi-Dev-72B
百度

模型

- 上线舆情分析视觉理解大模型和图片质量检测视觉理解大模型
  平台
- 支持使用 BCM 云监控对调用统计数据进行监控、自定义配置告警模版和报警规则，查看文档
- Qwen2.5-VL-7B-Inustruct模型支持W8A8C16压缩策略：查看文档
- 图像理解模型训练支持闲时调度，提供更优惠的训练价格
  20250616
  友商
  动态
  OpenAI

6月10日，发布o3-pro

- 数学、编程、科学基准，领先o1-pro和o3
- o3-pro价格只有o1-pro的87%：输入 20美元/M tokens，输出 80美元/M tokens
- o3降价80%：o3：输入 2美元/M tokens，输出 8美元/M tokens
  另，奥特曼剧透，OpenAI开源模型将在夏末发布，但不是6月

Mistral AI
6月10日，发布 Magistral，这是一个全新的大语言模型（LLM）系列，展现了强大的推理能力。它能够进行不断反思，并解决更复杂的任务。此次发布包含两个版本：

- 面向企业客户的大型专有模型 Magistral Medium，可通过 Mistral 的 Le Chat 界面和 La Plateforme API 访问
- 以及一个 24B 参数的开源版本 Magistral Small，使用 Apache 2.0 许可，可以自由使用、商用化
  在基准测试中，新模型取得了不错的成绩。这里主要是 Magistral 与其前身 Mistral-Medium 3 和 DeepSeek 系列的对比。Magistral Medium 在 AIME2024 上的得分为 73.6%，其中多数投票为 64%，得分为 90%。Magistral Small 的得分分别为 70.7% 和 83.3%。

直接体验：https://chat.mistral.ai/chat
模型开源：https://huggingface.co/mistralai/Magistral-Small-2506
论文：https://mistral.ai/static/research/magistral.pdf
百度

模型

- 上线舆情分析视觉理解大模型和图片质量检测视觉理解大模型
  平台
- Qwen2.5-VL-7B-Inustruct模型支持W8A8C16压缩策略：查看文档
- 图像理解模型训练支持闲时调度，提供更优惠的训练价格
  20250609
  友商
  动态
  OpenAI

6月5日，发布了两项 ChatGPT 新功能：「连接器（Connectors）」与「记录模式（Record Mode）」，把更新的重点放在了如何让 ChatGPT 真正融入企业日常、参与工作流：

- 连接器：结合深度研究功能，让 ChatGPT 连上公司里的各种工具和文件库，一句话就能帮你查资料、分析数据、整理成方案。
- 记录模式：开会点一下按钮，ChatGPT 就能自动录音、记笔记、整理重点，开完直接生成会议纪要。
  Google
  6月5日，发布新版Gemini 2.5 Pro（0605版本）
- 仅用一个月碾压旧版Gemini 2.5（I/O 大会上的0506版本），在数学、编程、推理基准测试中，新版模型全部刷新SOTA，超越o3、Claude 4、DeepSeek-R1
- 更新后版本维持原价
  Anthropic
  5月30日，开源“思维追踪”（circuit tracing）工具，以图形化方式，追踪并展示 AI 大语言模型的内部思维过程。
  - Github（1.8K star）：https://github.com/safety-research/circuit-tracer
    阿里

模型

- 6月4日，新集成DeepSeek-R1-0528
- 6月3日，新发布qvq-max-2025-05-15、qvq-plus-2025-05-15
  MCP
- MCP市场新上架30个云部署服务，涵盖股票数据、财税，证券，数字人，数据库等
  腾讯
  模型
- 新发布hunyuan-large-vision
  - 暂无公开定价
- 新发布hunyuan-turbos-20250604
  - 写作、阅读理解能力提升，较大幅度提升代码和理科能力，复杂指令遵循等持续提升
  - 该模型定价对标Doubao-1.5-pro

20250603
友商
动态
DeepSeek
5月28日，DeepSeek R1 发布0528新版本

- 更新后的 R1 模型在数学、编程与通用逻辑等多个基准测评中取得了当前国内所有模型中首屈一指的优异成绩，并且在整体表现上已接近其他国际顶尖模型，如 o3 与 Gemini-2.5-Pro。相较于旧版 R1，新版在复杂推理任务中的表现有了显著提升。
- 官网更新公告：https://api-docs.deepseek.com/zh-cn/news/news250528
  百度

模型

- 新集成InternVL3（1B、14B、38B）、DeepSeek-R1-250528
  腾讯
  模型
- 新发布hunyuan-large-vision，暂无公开定价
  快手可灵
  5月29日，发布可灵2.1，当前支持图生视频，即将支持文生视频，暂未提供toB API
- 2.1普通版：1080/720P，运动更好、细节更到位、更自然、画面更流畅，且主打性价比
- 2.1大师版：1080P，质量更高，大幅度运动表现更好（价格也更高）
- 价格上，可灵 2.1 模型生成标准 5 秒 720p 视频需要 20 灵感值（ 按标准价 2 元人民币 ），生成 1080p 高品质视频 35 灵感值（ 3.5 元人民币 ）， 价格和旧版（ 可灵 1.6 ）差不多，但生成效果更好，相当于 “ 加量不加价 ”
- 媒体稿：https://mp.weixin.qq.com/s/onhV73hLgvrnVFbXybNAPw

20250525
友商
动态
OpenAI

Responses API

- 5月21日，Responses API重要更新，标志着这一平台已从原本的AI对话接口，进化为支持多模态、多工具调用的统一智能代理开发平台。
- 此次升级内容包括MCP支持、图像生成（gpt-image-1）与代码执行环境（Code Interpreter）集成以及文件搜索功能增强等。开发者可借助一个API接口构建具备“感知-推理-执行”全链条能力的AI系统，涵盖搜索、图像创作、编程计算乃至与外部服务交互等复杂任务。
- 了解详情：https://openai.com/index/new-tools-and-features-in-the-responses-api/

Google
谷歌I/O 2025大会

- Gemini 2.5三连更：
- Gemini 2.5 Pro 性能提升：再次刷榜LMArena，ELO拿下1448分，所有类别第一，碾压o3，原生文本到音频生成，1000k上下文
- Gemini 2.5 Pro（Deep Think）：推出了实验性增强推理模式“Deep Think”，使模型能够在响应前考虑多个假设。刷榜数学、编码、多模态榜单
- Gemini 2.5 Flash（新）：排名仅次Gemini 2.5 Pro，ELO得分1424，原生文本到音频生成，在推理、多模态、代码和长上下文的关键基准测试中均有改进

- 图片生成和视频生成
  - Imagen 4
- 最新的 Imagen 模型结合了速度与精确度，能够创造出令人惊叹的图像
- 在细节表现上具有卓越的清晰度，如复杂的织物、水滴和动物毛发，并且在写实和抽象风格上都表现出色
- 可以生成多种长宽比的图像，最高支持 2k 分辨率——这对于打印或演示来说更佳
- 在拼写和排版方面也有显著提升，使您更容易制作自己的贺卡、海报甚至漫画
  - Veo 3 - Veo 3不仅在视频质量方面相比Veo 2有所提升，还首次实现了视频与音频的一体化生成能力 - Veo 3在多个关键技术领域展现出卓越表现：文本和图像提示响应、物理效果模拟、精准唇形同步、叙事理解能力。
    更多细节，详见：Google I/O 2025 All-in-One （by @赵甘霖 ）
    Anthropic

Claude 4

- 发布Claude Opus 4和 Claude Sonnet 4
  - Claude Opus 4是全球顶尖的编码模型，擅长复杂、长时间运行的任务，在AI智能体工作流方面性能极为出色
  - Claude Sonnet 4，则是对Sonnet 3.7 的重大升级，编码和推理能力都更出色，还能更精准地响应指令
- 定价，也与此前保持一致：
  - Opus 4：输入 15美元/M tokens，输出 75美元/M tokens
  - Sonnet 4：输入 3美元/M tokens，输出 15美元/M tokens
    阿里

模型

- 5月14日，发布并开源Wan2.1-VACE（通义万相视频生成与编辑模型），单一模型可同时支持文生视频、图像参考视频生成、视频重绘、视频局部编辑、视频背景延展以及视频时长延展等全系列基础生成和编辑能力。本次共开源1.3B和14B两个版本，其中1.3B版本可在消费级显卡运行。
  - 该模型也已集成在百炼平台，定价同其他视频生成模型：0.7元/秒
- 新发布qwen-vl-plus-2025-05-07新版视觉理解模型、aitryon-plus AI试衣模型
  平台
- 知识库，导入图片可选择Qwen VL进行解析，可选择qwen-vl-max或qwen-vl-plus模型，通过传入Prompt指引需识别的版面、元素和内容，适用于解析复杂图片或图表
  百度

平台

- SFT新增支持Qwen3-0.6B、Qwen3-8B、Qwen3-14B、Qwen3-32B
  模型
- Qwen3系列模型计费区分思考和非思考，定价完全同百炼
- 新发布ERNIE 4.5 Turbo VL，定价同doubao-1.5-vision-pro/doubao-1.5-thinking-vision-pro
  更多

智源

- 智源研究院联合多所高校研发了三款向量模型，包括代码向量模型BGE-Code-v1，多模态向量模型BGE-VL-v1.5以及视觉化文档向量模型BGE-VL-Screenshot
  - 这些模型取得了代码及多模态检索的最佳效果，并以较大优势登顶CoIR、Code-RAG、MMEB、MVRB等领域内主要测试基准
  - BGE-VL-Screenshot模型基于Qwen2.5-VL-3B-Instruct，以新闻、商品、论文、文档、项目主页等七类数据源进行训练，收集超过1300万张截图和700万组标注截图问答样本
    20250518

1. 企业级优化：定制训练、部署优化与多模态适配

- OpenAI正式发布RFT强化学习，当前支持o4-mini 模型；
  - 通过任务特定评分函数优化奖励信号指导模型学习，突破传统标注数据局限，适用于复杂任务定制。
  - 早期应用案例显示其在法律、医疗等领域显著提升任务性能（如AccordanceAI开发的税务分析模型准确率提升39%；Ambience Healthcare优化医疗编码，ICD-10分配性能提升12%）。
  - 使用 RFT 需四步骤，目前向认证组织开放，训练费每小时 100 美元（若使用 GPT-4o 等模型作为评分工具，需按标准推理费率额外计费），共享数据集可享 50% 折扣。
- Google Vertex AI，支持使用滚动部署替换已部署的模型 ；
  - 模型替换与资源复用
    - 用新版本模型替换旧模型，复用计算资源，保留上一次的流量分配和 dedicatedResources 配置。
    - 生成新 DeployedModel，含唯一 ID和 revisionNumber。
  - 配置与版本管理
    - 可配置字段（如 serviceAccount 等）默认继承旧模型，支持按需修改。
  - 副本更新与流量迁移
    - 旧副本逐步替换为新副本，基于可用资源快速更新。
    - 新副本健康检查（非 200 响应）失败时，自动回滚旧模型，部署终止。
- 阿里百炼知识库，导入图片可选择Qwen VL进行解析
  - 在创建知识库时，可选择qwen-vl-max或qwen-vl-plus模型，通过传入Prompt指引需识别的版面、元素和内容，适用于解析复杂图片或图表

2. 新模型发布：编码强化、多模态融合与低成本高效能

- Google发布全新升级的Gemini-2.5-Pro-Preview-05-06；
  - 重点强化编码能力，其 WebDev Arena 排名较旧版提升 147 Elo 点
    - 聚焦交互式网页应用开发，优化 UI 布局、交互逻辑生成能力。
    - 扩展至代码转换、编辑及复杂代理工作流开发，支持全流程开发需求。
  - 在视频理解、多模态推理方面保持领先
    - 视频理解：VideoMME 基准测试得分84.8%，支持视频内容解析与结构化输出。
    - 多模态融合：结合 UI 开发与视频分析，例如通过 “Video to Learning” 应用实现视频内容交互开发
      开发者可通过 Google AI Studio、Vertex AI 及 Gemini 应用调用该模型，Cursor 等工具已验证其工具调用失败率显著降低。
- Mistral AI发布Mistral Medium 3，定义为 “平衡型模型”，聚焦三大核心价值：
  - 性能领先：在编码、多模态理解、长上下文任务中达 SOTA 水平，例如 HumanEval 0-shot 得分92.1%，超越 Llama 4 Maverick（85.4%）。
  - 成本优势：输入 / 输出成本仅为 $0.4/$2 per M token，较 Claude Sonnet 3.7 低 8 倍，且性价比优于DeepSeek v3。
  - 企业级部署：支持混合云 / 本地部署（VPC 内）、自定义训练及企业工具集成，最低需 4 块 GPU 即可运行。
- 阿里发布新版视觉理解模型qwen-vl-plus-2025-05-07、视频生成与编辑开源模型Wan2.1-VACE；
  - 阿里称Wan2.1-VACE 模型是业界首个支持文生视频、图像参考生成、视频重绘 / 局部编辑 / 背景 / 时长延展等全系列功能的单模型视频生成与编辑方案，推出1.3B（消费级显卡可用）和 14B 版本，已在 GitHub、HuggingFace 等平台上线；
  - 其创新的视频条件单元 VCU 统一多模态输入，支持文本 / 图像 / 视频 / Mask 等混合输入及控制信号，开源以来下载量超 330 万，GitHub 星标超 1.1 万。
- 月之暗面发布深度思考模型 kimi-thinking-preview
  - 支持多模态推理与通用深度推理
  - API 响应含reasoning_content 思考过程字段，支持流式输出与多轮对话；
  - 模型处于预览阶段，不支持以下功能：- 工具调用（如计算器、数据库查询）；- 联网搜索（依赖内置知识，不获取实时信息）；- JSON Mode、Partial 模式及 Context Caching（上下文缓存）。
    20250506

1. 从“单模态生成”转向“多模态协同推理”
   OpenAI4.24发布 GPT-Image-1 API&4.15发布三款GPT 4.1模型&4.17发布满血版o3和o4-mini；Moonshot AI发布开源音频基础模型Kimi-Audio；

- 技术方向：OpenAI、Moonshot AI分别在图像推理、音频处理领域实现模态与思维链深度融合（如o3用图像思考、Kimi-Audio端到端语音对话），谷歌、百度强化多模态协同优化，推动“文本+视觉/音频”全场景覆盖。
- 应用场景：从基础生成（图像/文本）转向复杂任务（代码开发、视频创作、实时交互），如GPT-image-1支持商业设计、通义万相赋能视频定制，瞄准创意产业与企业级解决方案。

2. 性价比战争升级：
   智谱官宣多款大模型调价，GLM-4-Plus降价九成；xAI Grok 3 Mini低价策略、OpenAI GPT-4.1系列成本优化；谷歌Gemini 2.5 Flash预览版模型支持“思考预算”控制；

- 价格战升温：智谱GLM-4-Plus降价九成、xAI Grok 3 Mini低价策略、OpenAI GPT-4.1系列成本优化，倒逼行业降低使用门槛，中小企业与开发者成为争夺重点。
- 推理控制创新：谷歌“思考预算”、OpenAI“模式切换”（如o3的工具调用效率），通过动态调节算力分配平衡性能与成本，适配实时问答、高并发场景。

3. 开源常态化与工具链完善：
   阿里开源8款Qwen3混合推理模型、开源首尾帧生视频模型；DeepSeek开源Prover-V2数学推理模型；智谱开源 32B/9B 系列 GLM 模型；阿里云百炼上线业界首个全生命周期MCP服务；

- 开源常态化：智谱、阿里、DeepSeek等通过开源快速积累用户数据与生态反馈，形成“技术开源-应用反哺”闭环。
- 工具链完善：各厂商配套发布评估工具（如4月26日，开源全新音频基础模型Kimi-Audio）、开发套件（Codex CLI）、集成平台（ComfyUI），降低技术落地难度，加速行业应用。

4. 瞄准工业化落地关键障碍：
   百度发布文心大模型4.5 Turbo和X1 Turbo

- 针对性优化：百度聚焦“幻觉消除”与速度提升，发布文心大模型 4.5 Turbo（价格降 80%）、X1 Turbo（价格降 50%），并推出高说服力数字人、多智能体协作 APP “心响”、内容操作系统 “沧舟 OS” 等多款 AI 应用，解决模型可靠性、效率、规模化部署等实际问题。
- 细分场景突破：音频（Kimi-Audio）、视频（通义万相）、垂直领域（如编程、数学推理）成为差异化竞争点，避免同质化内卷。  
  20250428
  友商
  动态
  OpenAI

- 4月23日，发布全新图像生成模型gpt-image-1，定价按tokens收费：
  - 文本输入Token：5美元/百万token
  - 图像输入Token：10美元/百万token
  - 图像输出Token：40美元/百万token - 在实际应用中，对于低、中和高质量的方形图片，每生成一张图像的费用大约分别为0.01美元、0.04美元和0.17美元
  - gpt-image-1集成了三大核心功能：图像生成、图像编辑、图像变体（仅限DALL·E 2）
  - 与GPT-4o图像生成不同，gpt-image-1最大的特点，在于支持各种高级功能的定制
- 4月24日，OpenAI正式向免费用户推出深入研究（Deep Research），这次为轻量版，由o4-mini加持
  - 在BrowseComp Agentic Browsing基准测试中，轻量版准确率高达45.6%，相较于o3加持的原始版，仅差5%
  - 目前，Plus、Team用户每个月有25次，免费用户每个月5次。对于Pro版专业用户，每个月外加125次
- 4月25日，更新GPT-4o，在更新公告中，GPT-4o还优化了保存记忆的时间，增强了STEM领域问题解决能力。同时改进了响应方式，使其能更主动引导对话，输出有效的结果
  阿里
  模型
- 4月18日，新发布wanx2.1-kf2v-plus（首尾帧视频生成模型）、qwen-vl-max-2025-04-08（新版VLM）
- 4月24日，新发布cosyvoice-v2（新版声音复刻）
  百度

模型

- 4月24日，新发布ERNIE-X1-Turbo-32K、ERNIE-4.5-Turbo-128K、ERNIE-4.5-Turbo-32K、ERNIE-4.5-Turbo-VL-32K模型，重点模型定价：
  - X1 Turbo：输入 1元/M tokens，输出 4元/M tokens。为DeepSeek-R1的25%
  - 4.5 Turbo：输入 0.8元/M tokens，输出 3.2元/M tokens。为DeepSeek-V3的40%
- 4月24日，新集成GLM-4-32B-0414、GLM-Z1-32B-0414、GLM-Z1-Rumination-32B-0414、Qwen2.5-7B-Instruct模型
  平台
- SFT新增支持Qwen2.5-3B-Instruct；DPO新增支持Qwen2.5-1.5B-Instruct、Qwen2.5-32B-Instruct
  月之暗面
  4月26日，开源全新音频基础模型Kimi-Audio，支持语音识别、音频理解、音频转文本、语音对话等多种任务，在十多个音频基准测试中实现了最先进的 (SOTA) 性能
- 项目链接：https://github.com/MoonshotAI/Kimi-Audio
- 新闻稿：https://mp.weixin.qq.com/s/hbecvcn6qe4WO2LyqkS-iA
  更多

Vidu

- 4月22日，Vidu Q1发布，在权威评测基准VBench-1.0和VBench-2.0中，Q1一举超越Sora、Runway等国内外顶尖模型，勇夺文生视频赛道双榜第一。定价：每秒0.3元。
- 新闻稿：https://mp.weixin.qq.com/s/uv0FEYBrZ7iPXi4TthK9yA

20250422
友商
动态
OpenAI
4月15日，发布三款GPT 4.1模型：GPT-4.1、GPT-4.1 mini和GPT-4.1 nano，三款模型均拥有最高100万Token的超大上下文窗口，在代码、指令跟随等核心能力上全面超越GPT-4o及GPT-4o mini
代码能力
指令跟随
定价

- GPT-4.1 较 GPT-4o 降价60%
  - 4.1：输入2，输出8；4o：输入5，输出20
- GPT-4.1 mini 较GPT-4o mini 降价33%
  - 4.1 mini：输入0.4，输出1.6；4o mini：输入0.6，输出2.4
    4月17日，发布满血版o3和o4-mini，首次将图像推理融入思维链
- 在Codeforces、SWE-bench、MMMU等基准测试中，o3刷新SOTA，不论是在编程、数学、科学，还是在视觉感知领域都树立了新标杆
- 相较于满血版o3，o4-mini则以小巧高效、高性价比的特点脱颖而出，在数学、编程、视觉任务，以及非STEM领域，它的性能均优于o3-mini。
  数学
  编程
  视觉任务

Google

4月18日，发布首款混合推理模型Gemini 2.5 Flash，可灵活控制开启或关闭思考模式，关闭思考模式成本直降600%，性能击败Claude 3.7，比肩o4-mini。

- 关闭思考输出价格0.6美元/百万token，开启思考输出价格3.5美元/百万token
- 在多项基准测试中，Gemini 2.5 Flash再次刷新SOTA。在大模型排行榜中，Flash预览版以1392 ELO高分位居第二，与GPT-4.5-preview、Grok 3并驾齐驱。同时，价格也非常有性价比。
  阿里
  4月9日，百炼新增MCP市场与相关功能（（预置MCP、社区MCP、自定义注册MCP 和 MCP体验），整体体验还不错
- 可以直接使用百炼预置的MCP服务或部署自定义MCP服务，并在智能体应用和工作流应用中引用这些 MCP 服务，使用教程：https://help.aliyun.com/zh/model-studio/mcp-quickstart
- 访问链接：https://bailian.console.aliyun.com/?tab=mcp
- (但其toD体验中心：https://chat.qwen.ai/，仍然没发布MCP体验，应该是产研团队不同导致的)
  4月15日，魔搭（ModelScope）推出全新MCP广场，上架千余款热门的MCP服务，并独家首发支付宝、MiniMax等全新MCP服务
- 访问链接：https://www.modelscope.cn/mcp

4月17日，通义万相「首尾帧生视频模型」开源，该模型参数量为14B，是业界首个百亿参数规模的开源首尾帧视频模型。它可根据用户指定的开始和结束图片，生成一段能衔接首尾画面的720p高清视频，此次升级将能满足用户更可控、更定制化的视频生成需求。

- https://mp.weixin.qq.com/s/kudRFGW7MZRfESYS__V5LA
  关于百炼控制台：
- 用量统计功能，新增高级监控模式，支持分钟级低延时数据刷新，并可记录更详细的模型调用失败信息（如4xx、5xx分别出现次数等），详细文档
- 控制台有较大迭代升级，按模型、应用、MCP、文档等展示平台各功能，且支持免登时查看大部分内容
  模型
  应用
  文档
  百度

模型更新

- 4月8日新集成 Llama-4-Maverick-17B-128E-Instruct 和 Llama-4-Scout-17B-16E-Instruct，定价（元/M tokens）：
  - Llama-4-Maverick ：输入 7，输出 21
  - Llama-4-Scout ：输入 6，输出 18
    功能更新
- 数据洞察新，上线提示词模板拼接（在大模型精调阶段，将结构化的提示词模板整合进训练数据，让模型快速理解任务核心要求，高效地学习任务范式，从而提升训练效果）
  腾讯
  4月14日，腾讯云宣布大模型知识引擎升级支持MCP协议，用户在搭建应用时，可以通过大模型知识引擎调用平台精选的MCP插件或插入自定义的MCP插件。目前，知识引擎平台已经精选了多款MCP Server。
  4月12日，腾讯云开发平台发布MCP Marketplace、MCP托管、agent构建、发布到小程序/公众号为一体的AI套件平台，打通mcp生态、agent生态、小程序/公众号生态
- https://docs.cloudbase.net/ai/mcp/develop/server-templates
  智谱
  4月15日，开源 32B/9B 系列 GLM 模型，涵盖基座、推理、沉思模型，均遵循 MIT 许可协议。该系列模型现已通过全新平台 Z.ai 免费开放体验，并已同步上线智谱 MaaS 平台
- https://mp.weixin.qq.com/s/pyeqH8jGvH_dVPmekOQ1VQ
  4月15日，根据公开信息，智谱已聘请中金公司牵头筹备首次公开募股（IPO），计划最早于今年完成上市
- https://mp.weixin.qq.com/s/QZHa1Zljn5-EmDHyijreAw
  更多

MiniMax

- 4月12日，发布MiniMax MCP Server，其视频生成、图像生成、语音生成和声音克隆等多项能力可通过MCP使用
- https://mp.weixin.qq.com/s/ZlCviVVkd-SNC_0Bb9n87g
  快手可灵
- 4月15日，可灵举行了视频生成、图像生成和多模态编辑器的可灵2.0发布会：
  1. 新发布：可灵2.0、可图2.0、多模态编辑产品、一个新交互方式MVL
  2. 核心亮点：artificial榜单第一，视频和图像生成全面领先，可以生成对口型、配音和AI音效的完整短片
  3. 产品亮点：
  4. 视频生成模型：更好的语义响应、更好的动态质量、更好的画面美学。
  5. 文生图模型：更好的指令遵循、独特的电影美学、60+风格化精准响应
  - 完整记录：可灵2.0-灵感成真发布会总结（By @陈彧婷 ）

20250414
友商
动态
OpenAI
4月11日，ChatGPT记忆功能全新升级，记忆功能可以参考过去所有聊天记录，提供更加个性化回复。
4月10日，Verge爆料OpenAI正准备发布一系列全新模型：

- GPT-4.1新模型，据称是GPT-4o多模态模型的改进版
- 与此同时，他们还会发布尺寸更小的GPT-4.1 mini和nano版本
- 此外，还有备受期待的满血版o3，以及神秘o4系模型（o4-mini、o4-mini-high）也将同时亮相
  Google

Next 2025大会上，谷歌Veo 2震撼升级，为视频的创建、编辑和视觉效果添加了一套强大的功能集，使其从一个生成工具转变为一个全面的视频创作和编辑平台
xAI
4月10日，正式上线Grok 3 API，一次性推出4种模型，以适配不同应用场景

- 定价（美元/M token）
  - grok-3-beta（标准版）：输入3，输出15
  - grok-3-fast-beta（标准版，快速响应）：输入5，输出25
  - grok-3-mini-beta（轻量版）：输入0.3，输出0.5
  - grok-3-mini-fast-beta（轻量版，快速响应）：输入0.6，输出4美元
    月之暗面
    4月10日开源了两个MoE视觉理解大模型 Kimi-VL-A3B-Instruct 和 Kimi-VL-A3B-Thinking，总参数16.4B，激活参数仅为2.8B，上下文长度128K。
- Github: https://github.com/MoonshotAI/Kimi-VL
  4月7日，模型API服务降价，约降价至原来的1/5，仍高于Doubao-pro

阿里
4月9日，新增MCP市场与相关功能（（预置MCP、社区MCP、自定义注册MCP 和 MCP体验），整体体验还不错

- 可以直接使用百炼预置的MCP服务或部署自定义MCP服务，并在智能体应用和工作流应用中引用这些 MCP 服务，使用教程：https://help.aliyun.com/zh/model-studio/mcp-quickstart
- 访问链接：https://bailian.console.aliyun.com/?tab=mcp
- (但其toD体验中心：https://chat.qwen.ai/，仍然没发布MCP体验，应该是产研团队不同导致的)
  百度
  模型更新
- 4月8日新集成 Llama-4-Maverick-17B-128E-Instruct 和 Llama-4-Scout-17B-16E-Instruct
  - 定价（元/M tokens）：限时免费，暂无定价
    功能更新
- 数据洞察新，上线提示词模板拼接（在大模型精调阶段，将结构化的提示词模板整合进训练数据，让模型快速理解任务核心要求，高效地学习任务范式，从而提升训练效果）
  更多
  Lepton AI
- 创立两年的Lepton AI被英伟达收入囊中，联创贾扬清和白俊杰，已经加入收购方英伟达
- https://www.theinformation.com/briefings/nvidia-closes-acquisition-gpu-cloud-startup-lepton
  英伟达
- 4月9日，英伟达官宣开源「超大杯」Llama Nemotron推理模型，共有253B参数，基于Llama-3.1-405B微调而来，在多项基准测试中，Llama Nemotron一举击败了两款Llama 4模型。而且仅用一半的参数，性能直逼DeepSeek R1
- https://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1

20250407
厂商
动态
OpenAI

- 3月26日，GPT-4o的原生图像生成大升级（文本渲染、多轮交互生成和指令遵循等），已经在ChatGPT和Sora中，向所有用户推出
- 3月27日，官宣其Agents SDK已支持MCP，ChatGPT与API服务的MCP支持即将发布
- 4月1日，奥特曼透露：未来几个月即将开源自GPT-2以来的首款推理模型，可在消费级硬件上运行
- 4月4日，奥特曼透露：o3和o4-mini，将在几周后推出；GPT-5，会推迟几个月再推出
  Meta
- 4月6日，发布并开源Llama 4多模态模型。首次采用MoE，支持12种语言，首批发布一共两款：
  - Llama 4 Scout：激活17B，16个专家，109B参数，10M 上下文
  - Llama 4 Maverick：激活17B，128个专家，402B参数，1M 上下文 - 在大模型竞技场（Arena），Llama 4 Maverick 的总排名第二，为开源模型第一，超越了 DeepSeek；在编程、数学、创意写作等任务中排名均为第一，大幅超越了自家 Llama 3 405B，得分从 1268 提升到了 1417。
  - 另外，Llama 4 Behemoth，激活288B，16个专家，2T参数，将在未来几个月面世
    Google

- 3月26日，发布Gemini 2.5 Pro，其为深度思考模型，1000k上下文长度，最大输出tokens长度64k。在多个基准测试中达到了SOTA水平，在常见的编程、数学和科学基准测试中均处于领先地位。
  - 定价（元 /M tokens，已转化为人民币）：- prompts≤200k：输入：8.75，输出：70 - prompts>200k：输入：17.5，输出：105

- 4月4日，官宣Gemini API支持MCP并在API文档中补充MCP使用示例代码

DeepSeek

- 3月24日发布并开源了DeepSeek-V3-0324，在数学、代码类相关评测集上取得了超过 GPT-4.5
- 4月3日，DeepSeek和清华的研究者发表论文《Inference-Time Scaling for Generalist Reward Modeling》，探讨了奖励模型的推理时Scaling方法
  - 论文地址：https://arxiv.org/abs/2504.02495
    阿里
- 3月24日，发布并开源Qwen2.5-VL新版本（Qwen2.5-VL-32B），与近期的 Mistral-Small-3.1-24B、Gemma-3-27B-IT 等模型相比，Qwen2.5-VL-32B 优势明显，甚至超越了更大规模的 72B 模型
  - 百炼定价（元/M tokens）：输入 8，输出 24
- 3月27日，发布并开源Qwen2.5-Omni，这是 Qwen 系列中全新的旗舰级多模态大模型，专为全面的多模式感知设计，可以无缝处理包括文本、图像、音频和视频的各种输入，同时支持流式的文本生成和自然语音合成输出。
  - 百炼定价（元/M tokens）：
- 发布析言MCP，让LLM以自然语言的方式访问数据库，支持远程和本地数据库，https://github.com/XGenerationLab/xiyan_mcp_server
- toD体验中心的MCP体验入口已经挂了3周了，当前还是饼（hover提示即将推出）：https://chat.qwen.ai/
- 有另一个饼，Higress 社区正在积极推动 MCP 生态的发展，计划在2025年4月中旬在 higress.ai 上提供公开的 MCP 市场：https://higress.ai/
  百度
  模型更新
- 4月3日新集成Qwen2.5-VL-32B-Instruct
  - 定价（元/M tokens）：输入 8，输出 24
- 4月1日发布ERNIE-X1-32K-Preview
  - 定价（元/M tokens）：输入 2，输出 8
    功能更新
- SFT新增支持模型DeepSeek-V3-0324
  更多
  Anthropic
- Anthropic 开源的模型上下文协议 (MCP) 在酝酿一项重要的技术革新：全面采用 Streamable HTTP 作为其核心数据传输方式，这意味着 AI 模型与外部世界的数据交互进入了一个全新的高效时代
  Midjourney
- 4月5日，Midjourney V7 Alpha发布，Midjourney称V7 Alpha版本是最聪明、最美丽、最连贯的模型，强调这次有两大更新：V7是第一个默认开启模型个性化设置的模型；另一个是「草稿模式」，被V7称为旗舰功能。
  智谱AI
- 3月31日，发布AutoGLM沉思，这一全新智能体不仅具备深度研究能力（Deep Research），还能实现实际操作（Operator）。其中核心链路的模型和技术，将于4月14日正式开源
  20250331
  友商
  动态
  OpenAI
- 3月26日，GPT-4o的原生图像生成能力升级（文本渲染、多轮交互生成和指令遵循等），已经在ChatGPT和Sora中，向所有用户推出
- 3月27日，官宣其Agents SDK已接入行业标准MCP，ChatGPT与API服务的MCP支持即将发布
  Google
- 3月26日，发布Gemini 2.5 Pro，其为深度思考模型，1000k上下文长度，最大输出tokens长度64k。在多个基准测试中达到了SOTA水平，在常见的编程、数学和科学基准测试中均处于领先地位。暂无定价，已在Google AI Studio和Gemini应用中，向Gemini Advanced用户开放，并将很快在Vertex AI上推出。
  DeepSeek
- 3月24日发布并开源了DeepSeek-V3-0324，在数学、代码类相关评测集上取得了超过 GPT-4.5
  阿里
- 3月25日，发布并开源Qwen2.5-VL新版本，与近期的 Mistral-Small-3.1-24B、Gemma-3-27B-IT 等模型相比，Qwen2.5-VL-32B-Instruct 展现出了明显的优势，甚至超越了更大规模的 72B 模型：
- 3月27日，发布并开源Qwen2.5-Omni，这是 Qwen 系列中全新的旗舰级多模态大模型，专为全面的多模式感知设计，可以无缝处理包括文本、图像、音频和视频的各种输入，同时支持流式的文本生成和自然语音合成输出。
- 发布析言MCP，让LLM以自然语言的方式访问数据库，支持远程和本地数据库，https://github.com/XGenerationLab/xiyan_mcp_server
- toD体验中心增加了MCP的体验入口（即将推出）：https://chat.qwen.ai/
  百度
  模型更新
- 3月27日，新集成DeepSeek-V3-250324 、InternVL2_5-38B-MPO（上海人工智能实验室推出的开源多模态语言模型）、Flux.1-schnell（Black Forest Labs推出的文生图）模型
  功能更新
- 模型精调扩充基础模型选择范围：RFT新增QwQ-32B、新增ERNIE-Code-3-128K、SFT新增DeepSeek-V3、Post-pretrain支持ERNIE-4.0-turbo-128K
  更多
  Anthropic
- 推出了一项突破性研究（https://www.anthropic.com/research/tracing-thoughts-language-model），用类似大脑扫描的技术，深入Claude 3.5 Haiku的「脑子」，揭开了它运行的一些秘密
- Anthropic 开源的模型上下文协议 (MCP) 在酝酿一项重要的技术革新：全面采用 Streamable HTTP 作为其核心数据传输方式，这意味着 AI 模型与外部世界的数据交互进入了一个全新的高效时代。
  Lepton AI
- 英伟达即将收购贾扬清的初创Lepton AI，交易价值或达数亿美元。https://mp.weixin.qq.com/s/ZOBpcD1s2LP1AsfOonX_5w
