https://www.anthropic.com/engineering/building-effective-agents

`非常像以前的 golang vs rust`

这是一篇非常有价值的工程实践文章，来自 Anthropic（Claude 的开发商）的工程团队，题为**《Building effective agents》（构建高效的 Agent）**。

这篇文章的核心反直觉观点是：**构建成功的 AI 应用，往往不需要复杂的框架，而是通过简单的、可组合的模式（Patterns）来实现。**

以下是对这篇文章的详细分析和讲解，我将其拆解为核心理念、架构模式和关键工程实践三个部分。

### 1. 核心理念：工作流 (Workflows) vs. 代理 (Agents)

文章首先澄清了两个容易混淆的概念，这对于架构选型至关重要：

- **工作流 (Workflows)**：
  - **定义**：通过`预定义`的代码路径来编排 LLM 和工具。
  - **特点**：路径是固定的，逻辑是确定的。
  - **适用场景**：任务定义明确，需要可预测性和一致性。
- **代理 (Agents)**：
  - **定义**：LLM `动态`地指导自己的流程和工具使用，拥有对任务执行方式的控制权。
  - **特点**：自主决策，路径不固定。
  - **适用场景**：需要灵活性、模型驱动决策，且任务规模较大、难以预判步骤的场景。

**关键建议**：**如无必要，勿增实体。** 应该从简单的 LLM 调用开始，然后是工作流，最后才是自主代理。代理虽然强大，但会增加延迟、成本和错误累积的风险。

---

### 2. 五种核心架构模式 (Building Blocks & Patterns)

文章列举了从简单到复杂的五种常见模式，这是文章的精华部分：

#### A. 提示词链 (Prompt Chaining)

- **原理**：将任务分解为一系列步骤，上一步的输出作为下一步的输入。
- **图示**：`Input -> LLM Step 1 -> LLM Step 2 -> Output`
- **适用**：任务可以被清晰地分解为固定的子任务。
- **例子**：先生成营销文案，然后将其翻译成另一种语言。

#### B. 路由 (Routing)

- **原理**：先对输入进行分类，然后将其引导至专门的后续任务/提示词。
- **图示**：`Input -> Router (LLM/Code) -> [Task A | Task B | Task C]`
- **适用**：任务包含不同的类别，且不同类别需要不同的处理逻辑或工具。
- **例子**：客服系统将用户问题分类为“退款”、“技术支持”或“一般咨询”，然后分别处理。

#### C. 并行化 (Parallelization)

- **原理**：同时运行多个 LLM 任务，然后聚合结果。
  1.  **分段 (Sectioning)**：将大任务切分，并行处理（如同时检查多个安全规则）。
  2.  **投票 (Voting)**：对同一任务运行多次，以获得多样化的结果或提高准确度。
- **适用**：需要速度（分段）或需要高置信度/多视角（投票）。
- **例子**：代码漏洞扫描，使用多个不同的提示词同时检查代码，只要有一个发现问题就报警。

#### D. 编排器-工人 (Orchestrator-Workers)

- **原理**：一个中心化的“编排器”LLM 动态分解任务，分配给“工人”LLM，最后综合结果。
- **图示**：`Orchestrator -> [Worker 1, Worker 2, ...] -> Synthesizer`
- **区别**：与并行化不同，这里的子任务不是预定义的，而是由编排器根据输入动态决定的。
- **适用**：复杂任务，无法预知需要多少个子步骤或什么样的子步骤。
- **例子**：修改一个复杂的代码功能，编排器决定需要修改哪些文件，然后让工人分别去修改每个文件。

#### E. 评估器-优化器 (Evaluator-Optimizer)

- **原理**：一个 LLM 生成回复，另一个 LLM 进行评估和反馈，形成循环迭代。
- **图示**：`Generator -> Evaluator -> (Feedback) -> Generator`
- **适用**：有明确的评估标准，且通过迭代反馈能明显提升质量的场景。
- **例子**：文学翻译（翻译 -> 评审指出语病 -> 修正翻译）。

---

### 3. 真正的“代理” (The Autonomous Agent)

当上述模式都无法满足需求时，才考虑使用全自主代理。

- **工作方式**：循环模式（思考 -> 规划 -> 执行工具 -> 观察结果 -> 再思考）。
- **关键**：代理必须从环境中获得“基本事实”（Ground Truth）反馈（如代码运行报错、API 返回结果），以修正自己的路径。
- **风险**：容易陷入死循环或产生幻觉，需要设置停止条件（如最大迭代次数）和沙箱环境。

---

### 4. 关键工程实践：工具的提示工程 (Prompt Engineering your Tools)

文章的附录部分提出了一个非常深刻的概念：**ACI (Agent-Computer Interface)**。

就像我们需要设计良好的 HCI (人机交互界面) 一样，我们需要为 AI 设计良好的 ACI。

- **工具定义即提示词**：工具的描述、参数名、参数说明，本质上都是提示词的一部分。
- **格式选择**：
  - 选择模型容易生成的格式。例如，让模型写 JSON 代码通常比写 Markdown 表格更难（因为需要转义引号和换行）。
  - **防错设计 (Poka-yoke)**：如果模型经常用错某个参数（例如用相对路径找不到文件），直接修改工具定义，强制要求使用绝对路径，而不是仅仅在提示词里以此以此劝说模型。
- **测试**：在 Workbench 中大量测试模型对工具的调用情况，像调试代码一样调试工具定义。

### 总结

这篇文章是对当前 AI 开发趋势的一种“纠偏”。它告诉开发者：

1.  **不要迷信复杂的 Agent 框架**（如 LangChain 的某些复杂抽象），直接使用 LLM API 往往更清晰、更易调试。
2.  **从简单的模式（链式、路由）做起**，这些往往能解决 80% 的问题，且更稳定、更便宜。
3.  **把精力花在“上下文工程”和“工具定义”上**，而不是花在复杂的编排逻辑上。

结合你当前打开的文件《Effective context engineering for AI agents》，可以看出 Anthropic 的整体工程哲学是：**清晰的上下文 + 简单的架构模式 + 精细的工具定义 = 高效的 AI 应用。**
