# 低成本构建代码专属知识库-让仓库自己给 AI 讲故事

针对前端仓库开发的 AI 知识库构建工具，旨在解决 LLM 在理解复杂大型前端项目时的上下文缺失问题。

### 1. 核心痛点与解决方案

| 痛点 (Problem)   | 现状与挑战                                                            | DeepWiki 的破局思路                                                                                  |
| :--------------- | :-------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------- |
| **上下文缺失**   | LLM 只能看到当前代码，缺乏对产品背景、公司特有基建、整体架构的理解。  | **多维知识融合**：不仅分析代码，还融合公司基建文档、历史需求、业务逻辑。                             |
| **召回准确率低** | 传统的“代码直接向量化”方案，在语义召回时（RAG）经常导致不准确的结果。 | **结构化转换**：不直接存代码，而是先将代码转化为“结构化、自然语言描述的技术文档”，再进行向量化存储。 |
| **架构幻觉**     | 前端仓库架构范式固定（如 Monorepo），AI 此时容易产生幻觉或不稳定。    | **定制化解析**：针对前端架构（Monorepo、路由系统、组件库）进行特定规则的深度解析。                   |

### 2. 技术实现原理 (What it does)

DeepWiki 的核心在于**“从代码到知识的萃取”**，它不是简单的代码索引，而是一个“翻译+图谱构建”的过程。

#### A. 深度工程挖掘 (静态分析 + LLM 总结)

- **Monorepo 感知**：识别 EMO/Rush/Pnpm 结构，厘清子项目依赖关系。
- **路由/页面分析**：自动解析 React Router/EdenX/PIA/Lynx 路由，映射“URL -> 页面文件 -> 组件依赖”。
- **基础库拆解**：针对 UI 组件库或工具库，自动生成 API 文档和实现原理。

#### B. 动态知识图谱

- **业务历史提取**：关联 SCM 提交记录与 需求卡片，回答“这段代码为什么这么写（业务背景）”。
- **基建知识融合**：通过 MCP 接入官方文档（如 Lynx MCP），当扫描到特定依赖时，自动补充官方用法上下文，减少幻觉。

#### C. 数据流向

`源代码 + 历史提交 + 外部文档` -> **DeepWiki 解析引擎** -> `结构化文档/知识图谱` -> **MCP Server** -> `IDE (Trae/Cursor) / Agent`

### 3. 评测表现 (Why it's better)

文章列举了两个关键的评测维度，证明了其优越性：

1.  **SDMA-WikiBench (召回能力)**

    - **结论**：在召回准确率（Recall）和排序质量（nDCG）上，DeepWiki 远超 Devin DeepWiki 和通用方案。
    - **数据亮点**：在内场数据集上，**Recall_10 达到 88.24%**；在 `alibaba/hooks` 仓库上，nDCG 甚至达到了 **1.000**。这说明其生成的文档极其精准地描述了代码功能。

2.  **消融实验 (实际改 Bug 效果)**
    - **场景**：文娱平台修复 Bug。
    - **对比**：
      - **Claude-3.5-Sonnet**：无 RAG (0%) -> **有 Wiki RAG (85%)**。
      - **Gemini-2.5**：无 RAG (0%) -> **有 Wiki RAG (50%)**。
    - **意义**：证明了高质量的仓库知识上下文对于 AI 解决复杂 Bug 起到了决定性作用。

### 4. 接入与使用场景

- **接入**：通过 TMates 平台触发构建，支持 CI/CD 集成。
- **消费场景**：
  1.  **AI IDE 编程**：通过 **MCP (Model Context Protocol)** 协议，将 DeepWiki 挂载到 Trae 或 Cursor 中。`当你提问时，IDE 会通过 MCP 从 DeepWiki 检索精准的上下文发给 LLM。`
  2.  **新人入职/文档查询**：作为问答机器人，解释“这个模块是干嘛的”、“这个页面路由在哪”。
  3.  **技术方案生成**：辅助 Arch Agent 生成重构或新需求的技术方案。

### 总结

**DeepWiki 的本质是“代码的翻译官”。**
普通的 RAG 是把书（代码）撕碎了喂给 AI，DeepWiki 是先把书读一遍，写成一份逻辑清晰的“读书笔记”（结构化文档），再把这份笔记喂给 AI。
对于字节开发者而言，这意味着在 Trae/Cursor 中写代码时，AI 不再是“只懂语法的新手”，而是“懂业务、懂架构、懂公司基建的资深同事”。

# 业务知识库最佳实践

这是一篇关于 **"如何将通用的代码知识库进化为业务专属专家"** 的最佳实践指南。

如果说前一篇文章介绍了 DeepWiki "是什么"（基础设施），那么这篇文章则重点讲解了 "怎么用好"（运营与调优）。它核心解决的问题是：通用 AI 只能读懂代码逻辑，但读不懂团队约定和业务黑话。

以下是对该实战指南的深度拆解：

### 1. 核心目标：从 "读懂代码" 到 "懂业务、懂规范"

| 阶段         | DeepWiki 的状态                                            | AI 的表现                                               | 存在问题                                                                                    |
| :----------- | :--------------------------------------------------------- | :------------------------------------------------------ | :------------------------------------------------------------------------------------------ |
| **初始构建** | 只有代码分析、自动生成的架构图、历史 PRD                   | 能写出语法正确的代码，能理解架构                        | 不懂业务黑话（如"宣推卡"），不懂团队潜规则（如"必须用 hooks 不能用 class"），不懂环境怎么跑 |
| **调优后**   | + 业务名词解释<br>+ 开发规范 (`.tmates`)<br>+ 关键飞书文档 | **像一个入职 3 年的资深员工**，知道什么能做、什么不能做 | 极大减少代码 Review 的返工率                                                                |

### 2. "调教" AI 的三大法宝 (Implementation)

文章提出了三种核心手段来向 DeepWiki 注入"灵魂"（业务知识），这实际上构建了一个**分层的知识体系**：

#### A. 显式规范注入：`.tmates` 目录（Config as Code）

这是最硬核、最直接的手段。通过在仓库根目录建立标准的 `.tmates` 结构，将隐性的"口口相传"的知识显性化。

- **`01_project_rules/` (工程侧)**：
  - **环境/启动 (`node_environment.md`, `project_startup.md`)**：解决 AI 经常给出的启动命令报错问题。
  - **代码规范 (`dev_spec.md`, `ui_components.md`)**：强制 AI 遵循团队风格（例如：Table 组件必须用公司封装的 `XTable` 而不是开源的 `Antd Table`）。
- **`02_business/` (业务侧)**：
  - **黑话词典 (`terminology.md`)**：解释业务名词。当 Prompt 提到 "增加一个 B 号展示" 时，AI 能通过此文档理解 "B 号" 代表具体的 ID 字段。

#### B. 历史知识回溯：飞书文档上传

针对由于篇幅过长或格式原因不适合放入 Git 的文档（如详细的产品方案、复杂的架构演进 PPT），通过平台上传并**打标**。这弥补了 Git 仓库中只有"结果"（代码）没有"过程"（设计思考）的缺陷。

#### C. 路由指引：`AGENTS.md`

这是一个非常巧妙的设计。它相当于给 AI 的 **"寻路地图 (Routing)"**。

- **原理**：AI 有时不知道去哪里找答案。
- **用法**：在 `AGENTS.md` 中写明映射关系。
- **示例**：`"关于表格页面的修改，请参考 .tmates/docs/01_project_rules/ui_components.md"`。
- **作用**：显著提升 RAG 的召回准确率，防止 AI 在浩如烟海的文档中迷路。

### 3. "开发-验证" 闭环 (The Loop)

文章强调了知识库不是"建成即忘"的，而是一个持续迭代的过程：

1.  **注入知识**：提交 `.tmates` 文件或上传文档。
2.  **触发更新**：点击平台上的"更新业务知识"（注意：这是轻量级更新，3-5 分钟生效，无需全量重构 DeepWiki）。
3.  **RAG 调试 (Debug)**：这是保证效果的关键步骤。
    - **`search_knowledge`**：检查**切片召回**。看你问的问题，AI 是否真的找到了你刚才写的那个 `.md` 文件。如果不准，说明关键词或文档结构需要调整。
    - **`search_knowledge_sm`**：检查**总结能力**。看 AI 拿到文档后，回答是否符合预期。

### 4. 最佳实践总结与建议

对于想要接入的团队，建议遵循以下 roadmap：

1.  **Level 1 (快速接入)**：
    - 在 TMates 平台开启一键构建。
    - 获得基础的代码理解和自动文档。
2.  **Level 2 (规范对齐)**：
    - 创建 `.tmates/docs/01_project_rules`。
    - 放入 `dev_spec.md` (开发规范) 和 `ui_components.md` (组件库使用说明)。
    - _收益：AI 生成的代码风格统一，不再胡乱引入外部依赖。_
3.  **Level 3 (业务专家)**：
    - 创建 `02_business/terminology.md`，定义业务术语。
    - 编写 `AGENTS.md` 指引复杂场景。
    - _收益：能够处理复杂的业务需求，理解 PRD 中的简写和术语。_

通过这种方式，DeepWiki 将不再是一个冷冰冰的文档索引工具，而是一个真正理解你所在业务线上下文的 "AI 结对编程伙伴"。

# DeepResearch: 让 AI Friendly 变得更简单

DeepResearch 的核心在于利用 **Multi-Agent（多智能体）架构** 来模拟人类专家的研究流程，并通过 **知识归一化** 策略建立起业务知识的自我进化闭环。下面我们分两部分详细拆解。

## 一、技术实现：三层 Multi-Agent 架构

传统的 AI 对话往往是“单线程”的，即理解问题 -> 检索上下文 -> 生成答案。而 DeepResearch 采用了更复杂的 **规划-执行-生成** 三层架构，模拟了人类解决复杂问题的思维模式：先想怎么做，再根据计划去调研，最后根据调研结果写报告。

### 1. Plan 层 (Planner Agent) —— “大脑”与“指挥官”

- **核心职责**：根据用户输入，制定详细的行动指南。
- **工作机制**：
  - **意图理解**：首先分析用户的输入（是生成文档？修复 Bug？还是写技术方案？）。
  - **背景知识推断**：判断需要哪些“元知识”。例如，用户如果问“怎么使用 A 组件”，Planner 会意识到需要查询“组件库文档”、“仓库依赖关系”以及“该组件在现有代码中的用法”。
  - **制定计划**：生成一个分步骤的搜索计划（Search Plan）。这个计划不是一步到位的，而是分阶段的（例如：Step 1 查文档，Step 2 查代码，Step 3 查历史 commit）。

### 2. Search 层 (Search Agent) —— “调研员”与“侦探”

- **核心职责**：执行 Planner 指定的搜索计划，从海量信息中挖掘精准事实。
- **工作机制**：
  - **深度知识检索 (DeepWiki)**：这是它的第一手资料库。它会利用 DeepWiki 检索业务知识、仓库架构、模块关系等高层信息。
  - **跨仓库知识映射**：这是其强大之处。当遇到引用了其他仓库（如 Shared 组件库）的情况时，它能识别映射关系，自动跳转到对应仓库的知识库中检索（例如：查到代码用了 `@byted-growth/zebra-shared`，自动去该库的文档里找用法）。
  - **实时代码阅读 (Sandbox)**：它拥有一个沙盒环境，可以像开发者在 IDE 里一样实时阅读代码。
  - **智能工具链**：为了提升效率，它不会只用笨重的 `grep`。它可以调用 `RepoSearch` 等实时检索工具，结合 Glob 模式匹配，精准定位关键代码片段。

### 3. Generator 层 (Generator Agent) —— “作家”与“架构师”

- **核心职责**：基于调研结果，撰写最终产物（文档、方案或修复代码），并进行自我审视。
- **工作机制**：
  - **基于事实写作**：它将 Search Agent 提供的 Search Result 作为“第一手知识”，确保生成的内容有据可依，减少幻觉。
  - **边写边查 (Iterative Retrieval)**：这是模仿人类的关键行为。在写作过程中，如果发现某个细节 Search Agent 漏掉了（例如：写到一半发现不知道某个参数的类型），Generator 会即使挂起写作任务，再次调用 DeepWiki 或 RepoSearch 进行“补查”。
  - **结构化输出**：最终按照用户要求的格式（如 Markdown PRD、代码 Diff 等）生成高质量内容。

---

## 二、Why We Better：知识归一化与业务知识内循环

市面上的许多 AI 辅助工具往往面临**“知识孤岛”**和**“时效性差”**的问题——文档在飞书，代码在 GitLab，PRD 在 Meego，且代码更新了文档却没变。

DeepResearch 的核心优势在于建立了一套 **“知识归一化”** 体系，让代码和文档相互促进，形成闭环。

### 核心策略：5 步闭环

这个闭环解决了 AI 构建“友好型仓库”（AI Friendly）的最大痛点：**冷启动困难**。

1.  **构造图谱 (初始化)**

    - 用户一键触发，DeepWiki 会扫描代码仓库，自动提取代码结构、依赖关系、调用链路，生成一份**代码专属的知识图谱**。这是 AI 理解代码的基石。

2.  **接入沉淀 (知识注入)**

    - 将现有的外部文档（如飞书文档、Wiki）接入系统。系统会将这些非结构化的文档与步骤 1 中的代码实体建立关联（例如：将“登录接口文档”关联到 `LoginController` 代码）。

3.  **补充缺失 (AI 反哺)**

    - **关键点**：这是 DeepResearch 发挥作用的环节。如果发现某个重要模块缺乏文档，或者需要一份 `AGENTS.md` 开发规范，使用 `DeepResearch 自动生成`。这不仅是辅助研发，更是**为 AI 自己生产高质量的知识**。

4.  **自主进化 (动态更新)**

    - 代码是流动的。DeepWiki 支持增量更新，每当代码提交或步骤 3 补充了新文档，这些新知识会立即融入知识图谱。**知识库紧跟代码速度，永不过时**。

5.  **赋能 AI (RAG 应用)**
    - 最终，这个不断自我完善、内容归一化（代码+文档+规范）的图谱，通过 RAG（检索增强生成）技术反哺给 AI。当 AI 再次回答问题时，它拥有了最新、最全的上帝视角。

### 总结

DeepResearch 之所以更好，是因为它不仅仅是一个“问答机器人”，而是一个**知识生产与管理的生态系统**。它通过 Multi-Agent 架构解决了“怎么查、怎么写”的执行力问题，通过知识归一化策略解决了“数据从哪来、如何保鲜”的资源问题。
