# 为什么我们需要 Context Engineering？ - 周星星的文章 - 知乎

https://zhuanlan.zhihu.com/p/1953085369328337945

好的，我们来详细深入地讲解这个关于“上下文工程 (Context Engineering)”的课程大纲。这个大纲非常有前瞻性，它将构建高级 AI 应用所需的核心技术系统化地组织了起来。

### 核心概念：什么是上下文工程 (Context Engineering)？

基础知识+综合运用(agent)

首先，我们需要理解“上下文工程”的本质。

大语言模型 (LLM) 就像一个极其聪明但失忆的“大脑”。它本身拥有强大的通用知识和推理能力，但它对“当前”一无所知。它不知道你是谁，不知道你正在处理什么任务，也无法访问外部世界的实时信息。

**上下文工程 (Context Engineering) 就是一门研究如何为这个“大脑”高效、精准、动态地提供“上下文 (Context)”的系统性学科。**

这个“上下文”可以是一切能帮助 LLM 更好完成任务的信息，包括：

- **指令 (Instructions)**: 你希望它做什么 -> Prompt Engineering
- **知识 (Knowledge)**: 完成任务所需的背景信息 -> 知识库、RAG (Retrieval-Augmented Generation)
- **记忆 (Memory)**: 过去的对话历史或任务状态 -> Memory Management
- **工具 (Tools)**: 它可以使用的外部能力 -> MCP (Model Context Protocol) 和工具调用
  MCP 只解决了工具调用这一块。Agent 的核心功能如任务规划、上下文管理，你还得自己动手

这门课程的安排，正是围绕着如何构建和管理这四类上下文展开的。下面我们来逐一拆解。

---

### 课程大纲深度解析

#### 第一部分 (2 周): 提示工程 (Prompt Engineering) - 基础对话的艺术

- **讲解内容**:

  - **是什么**: 这是上下文工程的基石。它研究如何通过精心设计的自然语言指令，来引导和约束 LLM 的行为，以获得期望的输出。
  - **为什么重要**: Prompt 是向 LLM 传递**静态指令上下文**最直接的方式。一个好的 Prompt 能极大提升模型输出的质量、相关性和稳定性。
  - **核心知识点**:
    1.  **基础技巧**: 零样本 (Zero-shot)、少样本 (Few-shot) 提示，如何提供清晰的指令、角色扮演 (Persona)、设定输出格式 (JSON, Markdown)。
    2.  **高级技巧**: 思维链 (Chain-of-Thought, CoT) 引导模型进行分步推理；自洽性 (Self-Consistency) 通过多次生成和投票提高答案准确性。
    3.  **结构化提示**: 如何设计复杂的、包含多个部分的 Prompt 模板，以应对复杂任务。

- **课程目标**: 学生将掌握与 LLM 进行有效“对话”的基本功，能够编写出高质量的 Prompt，为后续更复杂的上下文管理打下基础。

#### 第二部分 (3 周): 检索增强生成 (RAG) - 赋予模型外部知识

- **讲解内容**:

  - **是什么**: RAG 是一种让 LLM 具备“开卷考试”能力的技术。当遇到需要外部知识的问题时，系统会先从一个知识库（如公司文档、网页、数据库）中检索出最相关的信息，然后将这些信息作为上下文喂给 LLM，让它基于这些信息来生成答案。
  - **为什么重要**: RAG 解决了 LLM 知识陈旧和无法访问私有数据两大痛点。它是提供**动态知识上下文**的核心技术。
  - **核心知识点**:
    1.  **数据处理与索引 (Indexing)**: 如何将非结构化文档（PDF, Word）切分成小块 (Chunking)，并使用嵌入模型 (Embedding Model) 将其向量化，存入向量数据库。
    2.  **检索 (Retrieval)**: 学习不同的检索策略，如语义相似度搜索、关键词搜索，以及更高级的混合搜索、重排 (Re-ranking) 技术，以确保找到最相关的信息。
    3.  **生成 (Generation)**: 如何将检索到的上下文与原始问题整合成一个有效的 Prompt，并交给 LLM 生成最终答案。

- **课程目标**: 学生将能从零开始构建一个完整的 RAG 系统，让 AI 应用能够基于特定的、最新的外部知识库进行问答。

#### 第三部分 (3 周): 记忆 (Memory) - 让模型记住你是谁

- **讲解内容**:

  - **是什么**: “记忆”机制旨在解决 LLM 在多轮对话或长任务中“失忆”的问题。它负责存储和管理对话历史、用户偏好、任务中间状态等信息。
  - **为什么重要**: 记忆是提供**时间序列上下文**的关键。没有记忆，AI Agent 无法执行需要多个步骤的复杂任务，也无法提供个性化的交互体验。
  - **核心知识点**:
    1.  **短期记忆**: 如何管理和截断最近的对话历史，以适应有限的上下文窗口（如滑动窗口）。
    2.  **长期记忆**: 如何将重要的信息（如用户画像、关键事实）进行总结并存入向量数据库，在需要时通过 RAG 的方式检索回来，作为长期记忆。
    3.  **结构化记忆**: 如何设计专门的数据结构来存储任务状态，例如任务规划树、已完成步骤列表等。

- **课程目标**: 学生将掌握为 AI Agent 设计和实现记忆系统的方法，使其能够处理长程、复杂、需要状态保持的任务。

#### 第四部分 (3 周): 工具 (Tools) 与 MCP - 赋予模型行动能力

- **讲解内容**:

  - **是什么**: “工具”是 LLM 可以调用的外部函数或 API。通过工具，LLM 不再只是一个“说话者”，而是一个“行动者”，可以查询天气、发送邮件、执行代码、操作数据库等。MCP (模型上下文协议) 则是标准化这些工具调用流程的协议。
  - **为什么重要**: 工具提供了**交互式上下文**，让 LLM 能够与外部世界进行实时互动并获取最新信息，极大地扩展了其能力边界。
  - **核心知识点**:
    1.  **工具定义与注册**: 如何用 LLM 能理解的方式（通常是 JSON Schema）来描述一个工具的功能、输入参数和输出。
    2.  **工具调用循环 (ReAct/Agent Loop)**: 学习 LLM 如何进行“思考 -> 决定调用工具 -> 执行工具 -> 观察结果 -> 继续思考”的循环，以完成任务。
    3.  **MCP 协议**: 深入理解 MCP 的客户端-服务器架构，学习如何构建 MCP Server 来暴露工具，以及 AI 应用如何作为 MCP Client 来发现和调用这些工具。

- **课程目标**: 学生将能够为 LLM 开发和集成外部工具，并理解 MCP 如何将工具生态标准化，构建出能与真实世界交互的 AI Agent。

#### 第五、六、七部分: 框架、评估与实践

这三个部分是将前面学到的理论知识进行整合、评估和应用的阶段。

- **主流 Agent 框架 (2 周)**:

  - **内容**: 学习 LangChain, LlamaIndex, CrewAI 等主流 Agent 开发框架。这些框架已经将 RAG、Memory、Tools 等模块封装好，可以大大加速开发进程。
  - **目标**: 避免重复造轮子，学会站在巨人的肩膀上快速构建复杂的 AI Agent。

- **Agent 评估 (2 周)**:

  - **内容**: 如何科学地评估一个 Agent 的性能？学习评估指标（如任务完成率、答案准确性、工具调用效率）和评估方法（如使用 RAGAS, TruLens 等评估框架，构建评估数据集）。
  - **目标**: 培养学生的工程思维，知道如何量化地衡量和迭代优化自己构建的 Agent 系统。

- **实际案例拆解 (2 周)**:
  - **内容**: 深入分析业界顶级的 AI 应用，如 **Claude Code**（代码生成与修改）、**Deep Research**（自动化研究报告）。
  - **目标**: 将前面所有学到的知识点串联起来，看它们在真实的、复杂的产品中是如何被综合运用的。例如，分析 Claude Code 如何进行任务拆分（Memory）、如何读写文件（Tools），以及如何理解整个代码库（RAG）。

### 总结

这个课程大纲的设计非常精妙，它完美地勾勒出了“上下文工程”这门新兴学科的知识图谱。它从最基础的 Prompt 开始，层层递进，系统性地教会学生如何通过 RAG、Memory、Tools 等技术，为 LLM 构建一个丰富、动态、可交互的上下文环境，最终打造出真正智能和实用的 AI Agent。这确实是一门面向未来的、含金量极高的课程。

---

好的，这是一篇关于“上下文工程 (Context Engineering)”的深度好文。它系统性地阐述了这门新兴学科的定义、重要性、核心挑战以及实战方法论。我将为你进行详细、深入的讲解。

---

### 深度解析：《上下文工程 (Context Engineering)》

这篇文章的核心论点是：随着 AI 从简单的聊天机器人演变为能执行复杂任务的智能体 (Agent)，我们不能再像过去一样简单地处理“上下文”。**上下文工程 (Context Engineering) 是一门系统性的学科，它研究如何从全局视角，动态地组织、筛选、压缩和隔离信息，从而为 AI Agent 在任务的每一步都提供最高效、最精准的上下文，以最大化整体任务的成功率。**

以下是文章各部分的详细解读：

#### 1. 什么是上下文工程？(The "What")

文章开篇就用一个绝佳的比喻给出了定义：

- **场景**: 想象一个复杂的任务被拆分给多个子智能体 (sub-Agent) 协同完成。
- **问题**: 当轮到其中一个子智能体（红色框）工作时，我们必须解决以下问题：
  1.  **信息注入**: 如何把其他子智能体（绿色框）的有用成果，有效地传递给当前智能体？
  2.  **信息选择**: 如何根据当前任务，从外部知识库、记忆、工具中，挑选最相关的信息？
  3.  **信息压缩**: 如果上下文太长，如何智能地删减或总结，只保留核心？
  4.  **信息保存**: 当前智能体产生了什么有价值的中间结果，需要被保存下来，供后续的智能体使用？

**一句话总结：上下文工程就是 AI Agent 系统的“交通指挥官”和“信息调度中心”，它确保在正确的时间，将正确的信息，以正确的格式，传递给正确的执行单元。**

#### 2. 为什么现在需要上下文工程？(The "Why")

- **发展的必然**: 过去我们用 LLM 做简单聊天，上下文管理很简单。但现在，随着 GPT-5/Claude-4 级别模型的出现和复杂 Agent 架构（如 Deep Research 工作流）的普及，AI 正从“玩具”走向“生产力工具”。
- **问题的根源**: 大多数 Agent 失败，**不是因为模型不够聪明，而是因为我们没给它提供正确的上下文**。
- **概念的诞生**: “上下文工程”这个术语的出现，是为了给这套复杂的、动态管理信息的方法论一个清晰的定义，便于行业交流和沉淀最佳实践。Shopify CEO 和 Andrej Karpathy 等行业领袖的推动，加速了这一概念的普及。

#### 3. 上下文工程 vs. 提示工程 (The "Difference")

这是一个关键的区别：

- **提示工程 (Prompt Engineering)**: 是上下文工程的**子集**。它更关注如何**静态地**构建一个完美的 Prompt，包括指令、用户输入、少量示例等。它是一次性的、针对单个请求的优化。
- **上下文工程 (Context Engineering)**: 解决的是**动态的、系统性的问题**。它关注的是在 Agent 执行任务的**整个生命周期**中，信息如何在不同步骤、不同子智能体之间流动、筛选和演变。它管理的是一个信息流，而不仅仅是一个信息点。

**简单比喻：提示工程是教你如何写一封完美的信；而上下文工程是教你如何管理一个大型项目的所有来往邮件、会议纪要和文档库。**

#### 4. 核心痛点：上下文的“金发姑娘”难题 (The Goldilocks Problem)

上下文工程要解决的核心矛盾是：上下文**不能太长，也不能太短**，必须恰到好处。

- **太长不行 (信噪比低)**:

  - **性能下降**: 即使模型号称支持百万级上下文，在实际复杂任务中，上下文一旦过长（如超过 32K），模型就会“迷失”，过度关注局部、忽略全局，甚至输出乱码。
  - **上下文损坏 (Context Corruption)**:
    1.  **干扰 (Distraction)**: 无关的历史信息（如之前的报错记录）干扰了模型对新任务的理解。
    2.  **冲突 (Clash)**: 上下文中包含相互矛盾的信息（如用户既喜欢极简风又喜欢中式红木），让模型无所适从。
    3.  **中毒 (Poisoning)**: 上下文中的一个错误信息（幻觉）被模型当成事实，导致后续推理全错。
    4.  **混淆 (Confusion)**: 过多的冗余信息影响了模型的判断。

- **太短不行 (信息不足)**:
  - 如果只给 Agent 最基本的用户请求，它只能做出机械、刻板的反应。
  - 一个优秀的 Agent 需要丰富的上下文（如日历、历史邮件、联系人信息）才能做出智能、人性化的决策。

#### 5. 上下文工程实战体系 (The "How")

文章引用了 LangChain 核心开发者 Lance Martin 的分类，将上下文工程的实践分为四大模块：

**A. 写入上下文 (Write Context): 将有价值的信息保存下来**

- **目的**: 把当前 Agent 产生的、对未来步骤或其他 Agent 有用的信息，保存到上下文窗口之外，以备后用。
- **方法**:
  1.  **长期记忆 (Long-term Memory)**: 跨对话、跨会话的记忆。例如，OpenAI 的记忆功能，能记住你过去几周的对话内容。技术上通常通过 RAG 实现。
  2.  **草稿本 (Scratchpads)**: 单次任务内的“草稿纸”。Agent 先把任务计划写到一个 `todo.md` 文件里，然后在执行过程中不断回顾和修改这个计划。
  3.  **状态 (State)**: 在 LangGraph 等框架中，将任务的关键中间变量（如 `todo_list`, `current_step`）作为独立的状态变量，在整个工作流中传递和更新，与主对话流分离。

**B. 选择上下文 (Select Context): 在需要时，精准地调取信息**

- **目的**: 从海量信息中，只把当前任务最需要的部分拉入上下文窗口。
- **方法**:
  1.  **检索相关工具 (Retrieve relevant tools)**: 当工具有上百个时，通过 RAG 的方式，只检索并提供与当前用户意图最相关的几个工具，避免模型混淆。
  2.  **从草稿本/长期记忆中检索**: 根据当前任务，从之前“写入”的记忆或草稿中，检索出相关信息。例如，当用户点餐时，从长期记忆中检索出他是“素食主义者”。
  3.  **检索相关知识 (Retrieve relevant knowledge)**: 这就是经典的 RAG，从外部知识库中检索信息。

**C. 压缩上下文 (Compress Context): 为上下文“瘦身”**

- **目的**: 当上下文过长时，智能地减少其内容，同时保留核心信息。
- **方法**:
  1.  **总结 (Summarize)**: 当对话历史过长时，自动将其总结成一段简短的摘要，替换掉原文。Claude Code 在上下文达到 95%时会自动执行此操作。
  2.  **裁剪 (Trim)**: 直接丢弃部分信息（如最早的几轮对话），或者更精细地，通过算法去除语气词、无关句子，只保留核心实体和关系。

**D. 隔离上下文 (Isolate Context): 避免不必要的干扰**

- **目的**: 将任务或上下文拆分，让 Agent 能在“干净”的环境中专注执行。
- **方法**:
  1.  **在状态中分区 (Partition in state)**: 利用 State 机制，不同的子 Agent 只访问和操作与自己相关的状态变量，而不是把所有信息都混在主对话流里。
  2.  **在沙箱中执行 (Hold in environment/sandbox)**: Smol-agents 框架的思想。将一个复杂的任务（如“计算各国手机价格并找到最便宜的”）转换成一段 Python 代码，在一个隔离的沙箱环境中一次性执行。这避免了传统 Agent 多轮、冗长且易错的工具调用链。
  3.  **在多智能体间分区 (Partition across multi-agent)**: 这是多智能体架构的天然要求。例如，一个“评估 Agent”在工作时，只需要看到“待评估的答案”和“评估标准”，完全不需要知道前面的“搜索过程”，把搜索过程的上下文传给它只会造成干扰。

#### 6. 番外篇：Single-Agent vs. Multi-Agent 之争

这部分探讨了与上下文工程密切相关的架构选择问题。

- **Multi-Agent 的优势 (Anthropic 观点)**:

  - **更适合广度优先任务**: 当一个任务需要同时探索多个独立方向时（如做深度研究），多智能体表现更好。
  - **更有效地消耗 Token**: 核心优势不是“花更多钱”，而是能把 Token 预算**合理地分配**给多个子任务。每个子任务都在一个较短、不易出错的上下文中运行，从而提高了 Token 的利用效率。

- **Multi-Agent 的劣势 (Cognition/Devin 观点)**:

  - **缺乏全局上下文，易产生冲突**: 像两个人同时修改一份代码，子智能体并行工作时，由于看不到彼此的成果，很容易产生风格不一、逻辑冲突的结果。
  - **Cognition 的实践**: Devin 采用的是强大的单智能体模型，认为这才是未来。

- **作者的预测**:
  - **不存在唯一最优解**: 技术仍在演进。
  - **基模公司的倾向**: OpenAI、Kimi 等公司相信 Scaling Law，倾向于训练一个超级强大的单智能体模型来解决一切。
  - **理想模式**: 未来可能是**以一个强大的单智能体为核心，辅以少数几个专门处理广度优先任务的子智能体**的混合模式。

### 总结

这篇文章高屋建瓴地定义了“上下文工程”这一关键领域。它告诉我们，构建高级 AI Agent 的核心，已经从单纯追求模型能力，转向了**如何设计一个精巧的信息调度系统**。通过**写入、选择、压缩、隔离**这四大手段，我们可以动态地为 AI Agent 的每一步都构建出“恰到好处”的上下文，从而在根本上提升其解决复杂问题的能力。这确实是一门值得所有 AI 从业者深入学习的系统性学科。
