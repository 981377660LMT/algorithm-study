基于您提供的文本，这是对**提示工程指南（Prompt Engineering Guide）**开篇介绍部分的专业讲解与核心要点提炼。

这段内容确立了提示工程作为一门**学科**的地位，并阐述了它对于不同角色的意义。

---

### 第一章：提示工程概论 (Introduction to Prompt Engineering)

#### 1. 核心定义：什么是提示工程？

提示工程（Prompt Engineering）不仅仅是简单的“提问”，它被定义为一门**较新的学科 (New Discipline)**。

- **核心目标：** 开发和优化提示（Prompts），以便高效地将大语言模型（LLM）应用于各种场景和研究领域。
- **深层价值：** 掌握这项技能有助于我们更深刻地理解大语言模型的**能力边界（Capabilities）**与**局限性（Limitations）**。

#### 2. 不同角色的应用视角

文本明确区分了研究人员和开发者在提示工程上的不同侧重点：

- **对于研究人员 (Researchers):**
  - 侧重于**提升模型能力**。
  - 通过提示工程，让 LLM 能够处理更广泛、更复杂的任务，例如高难度的问答（QA）和算术推理（Arithmetic Reasoning）。
- **对于开发者 (Developers):**
  - 侧重于**构建稳健的应用**。
  - 利用提示工程设计有效且鲁棒的技术，实现 LLM 与其他工具或系统的无缝对接。

#### 3. 提示工程的广度：超越“设计提示”

这是一个非常关键的观点。提示工程的范畴远不止于“写出好的提示词”，它涵盖了一系列与 LLM 交互和开发的技能：

- **安全性 (Safety):** 利用提示工程来防御潜在风险，提高 LLM 输出的安全性。
- **能力增强 (Augmenting Capabilities):**
  - **领域知识:** 将特定行业的专业知识注入模型。
  - **外部工具:** 让模型学会使用计算器、搜索引擎或 API（这是构建 AI Agent 的基础）。

#### 4. 为什么需要这份指南？

随着人们对 LLM 开发的兴趣激增，该指南旨在整合以下资源：

- 最新的学术论文 (Latest papers)
- 高级提示技术 (Advanced prompting techniques)
- **特定模型的提示指南 (Model-specific guides)**
- 相关讲座、参考资料及工具

---

### 总结

这段介绍将提示工程从一种“技巧”提升到了“工程方法论”的高度。它强调了**结构化交互**的重要性，不仅是为了获得答案，更是为了构建可靠、安全且功能强大的 AI 系统。

接下来，我们可以进入具体的**提示技术**章节，或者您希望先了解**LLM 设置**的相关细节？

---

基于您提供的**简介 (Introduction)** 章节，以下是核心内容的专业解读。这一节为整个指南设定了基调，并明确了实验环境。

### 1. 学科定义与目标

提示工程（Prompt Engineering）被正式定义为一门**相对较新的学科**。

- **核心动作：** 开发（Developing）和优化（Optimizing）提示。
- **最终目的：** 为了在广泛的应用和用例中，高效地应用和构建大语言模型（LLM）。

### 2. 技能价值与受众

掌握提示工程技能对于理解 LLM 的**能力（Capabilities）**和**局限性（Limitations）**至关重要。

- **对于研究人员 (Researchers):**
  - 关注点：**安全性 (Safety)** 与 **能力提升 (Capacity)**。
  - 应用：解决问答（QA）和算术推理等复杂任务。
- **对于开发者 (Developers):**
  - 关注点：**稳健性 (Robustness)** 与 **集成 (Interface)**。
  - 应用：设计有效的提示技术，将 LLM 与其他工具或系统连接起来。

### 3. 指南范围

本指南旨在涵盖提示工程的**理论 (Theory)** 与 **实践 (Practical aspects)**，教导用户如何利用最佳技术与 LLM 进行交互和构建应用。

### 4. 实验环境与参数配置 (关键技术细节)

为了确保示例的可复现性，文档明确了测试基准：

- **基准模型：** `gpt-3.5-turbo`。
- **测试平台：** OpenAI Playground。
- **默认参数：**
  - `temperature=1`: 温度设置为 1，意味着模型输出具有较高的随机性和多样性（非确定性）。
  - `top_p=1`: 核采样设置为 1，意味着模型考虑所有可能的下一个 token。
- **兼容性提示：** 虽然这些提示在具有类似能力的其他模型上应该也能工作，但具体的响应内容可能会有所不同。

---

**Copilot 见解：**
注意这里的参数设置 `temperature=1`。在生产环境中，如果你需要模型输出非常稳定、确定的答案（例如提取数据或代码生成），通常会将温度调低（如 0 或 0.2）。指南使用默认的高温度可能是为了展示模型的生成能力和多样性，但在实际工程落地时，你需要根据任务类型调整这些参数。

---

基于您提供的 **LLM 设置 (LLM Settings)** 章节，以下是对各个关键参数的专业讲解。

在使用 API 与 LLM 交互时，调整这些参数对于控制输出的**可靠性 (Reliability)** 和 **合意性 (Desirability)** 至关重要。通常需要通过实验来找到最适合特定用例的配置。

### 1. 核心采样参数 (控制随机性)

这两个参数决定了模型如何选择下一个 token（词/字）。**一般建议：只调整 Temperature 或 Top P 其中之一，不要同时调整。**

- **Temperature (温度):**
  - **原理：** 调整候选 token 的概率权重。
  - **低温度 (如 0.1):** 结果更具**确定性 (Deterministic)**。模型总是选择概率最高的词。适用于基于事实的问答 (QA)、代码生成。
  - **高温度 (如 0.8+):** 结果更具**随机性 (Randomness)**。增加了其他可能 token 的权重，鼓励多样性和创造力。适用于写诗、创意写作。
- **Top P (核采样 / Nucleus Sampling):**
  - **原理：** 仅从累积概率达到 P% 的 token 集合中进行选择。
  - **低 Top P:** 仅考虑最自信的答案，结果精确且基于事实。
  - **高 Top P:** 允许模型考虑更多可能性的词（包括那些不太可能的），从而产生更多样化的输出。

### 2. 长度与结构控制

- **Max Length (最大长度):**
  - **作用：** 限制模型生成的 token 数量。
  - **目的：** 防止模型生成冗长或无关的废话，同时有效控制 API 调用成本。
- **Stop Sequences (停止序列):**
  - **作用：** 定义一个字符串，一旦模型生成该字符串，就会立即停止生成。
  - **应用：** 控制输出结构。例如，如果你想要一个不超过 10 项的列表，可以将 "11" 设为停止序列。

### 3. 重复性惩罚 (控制多样性)

这两个参数用于解决模型“复读机”问题或鼓励话题转换。**一般建议：只调整其中之一，不要同时调整。**

- **Frequency Penalty (频率惩罚):**
  - **机制：** 惩罚力度与 token 出现的**次数成正比**。出现次数越多，惩罚越重。
  - **效果：** 显著减少特定单词的逐字重复。
- **Presence Penalty (存在惩罚):**
  - **机制：** 只要 token 出现过（无论几次），就施加**相同的惩罚**。
  - **效果：** 防止模型重复使用相同的短语或话题。如果你希望模型转向新话题或更具创造性，可以调高此参数；如果希望模型保持专注，则调低。

### 总结建议

- **事实性任务：** 低 Temperature，低 Top P，低 Penalty。
- **创意性任务：** 高 Temperature 或 高 Top P，适当提高 Penalty 以增加词汇丰富度。

---

基于您提供的 **提示基础 (Basics of Prompting)** 章节，以下是对提示工程核心机制与格式规范的专业讲解。

这一节从最简单的交互开始，逐步引出了提示工程的本质：**通过结构化的指令和示例，将模型的“文本补全”能力转化为“任务执行”能力。**

### 1. 提示的本质与改进 (Prompting an LLM)

#### 从“补全”到“指令”

LLM 的基础能力是预测下一个 token。

- **基础提示 (Basic Prompt):**
  - _输入:_ `The sky is`
  - _输出:_ `blue.`
  - _问题:_ 模型只是顺着语流补全了句子。结果虽然通顺，但可能不是你想要的（比如你可能想要一句诗，或者科学解释）。
- **工程化提示 (Engineered Prompt):**
  - _输入:_ `Complete the sentence: The sky is`
  - _输出:_ `blue during the day and dark at night.`
  - _改进:_ 通过添加**指令 (Instruction)**，明确了任务目标。这就是提示工程的核心——设计有效的指令来引导模型执行特定任务。

#### 聊天模型的角色结构

在使用如 `gpt-3.5-turbo` 等现代聊天模型时，提示被结构化为三种角色：

- **System (系统):** 设定 AI 的整体行为、角色或风格（如“你是一个乐于助人的助手”）。
- **User (用户):** 具体的指令或问题。
- **Assistant (助手):** 模型的回复。在构建少样本提示时，开发者可以伪造 Assistant 的回复作为示例。

### 2. 提示格式化 (Prompt Formatting)

提示的格式直接影响模型的理解效率。

#### 零样本提示 (Zero-shot Prompting)

这是最直接的方式，不给模型任何示例，直接提问。

- **标准格式:** `<Question>?` 或 `<Instruction>`
- **QA 格式:**
  ```text
  Q: <Question>?
  A:
  ```
- **适用场景:** 模型已经具备相关知识的通用任务。现代模型通常不需要 "Q:" 前缀也能理解这是问答任务。

#### 少样本提示 (Few-shot Prompting)

这是提示工程中非常强大的一种技术，也称为**上下文学习 (In-context Learning)**。

- **核心逻辑:** 在提问之前，先给模型看几个“问题-答案”的**示例 (Exemplars/Demonstrations)**。
- **格式示例 (QA):**

  ```text
  Q: <问题1>?
  A: <答案1>

  Q: <问题2>?
  A: <答案2>

  Q: <目标问题>?
  A:
  ```

- **格式示例 (分类任务):**
  ```text
  This is awesome! // Positive
  This is bad! // Negative
  What a horrible show! //
  ```
  _模型会自动补全为 `Negative`。_

### 总结

- **提示要素:** 一个好的提示通常包含`指令、上下文、输入数据和输出指示`。
- **少样本的威力:** 通过提供示例，你可以让模型快速“学会”特定的输出格式或逻辑，而无需重新训练模型。这将在后续章节中详细讨论。

---

基于您提供的 **提示要素 (Elements of a Prompt)** 章节，以下是对构成一个高效提示的四大核心组件的专业拆解。

理解这些要素是将提示工程从“凭感觉写”转变为“结构化设计”的关键。

### 1. 提示的四大核心要素

一个完整的提示通常包含以下四个部分（虽然并非每次都需要全部包含）：

1.  **指令 (Instruction):**
    - **定义：** 你希望模型执行的具体任务或命令。
    - _作用：_ 确立任务的性质（如：翻译、总结、分类、代码生成）。
2.  **上下文 (Context):**
    - **定义：** 能够引导模型做出更好反应的外部信息或背景情况。
    - _作用：_ 缩小解空间，设定角色或风格。例如，提供少样本（Few-shot）示例就是一种极佳的上下文形式。
3.  **输入数据 (Input Data):**
    - **定义：** 我们感兴趣的、需要模型处理的具体输入或问题。
    - _作用：_ 任务的操作对象。
4.  **输出指示 (Output Indicator):**
    - **定义：** 期望输出的类型或格式。
    - _作用：_ 规范结果。例如，以“Sentiment:”结尾提示模型只需输出情感标签，或者明确要求“以 JSON 格式输出”。

### 2. 实例拆解分析

为了更好地理解这些概念，让我们分析文档中提供的文本分类提示：

> **Prompt:**
>
> ```text
> Classify the text into neutral, negative, or positive
>
> Text: I think the food was okay.
>
> Sentiment:
> ```

**结构分析：**

- **指令 (Instruction):** `Classify the text into neutral, negative, or positive`
  - 明确了任务是分类，并限定了标签范围。
- **输入数据 (Input Data):** `Text: I think the food was okay.`
  - 这是模型需要分析的具体内容。
- **输出指示 (Output Indicator):** `Sentiment:`
  - 这引导模型直接在冒号后生成结果，而不是输出一长串解释。
- **上下文 (Context):** _（此示例中缺失）_
  - 文档指出，虽然此例未包含上下文，但如果任务复杂，可以在指令后添加几个分类示例作为上下文，帮助模型理解什么是“中性”，什么是“积极”。

### 3. 关键原则

**不必面面俱到：** 您不需要在每个提示中都包含所有这四个要素。格式的选择取决于手头任务的复杂性。简单的任务可能只需要指令和输入，而复杂的任务则需要详尽的上下文和严格的输出指示。> Classify the text into neutral, negative, or positive

> Text: I think the food was okay.
>
> Sentiment:
>
> ```
>
> ```

**结构分析：**

- **指令 (Instruction):** `Classify the text into neutral, negative, or positive`
  - 明确了任务是分类，并限定了标签范围。
- **输入数据 (Input Data):** `Text: I think the food was okay.`
  - 这是模型需要分析的具体内容。
- **输出指示 (Output Indicator):** `Sentiment:`
  - 这引导模型直接在冒号后生成结果，而不是输出一长串解释。
- **上下文 (Context):** _（此示例中缺失）_
  - 文档指出，虽然此例未包含上下文，但如果任务复杂，可以在指令后添加几个分类示例作为上下文，帮助模型理解什么是“中性”，什么是“积极”。

### 3. 关键原则

**不必面面俱到：** 您不需要在每个提示中都包含所有这四个要素。格式的选择取决于手头任务的复杂性。简单的任务可能只需要指令和输入，而复杂的任务则需要详尽的上下文和严格的输出指示。

---

基于您提供的 **设计提示的一般技巧 (General Tips for Designing Prompts)** 章节，以下是五个核心原则的专业解读。这些原则是构建高质量提示的基石。

### 1. 从简单开始 (Start Simple)

提示工程是一个**迭代过程 (Iterative Process)**。

- **策略：** 不要试图一次性写出完美的复杂提示。先从简单的指令开始，观察结果，然后逐步添加上下文、约束和示例。
- **分解任务：** 如果任务很复杂，将其拆解为简单的子任务，逐个击破。这比一开始就设计一个庞大的提示要有效得多。

### 2. 指令的位置与清晰度 (The Instruction)

- **使用动词：** 使用明确的命令词，如 "Write"（写）、"Classify"（分类）、"Summarize"（总结）、"Translate"（翻译）。
- **位置建议：** 许多专家建议将指令放在提示的**最开头**。
- **分隔符：** 使用清晰的分隔符（如 `###`）将指令与上下文或输入数据分开。这有助于模型区分“要做什么”和“处理什么”。

  - _示例：_

    ```text
    ### Instruction ###
    Translate the text below to Spanish:

    Text: "hello!"
    ```

### 3. 具体性 (Specificity)

这是提示工程中最重要的原则之一。**越具体，结果越好。**

- **描述性：** 详细描述你想要的任务和结果。如果你有特定的风格或格式要求，必须明确指出。
- **提供示例：** 在提示中包含示例是实现具体性的最有效方法之一（即少样本提示）。
- **平衡长度：** 虽然要具体，但也要避免无关的细节。每一个细节都应该对任务有贡献。
- **格式控制示例：**
  - _Prompt:_ `Extract the name of places... Desired format: Place: <comma_separated_list_of_places>`
  - _效果:_ 强制模型按指定格式输出，便于后续程序处理。

### 4. 避免模糊 (Avoid Impreciseness)

不要试图用复杂的语言去“耍小聪明”，直接了当是最好的沟通方式。

- **反面教材：** `...Keep the explanation short, only a few sentences, and don't be too descriptive.`
  - _问题:_ “短”是多少？“不太描述性”是什么意思？这很模糊。
- **正面教材：** `Use 2-3 sentences to explain the concept of prompt engineering to a high school student.`
  - _改进:_ 明确了长度（2-3 句）和目标受众（高中生），这隐含了对风格和深度的要求。

### 5. 做什么 vs 不做什么 (To do or not to do?)

模型通常**更擅长执行“正向指令”，而不是“负向指令”。**

- **原则：** 尽量告诉模型**要做什么**，而不是**不要做什么**。
- **案例分析：**
  - _失败提示:_ `DO NOT ASK FOR INTERESTS.`（不要询问兴趣）。结果模型还是问了，因为否定句有时会被忽略或误解。
  - _成功提示:_ `The agent is responsible to recommend a movie from the top global trending movies.`（代理负责推荐全球热门电影）。
  - _解析:_ 通过给出一个具体的替代行为（推荐热门电影），自然地规避了询问用户兴趣的需求。

### 总结

设计提示就像编写代码：**模块化（分解任务）、语法清晰（使用分隔符）、逻辑明确（正向指令）、定义精确（具体性）。** 遵循这些原则可以显著提高与 LLM 交互的效率和准确性。

---

基于您提供的 **提示示例 (Examples of Prompts)** 章节，以下是对各个应用场景的专业讲解与核心技术提炼。

这一节通过具体的案例，展示了如何将前面学到的理论（指令、上下文、格式）应用到实际任务中。

### 1. 信息提取 (Information Extraction)

- **任务：** 从非结构化文本中提取特定实体或信息。
- **核心技术：** **指令明确化**。
- **案例分析：**
  - 提示明确要求“Mention the large language model based product mentioned...”（提及段落中提到的大语言模型产品）。
  - 这展示了 LLM 不仅能生成文本，还能作为高效的 NLP 分类器或提取器使用。

### 2. 问答 (Question Answering)

- **任务：** 基于给定的上下文回答问题。
- **核心技术：** **RAG (检索增强生成) 的雏形**。
  - 结构：`Context` + `Question` + `Answer`。
  - 约束：`Keep the answer short`（保持简短），`Respond "Unsure..." if not sure`（不确定则回答不知道）。这是减少**幻觉 (Hallucination)** 的关键手段。

### 3. 文本分类 (Text Classification)

- **任务：** 将文本归类为特定标签（如情感分析）。
- **核心技术：** **少样本提示 (Few-shot Prompting) 用于格式控制**。
  - _问题:_ 简单的指令可能导致模型输出 `Neutral`（首字母大写），而你需要 `neutral`（全小写）。或者模型可能忽略拼写错误的标签（如 `nutral`）。
  - _解决方案:_ 提供一个示例 `Text: ... Sentiment: neutral`。这不仅教会了模型分类逻辑，还强制规定了输出格式（全小写）。
  - _启示:_ 示例的作用不仅仅是传授知识，更是**规范行为**。

### 4. 对话 (Conversation)

- **任务：** 构建具有特定角色或风格的聊天机器人。
- **核心技术：** **角色提示 (Role Prompting)**。
  - _指令:_ `The assistant tone is technical and scientific.` vs `...easy to understand even by primary school students.`
  - _效果:_ 同样的输入（“什么是黑洞？”），模型根据角色设定给出了截然不同的回答（专业术语 vs 通俗易懂）。这是构建个性化 AI 产品的核心。

### 5. 代码生成 (Code Generation)

- **任务：** 生成特定编程语言的代码或数据库查询。
- **核心技术：** **上下文感知**。
  - _案例:_ 生成 MySQL 查询。
  - _关键:_ 提示中提供了数据库架构信息（表名、列名）。模型利用这些上下文生成了准确的 SQL 语句。这证明了 LLM 具备极强的逻辑转换能力。

### 6. 推理 (Reasoning)

- **任务：** 处理数学计算或逻辑推导。
- **核心技术：** **思维链 (Chain-of-Thought) 的雏形**。
  - _挑战:_ LLM 在直接回答复杂算术问题时容易出错（如判断奇数和的奇偶性）。
  - _解决方案:_ `Solve by breaking the problem into steps.`（分步解决）。
  - _效果:_ 强制模型先列出奇数，再求和，最后判断。这种“分步思考”显著提高了准确率。这是后续章节将深入探讨的高级技术。

### 总结

本章通过六个维度的示例，展示了提示工程的实战威力：

1.  **指令**决定任务类型。
2.  **上下文**提供解题依据。
3.  **示例**规范输出格式。
4.  **角色**设定语言风格。
5.  **分步思考**提升逻辑准确性。

接下来，我们将进入更高级的**提示技术 (Prompting Techniques)** 章节，深入探讨零样本、少样本和思维链等前沿方法。
