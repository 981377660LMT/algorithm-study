这篇文章通过 Google DeepMind 让 Gemini 2.5 Pro 玩《宝可梦：红/蓝》的案例，深入剖析了构建 AI 智能体（Agent）时面临的复杂现实。

以下是详细分析讲解：

### 1. 核心发现：结构化数据优于原始视觉

- **视觉局限**：尽管 Gemini 在视觉基准测试中表现优异，但它难以直接读取 Game Boy 屏幕上的像素字体。
- **解决方案**：开发团队不得不从游戏的 RAM 中提取文本并插入上下文。
- **启示**：对于智能体而言，**信息控制设计**至关重要。有时，直接提供结构化数据（如 RAM 文本）比让多模态模型去“看”图像更有效且可靠。

### 2. 上下文管理的陷阱：多即是少

- **长上下文的副作用**：虽然 Gemini 支持百万级 Token，但在玩游戏时，当上下文超过 10 万 Token，模型反而表现变差。它开始倾向于**重复历史动作**，而不是合成新计划。
- **启示**：基准测试（如长文本检索）的成功并不代表在多步推理任务中也能奏效。智能体开发者必须建立自己的评估体系（Evals），防止模型被冗长的历史记录“带偏”。

### 3. 训练数据的“污染”与干扰

- **先验知识的误导**：Gemini 学习过互联网上的所有攻略。在《红/蓝》版本中，过关需要给守卫饮料；但在重制版《火红/叶绿》中，需要给“茶”。
- **结果**：模型在原版游戏中执着于寻找并不存在的“茶”，导致卡关数小时。
- **启示**：模型自带的知识库有时会与当前任务环境发生冲突，需要通过提示词（如“忽略先验知识”）来强行修正。

### 4. 上下文中毒（Context Poisoning）

- **定义**：当模型产生的幻觉（如上述的“茶”）被写入其记录目标的“草稿本（Scratchpad）”时，就会发生上下文中毒。
- **后果**：模型会变得偏执，反复尝试实现不可能或无关的目标。
- **极端策略**：中毒后的模型甚至会采取“自杀式”策略（让宝可梦全部晕倒以传送回中心），只为了摆脱逻辑困境。

### 5. 智能体的“情绪”与压力响应

- **压力下的失常**：在紧张的游戏战斗或复杂场景中，Gemini 会出现“过度焦虑”，导致它忘记使用寻路工具（Pathfinder），甚至逻辑崩溃。
- **启示**：模型在处理高压、高频反馈任务时，其推理能力的稳定性会受到挑战。

### 6. 极简工具论

- **工具设计**：完成整个游戏，DeepMind 仅为 Gemini 设计了两个核心工具：
  1.  **寻路工具 (Pathfinder)**：基于地图 XML 模型进行导航。
  2.  **推石块策略工具 (Boulder Puzzle Strategist)**：专门用于解决特定的解谜关卡。
- **启示**：强大的智能体不需要无数个工具，而需要**高度适配核心痛点**的专用工具。

### 总结

这个案例表明，构建一个成功的智能体不仅仅是选择一个强大的模型，更是一场关于**上下文工程（Context Engineering）**、**信息过滤**以及**工具调用逻辑**的精细博弈。DeepMind 的“败笔”和“补丁”为所有开发者提供了宝贵的实战教训。
