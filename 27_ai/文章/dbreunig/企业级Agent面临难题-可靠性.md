这篇文章 **《Enterprise Agents Have a Reliability Problem》（企业级 Agent 面临可靠性难题）** 发布于 2025 年 12 月 6 日，作者深入剖析了 2025 年企业 AI 应用的一个怪圈：**现成的 AI 工具（如 ChatGPT）火爆异常，但企业内部开发的 AI Agent（智能体）却难以落地。**

以下是对这篇文章的详细讲解和核心观点梳理：

### 1. 核心矛盾：冰火两重天

文章开篇指出了一个看似矛盾的现象，通过对比多份行业报告揭示了真相：

- **繁荣的表象：** 许多报告声称 AI 在企业中的采用率正在飙升。
- **残酷的现实：**
  - **第三方工具（Off-the-shelf）：** 如 ChatGPT、Copilot、Gemini 等现成工具，在企业员工中被广泛使用且备受推崇。
  - **第一方开发（Internal 1st party）：** 企业内部投入研发的 AI 试点项目（Pilots）和自定义 Agent，绝大多数都失败了，无法进入生产环境，也无人问津。

### 2. 证据链：四大报告揭示的困境

作者引用了四个主要机构的报告来支撑他的观点：

1.  **Wharton/GBK AI 采用率报告：**

    - 虽然 82% 的领导者每周使用 GenAI，但绝大多数用的是现成的聊天机器人。
    - 所谓的“自定义解决方案”虽然预算在增加，但实际使用率极低。

2.  **MIT NANDA 报告：**

    - **惊人数据：** 95% 的企业生成式 AI 试点项目宣告失败。
    - **归因偏差：** 企业领导者认为失败原因是“员工不愿意采用新工具”。但作者反驳说，员工既然愿意用 ChatGPT，说明他们不排斥 AI，他们排斥的是**不好用的内部工具**。

3.  **McKinsey（麦肯锡）AI 现状报告：**

    - 只有不到 10% 的受访者表示他们的 Agent 项目走出了试点阶段，真正进入了生产环境。

4.  **Google Cloud 报告：**
    - 虽然声称 Agent 使用广泛，但他们把 ChatGPT 也定义为 Agent，这混淆了视听。

### 3. 根本原因：可靠性（Reliability）

为什么企业自己造的 AI 工具没人用？作者给出的答案很简单：**`不可靠`。**

文章引用了 UC Berkeley 的 Melissa Pan 领导的研究《Measuring Agents in Production》（评估生产中的 Agent），揭示了为了让 Agent 能用，开发者不得不做出的妥协：

- **降低野心：** 为了达到可用的可靠性，开发者被迫构建非常简单的 Agent。
- **缩短流程：** 68% 的生产级 Agent 执行步骤少于 10 步。
- **人机回环（Human-in-the-loop）：** 92.5% 的 Agent 输出是给人类看的，而不是直接传给其他软件。这意味着 Agent 缺乏独立工作的自主权。
- **结论：** 组织故意限制 Agent 的自主性，以维持其可靠性。

### 4. 旁证：OpenRouter 的数据

OpenRouter（一个聚合 LLM API 的平台）发布的“State of AI”报告进一步证实了这一点：

- **停滞的复杂性：** 除了**编程类 Agent**（这是一个特例，表现很好）之外，其他所有领域的 Prompt 长度和序列长度都处于停滞状态。
- 这说明开发者并没有构建越来越复杂的 Agent，而是为了求稳，保持 Prompt 简单、流程短小。

### 5. 总结与建议

作者最后对这一现象进行了总结和建议：

- **为员工正名：** 员工不使用内部 AI 工具不是因为顽固，而是因为**理性**。如果工具不可靠、经常出错，理性的选择就是不使用它。
- **短期策略：** 成功的团队应该**限制范围（Constrained Scope）**。不要试图构建无所不能的超级 Agent，而是构建简单、可靠的小工具来赢得信任。
- **长期展望：** 想要实现更大的野心，我们需要更好的 AI 工程化工具来解决可靠性问题。

**一句话总结：**
在 2025 年，企业 AI 的真相是：员工热爱 ChatGPT，但讨厌公司内部开发的半成品。因为内部开发的 Agent 太不可靠，开发者为了上线不得不将其“降智”为简单的自动化脚本。要想破局，必须先解决“可靠性”这个拦路虎。
