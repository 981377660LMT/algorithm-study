这篇文章分析了 Anthropic 公司在发布 Claude 4.0 时，其系统提示词（System Prompt）相对于 3.7 版本的变化，并揭示了该公司的产品优先级和开发周期。

以下是详细分析讲解：

### 1. “热修复”的演进：从提示词到模型权重

作者观察到，系统提示词是 Anthropic 处理模型缺陷的“第一道防线”：

- **旧问题的解决**：3.7 版本中针对特定逻辑错误（如“Strawberry 中有几个 R”）的指令在 4.0 中消失了。这说明这些问题已通过**后训练（Post-training）和强化学习（RL）**被固化到了模型权重中。
- **新问题的出现**：4.0 增加了一条新指令，禁止模型过度奉承用户（不准说“好问题”、“深刻的见解”）。这显然是针对竞争对手（如 GPT-4o）近期表现出的“谄媚”倾向而做的快速热修复。

### 2. 搜索策略：从“征求许可”到“主动出击”

- **行为转变**：在 3.7 中，Claude 被要求在不确定时先询问用户是否需要搜索；而在 4.0 中，对于时效性强或不稳定的信息，Claude 被授权**立即搜索**。
- **行业信号**：这表明 Anthropic 对其搜索工具的可靠性更有信心，同时也反映出聊天机器人正在加速蚕食 Google 的搜索领地。

### 3. Artifacts（制品）功能的细化

- **用户驱动的设计**：系统提示词中增加了对 Artifacts 使用场景的描述，如“饮食计划、健身方案、学习指南”。
- **UX 编程**：Anthropic 正在利用自然语言（系统提示词）来“编程”聊天机器人的交互行为，使其更符合观察到的用户真实使用习惯。

### 4. 上下文限制的无奈：代码风格的妥协

- **节省 Token**：4.0 的提示词竟然要求模型在编写代码时使用**简短的变量名**（如 `i`, `j`, `e`），以节省上下文空间。
- **竞争压力**：相比 Gemini 2.5 和 GPT-4.1 的 100 万 Token 限制，Claude 4.0 仅支持 20 万 Token。这种在提示词中强制缩减代码长度的做法，反映了 Anthropic 在处理长上下文效率上的瓶颈。

### 5. 安全护城河：新增网络犯罪防御

- **防御升级**：4.0 显著加强了对恶意代码、漏洞利用和协议分析的拒绝指令。即使是以“教育目的”为借口，模型也被要求必须拒绝处理任何疑似与恶意软件相关的请求。

### 6. 总结：系统提示词即“用户体验（UX）”

作者认为，系统提示词不仅是指令，更是聊天机器人的**核心 UX 设计**：

- **开发周期**：Anthropic 的开发模式是“观察用户行为 -> 系统提示词热修复 -> 下一代模型强化学习”。
- **优先级透明化**：系统提示词占据了 4.0 上下文窗口的 11%（约 23,000 Token），这清晰地展示了 Anthropic 在安全、效率和搜索能力上的权衡。

**核心结论：** 系统提示词是观察 AI 公司如何平衡模型能力、用户安全和竞争策略的最佳窗口。
