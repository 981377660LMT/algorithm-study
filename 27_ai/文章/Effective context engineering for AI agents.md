https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents

好的，这是对《Effective context engineering for AI agents》这篇文章的深入详细讲解。

这篇文章的核心思想是，随着我们从简单的单次问答转向构建更复杂的、能够自主行动的 AI 代理（Agent），我们的关注点需要从“提示工程”（Prompt Engineering）转向“上下文工程”（Context Engineering）。

**上下文工程**不仅仅是编写完美的提示词，而是指**管理和策划在与大语言模型（LLM）交互的每一步中提供给它的所有信息（即“上下文”）**，以最高效的方式引导模型产生我们期望的行为。

以下是文章关键要点的详细解析：

### 1. 上下文工程 vs. 提示工程

- **提示工程 (Prompt Engineering)**：主要关注如何编写和组织指令（特别是系统提示），以在单次或少数几次交互中获得最佳结果。
- **上下文工程 (Context Engineering)**：一个更广阔的概念，它涵盖了在模型进行推理时，进入其“视野”的所有信息。这包括系统提示、可用的工具、外部数据、历史对话记录等。它是一个**持续和迭代**的过程，在代理运行的每一步都需要决定哪些信息应该被保留或舍弃。

### 2. 为什么上下文工程至关重要？

文章指出了一个关键问题：**上下文衰减 (Context Rot)**。

- **核心问题**：就像人类的短期记忆有限一样，LLM 的“注意力预算”（Attention Budget）也是有限的。随着上下文窗口中的信息（Token 数量）越来越多，模型准确回忆和利用其中信息的能力会下降。
- **技术原因**：这源于 Transformer 架构的内在限制。该架构中，每个 Token 都会与其他所有 Token 建立关系，导致计算复杂度随 Token 数量（n）呈 n² 增长。当上下文变长时，模型捕捉所有关系的能力被“稀释”了。
- **结论**：我们必须将上下文视为一种**有限且宝贵的资源**，其边际回报是递减的。目标是用最少、但信号最强的信息，来最大化获得期望结果的可能性。

### 3. 高效上下文的构成要素

如何构建一个“小而美”的高效上下文？文章从几个方面给出了建议：

- **系统提示 (System Prompts)**：
  - **语言**：使用极其清晰、简单、直接的语言。
  - **“高度”适中**：避免两种极端。一是过于具体、硬编码逻辑，这会使系统脆弱且难以维护；二是过于模糊、高层，这无法给模型提供具体指导。要找到一个既能有效引导行为，又足够灵活的平衡点。
  - **结构化**：使用 XML 标签（如 `<instructions>`）或 Markdown 标题来划分不同部分，使结构清晰。
- **工具 (Tools)**：
  - 工具是代理与环境交互的桥梁。
  - **设计原则**：工具功能应明确、独立、无歧义，避免功能重叠。如果人类工程师都分不清在某种情况下该用哪个工具，就不能指望 AI 能做得更好。
  - **效率**：工具返回的信息应该是“Token 高效”的，即简洁且信息量大。
- **示例 (Examples / Few-shot Prompting)**：
  - 提供示例是公认的最佳实践。
  - **要点**：不要试图用一个冗长的列表来覆盖所有边缘情况。相反，应该精心挑选一组**多样化、有代表性的典型示例**，它们就像“胜过千言万语的图片”，能高效地向模型展示期望的行为模式。

### 4. 上下文检索与代理式搜索

这部分探讨代理如何在运行时动态获取信息。

- **传统方法**：在推理前，通过 embedding 检索（RAG 的一种形式）将所有可能相关的数据一次性加载到上下文中。
- **“即时”方法 (Just in time)**：代理不预先加载所有数据，而是只维护一些轻量级的标识符（如文件路径、URL）。在需要时，它会**自主使用工具在运行时动态加载**所需数据。
  - **优点**：这更像人类的工作方式（我们不会记住所有事，而是知道去哪里查找）。它能让代理通过探索逐步发现信息（渐进式披露），并且总能获取最新信息。
- **混合策略 (Hybrid Strategy)**：结合上述两者。预先加载一些关键信息，同时赋予代理自主探索和“即时”获取更多信息的能力。文章认为这通常是最佳实践。

### 5. 针对长时程任务的上下文工程技术

当任务非常复杂，需要的时间和交互次数远超单个上下文窗口的容量时，就需要专门的技术来管理上下文。

1.  **压缩 (Compaction)**：
    - **做法**：当对话历史接近上下文窗口上限时，让模型自己对历史进行**总结和压缩**，然后用这个压缩后的摘要开启一个新的上下文窗口继续任务。
    - **关键**：压缩的艺术在于决定保留什么、丢弃什么。一个简单有效的方法是清理掉旧的工具调用及其原始结果。
2.  **结构化笔记 (Structured Note-taking / Agentic Memory)**：
    - **做法**：让代理在执行任务时，定期将关键信息、待办事项、中间结论等以结构化的形式**写入到上下文窗口之外的“记忆”中**（例如一个 `NOTES.md` 文件）。在需要时，再将这些笔记读回上下文中。
    - **优点**：这为代理提供了持久的记忆，开销很小。
3.  **子代理架构 (Sub-agent Architectures)**：
    - **做法**：将一个庞大的任务分解。由一个“主代理”负责顶层规划和协调，然后将具体的子任务分配给多个“子代理”。每个子代理在自己独立的、干净的上下文窗口中完成任务，然后只将精炼后的结果返回给主代理。
    - **优点**：实现了清晰的“关注点分离”，主代理不会被海量的细节淹没。

### 结论

上下文工程代表了我们构建 LLM 应用方式的根本性转变。核心原则始终是：**将模型的注意力视为一种宝贵的有限资源，在每一步都精心策划，找到能最大化期望结果概率的、最小但信号最强的信息集合。** 即使未来模型能力不断增强，这一原则对于构建可靠、高效的 AI 代理仍然至关重要。
