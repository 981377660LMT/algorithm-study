这份文档详细介绍了使用 **LangGraph** 构建 LLM 应用时的常见 **工作流 (Workflows)** 和 **Agent (智能体)** 模式。

主要区别在于：
*   **工作流 (Workflows)**：路径预定义，按特定顺序执行。
*   **Agent (智能体)**：动态决策，自主决定工具使用和执行过程。

以下是文档中介绍的六种核心模式总结：

### 1. 提示链 (Prompt Chaining)
最基础的模式，将一个 LLM 的输出作为下一个 LLM 的输入。
*   **适用场景**：任务可以分解为一系列固定的、可验证的小步骤（如：生成笑话 -> 检查笑点 -> 润色 -> 增加反转）。
*   **特点**：线性执行，逻辑清晰。

### 2. 并行化 (Parallelization)
同时运行多个 LLM 任务。
*   **适用场景**：
    *   **速度优化**：将任务拆分为独立的子任务同时处理（如：同时生成故事、笑话和诗歌，最后聚合）。
    *   **质量验证**：对同一任务运行多次以获取不同结果进行对比。
*   **特点**：利用异步并发提高效率。

### 3. 路由 (Routing)
根据输入内容将任务分发给专门的后续步骤。
*   **适用场景**：处理复杂且多样的用户请求（如：根据用户意图，将请求路由到“写故事”、“讲笑话”或“写诗”的专用节点）。
*   **特点**：通常使用结构化输出 (Structured Output) 来进行分类决策。

### 4. 编排器-工人 (Orchestrator-Worker)
一个中心化的“编排器”负责分解任务，并动态分配给“工人”节点执行，最后汇总结果。
*   **适用场景**：子任务数量未知或动态变化的情况（如：为一个主题生成报告，编排器决定需要写哪些章节，然后分发给工人并行写作）。
*   **特点**：利用 LangGraph 的 `Send` API 动态创建并行分支，非常灵活。

### 5. 评估器-优化器 (Evaluator-Optimizer)
引入反馈循环。一个 LLM 生成内容，另一个 LLM（或人工）进行评估并提供反馈，生成器根据反馈进行修改，直到满足标准。
*   **适用场景**：对输出质量有明确标准，需要迭代优化的任务（如：翻译优化、代码生成）。
*   **特点**：包含循环结构，直到评估通过才结束。
 
### 6. Agents (智能体)
最灵活的模式。LLM 处于循环中，自主决定是否调用工具、调用什么工具以及何时结束。
*   **适用场景**：问题和解决方案不可预测，需要自主探索和解决的任务。
*   **特点**：核心是 `ToolNode` 和条件边（判断是继续调用工具还是结束），形成 "ReAct" (Reasoning + Acting) 循环。

### 代码实现风格
文档同时提供了两种 API 的实现示例：
*   **Graph API**：显式定义 `StateGraph`、节点和边，适合复杂状态管理。
*   **Functional API**：使用 `task` 和 `entrypoint`，代码风格更像普通函数调用，适合简单流程。