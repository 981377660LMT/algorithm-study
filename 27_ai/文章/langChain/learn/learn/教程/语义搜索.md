这份指南介绍了如何使用 LangChain 构建一个基于 PDF 文档的语义搜索引擎。该过程涉及文档加载、文本分割、向量嵌入（Embeddings）以及向量存储（Vector Store）。

以下是构建该搜索引擎的核心步骤和代码示例：

### 核心步骤

1.  **加载文档 (Loading)**: 使用 `PDFLoader` 将 PDF 文件加载为 LangChain 的 `Document` 对象。
2.  **文本分割 (Splitting)**: 使用 `RecursiveCharacterTextSplitter` 将长文档分割成较小的块（Chunks），以便于嵌入和检索。
3.  **嵌入 (Embeddings)**: 使用嵌入模型（如 OpenAI, Azure, AWS 等）将文本块转换为数值向量。
4.  **向量存储 (Vector Store)**: 将生成的向量存储在向量数据库中（如 Memory, Chroma, FAISS 等），以便进行相似度搜索。
5.  **检索 (Retrieval)**: 通过查询向量存储，找到与输入问题最相似的文档块。

### 完整代码示例

以下代码演示了如何加载 PDF、分割文本、生成嵌入并进行语义搜索。

**前提条件**：
你需要安装相关依赖并设置 API Key（以 OpenAI 为例）。
```bash
npm install @langchain/community pdf-parse @langchain/openai @langchain/textsplitters
```

**实现代码**：

```typescript
import { PDFLoader } from "@langchain/community/document_loaders/fs/pdf";
import { RecursiveCharacterTextSplitter } from "@langchain/textsplitters";
import { OpenAIEmbeddings } from "@langchain/openai";
import { MemoryVectorStore } from "langchain/vectorstores/memory";

async function run() {
  // 1. 加载 PDF 文档
  // 假设文件路径为 ./nke-10k-2023.pdf
  const loader = new PDFLoader("./nke-10k-2023.pdf");
  const docs = await loader.load();
  console.log(`Loaded ${docs.length} pages.`);

  // 2. 分割文本
  const textSplitter = new RecursiveCharacterTextSplitter({
    chunkSize: 1000,    // 每个块的大小
    chunkOverlap: 200,  // 块之间的重叠部分，保持上下文连贯
  });
  const allSplits = await textSplitter.splitDocuments(docs);
  console.log(`Split into ${allSplits.length} chunks.`);

  // 3. 初始化嵌入模型 (需要设置 OPENAI_API_KEY 环境变量)
  const embeddings = new OpenAIEmbeddings({
    model: "text-embedding-3-large",
  });

  // 4. 创建向量存储并索引文档
  // 这里使用内存存储作为示例，生产环境可使用 Chroma, Pinecone 等
  const vectorStore = new MemoryVectorStore(embeddings);
  await vectorStore.addDocuments(allSplits);

  // 5. 执行相似度搜索
  const query = "What was Nike's revenue in 2023?";
  const results = await vectorStore.similaritySearch(query, 1); // 返回最相似的 1 个结果

  if (results.length > 0) {
    console.log("\nSearch Result:");
    console.log(results[0].pageContent);
    console.log("\nMetadata:", results[0].metadata);
  }
}

run().catch(console.error);
```

### 进阶：使用检索器 (Retriever)

为了将搜索集成到更复杂的 RAG（检索增强生成）工作流中，通常会将向量存储转换为检索器接口：

```typescript
// 将向量存储转换为检索器
const retriever = vectorStore.asRetriever({
  searchType: "mmr", // 使用最大边际相关性算法，平衡相关性和多样性
  searchKwargs: {
    fetchK: 5,
  },
});

// 使用检索器查询
const retrievedDocs = await retriever.invoke("When was Nike incorporated?");
console.log(retrievedDocs);
```