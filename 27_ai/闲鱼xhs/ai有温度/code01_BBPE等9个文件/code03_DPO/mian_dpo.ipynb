{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "583eff71-555b-4e73-9bb8-ea0e3c5321af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from model.model import Model\n",
    "from model.reference_model import ReferenceModel\n",
    "from data_load import CustomDataset\n",
    "from dpo import DPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25768f42-2428-47f0-84c4-493e1d2f5c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.2206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.1051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(6.7870e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.8146e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.1080e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.3605e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.0234e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.1075e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(7.8254e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.9530e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.5967e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.8278e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4788e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2213e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.4312e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0145e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(7.4545e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.6529e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.3529e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.0651e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.6042e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(8.9090e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(8.3150e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.2691e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.1483e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.0481e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.4211e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.2500e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.0972e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.0556e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.9587e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.8734e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(7.3638e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(7.1416e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(6.9464e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.3161e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.2662e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.2213e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.6928e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.6386e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.5900e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.6219e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.5293e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(9.4428e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.5782e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.5554e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.5345e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.3269e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.2682e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(4.2157e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.9236e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.9100e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.8975e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.8656e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.8567e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.8482e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.0286e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.0214e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.0142e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.3493e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.3301e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(5.3125e-08, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7821e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7676e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7439e-05, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.4404e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.4223e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(2.4048e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7974e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7792e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.7629e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5525e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5394e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(1.5269e-06, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     35\u001b[0m     train_dpo \u001b[38;5;241m=\u001b[39m TrainDpo()\n\u001b[0;32m---> 36\u001b[0m     \u001b[43mtrain_dpo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dpo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m, in \u001b[0;36mTrainDpo.train_dpo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m         batch_data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     21\u001b[0m         k: v\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdevice) \n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch_data\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     23\u001b[0m         ref_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_model(batch_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs_masks\u001b[39m\u001b[38;5;124m\"\u001b[39m])  \u001b[38;5;66;03m# 获得参考模型的logit\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minputs_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minputs_masks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model()\n",
      "File \u001b[0;32m/data/zhuantai/llm_map/code03_DPO/dpo.py:24\u001b[0m, in \u001b[0;36mDPO.train\u001b[0;34m(self, inputs_ids, attention_mask, ref_logits, labels_mask)\u001b[0m\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdpo_loss(policy_logps, ref_logps)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 24\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "File \u001b[0;32m/data/anaconda3/envs/janus/lib/python3.11/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/anaconda3/envs/janus/lib/python3.11/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/anaconda3/envs/janus/lib/python3.11/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class TrainDpo:\n",
    "    def __init__(self):\n",
    "        self.config = Config()\n",
    "        # 演员和评论家模型\n",
    "        self.model = Model(self.config).to(self.config.device)\n",
    "        self.tokenizer = self.model.tokenizer\n",
    "        # 获得策略模型优化器, 这里使用的是lora, 不优化全量数据\n",
    "        self.model_opt = Adam(self.model.parameters(), lr=self.config.lr)\n",
    "        # 参考模型\n",
    "        self.reference_model = ReferenceModel(self.config).to(self.config.device)\n",
    "        # 训练数据\n",
    "        dataset = CustomDataset(self.config.data_path, self.tokenizer)\n",
    "        self.data_loader = DataLoader(dataset, batch_size=self.config.batch_size, shuffle=True,\n",
    "                                      collate_fn=dataset.collate_fn)\n",
    "        self.dpo = DPO(self.model, self.model_opt, self.config)\n",
    "\n",
    "    def train_dpo(self):\n",
    "        for epoch in range(self.config.epochs):\n",
    "            for batch_data in self.data_loader:\n",
    "                batch_data = {\n",
    "                k: v.to(self.config.device) \n",
    "                for k, v in batch_data.items()}\n",
    "                ref_logits = self.reference_model(batch_data[\"inputs_ids\"], batch_data[\"inputs_masks\"])  # 获得参考模型的logit\n",
    "                self.dpo.train(batch_data[\"inputs_ids\"], batch_data[\"inputs_masks\"], ref_logits,\n",
    "                               batch_data[\"labels_mask\"])\n",
    "\n",
    "        self.save_model()\n",
    "\n",
    "    def save_model(self):\n",
    "        # 保存lora参数\n",
    "        self.model.model.save_pretrained(self.config.save_lora_path, safe_serialization=False)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_dpo = TrainDpo()\n",
    "    train_dpo.train_dpo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6fa49-f419-4314-a7f9-c31089dbd628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "janus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
