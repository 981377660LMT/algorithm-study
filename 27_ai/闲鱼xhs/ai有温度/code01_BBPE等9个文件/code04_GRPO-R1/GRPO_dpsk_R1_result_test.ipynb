{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e6bb49-340c-4ab1-8d01-491a71cdd514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 小红书：AI有温度，日更学习资料&面试资料\n",
    "# 作者：Tiger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b684d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import TextStreamer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6956fdd-448f-444a-801d-d29029462507",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\").to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\")\n",
    "\n",
    "model_r1 = AutoModelForCausalLM.from_pretrained(\"outputs/Qwen-0.5B-GRPO/checkpoint-1700\").to(\"cuda\")\n",
    "tokenizer_r1 = AutoTokenizer.from_pretrained(\"outputs/Qwen-0.5B-GRPO/checkpoint-1700\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0072a9bd-5493-4914-9aeb-f7817ebe79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_stream(input_text, model, tokenizer):\n",
    "    print(f\"\\n输入: \\n{input_text}\")\n",
    "    print(\"\\n输出:\")\n",
    "    \n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "    streamer = TextStreamer(tokenizer)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_length=1024,\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            streamer=streamer\n",
    "        )\n",
    "    \n",
    "    # 完整结果\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7346ee9-9e1b-4e69-8cb9-d82f86222452",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"桑切斯先生发现他五年级学生中有40%的学生最终成绩低于B。如果他有60名五年级学生，有多少学生的最终成绩是B及以上？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5320397c-aca4-43f3-bc14-9bd81401a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用\n",
    "qwen_ans = generate_with_stream(input_text, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d1fe63-5363-40fa-a515-7dea9021069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用\n",
    "r1_ans = generate_with_stream(input_text, model_r1, tokenizer_r1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
