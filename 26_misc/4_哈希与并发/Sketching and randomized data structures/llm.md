下面是一份对“Sketching and Randomized Data Structures”主题的系统性、深层次的探讨，涵盖了所列出的各个小节（1 至 11）的核心内容、思想演进、关键定理以及背后的深度洞察。尽管以下内容未必能穷尽所有细节，但希望能把主要脉络和核心本质说明清楚。

---

## 1. Hash Tables & Probability

### 1.1 基本概念与动机

- **哈希表（Hash Table）** 是一种常见的数据结构，通过将元素映射到一个在\[0, M-1\]的索引范围内，从而以近似 \(O(1)\) 时间进行插入、查找和删除操作。
- 在实现哈希表时，需要考虑冲突（collision）问题：不同的元素可能映射到相同的哈希值。
- **随机化思想** 在哈希表中的应用：选择随机哈希函数、使用随机策略处理冲突，可以在统计意义上将期望操作时间保持在常数量级。

### 1.2 哈希表中的概率分析

- 在一个有 \(n\) 个元素、桶数为 \(m\) 的哈希表中，如果哈希函数足够好（例如足够“随机”或接近均匀散列），则单个桶中元素数量大多分布在一个低量级。
- **负载因子（Load Factor）**：\(\alpha = \frac{n}{m}\)。当 \(\alpha\) 不太大时，冲突数量一般可控。
- 用概率方式来讨论期望冲突数量、期望查询时间，与传统“最坏情况分析”不同，更具弹性，且在工程实践中效果好。

---

## 2. Hashes & Randomness

### 2.1 理想哈希与随机性

- 真正的**理想哈希**意味着每个元素被独立随机地映射到 \(\{0, 1, \dots, m-1\}\)，但在实际中无法完全实现。
- 可以使用**伪随机函数（PRF）**或**通用哈希（universal hashing）**来模拟近似随机。

### 2.2 随机哈希函数的重要性

- 随机哈希用于**平均化**分布：在不懂元素分布的情况下，如果哈希函数不够随机，可能出现灾难性的碰撞或偏差。
- 引入随机哈希函数的代价：需要存储或维护一个随机种子，确保相同输入始终得到相同输出。

### 2.3 一点思考

- 哈希函数不是越复杂越好，关键在于理论上要有足够的随机性保证。
- 后续引入的**通用哈希（Universal Hashing）**正是为了在数学上给出一种保证：对任意两个不同输入，其哈希碰撞的概率是可控且可计算的。

---

## 3. Coupon Collector and More Bloom Filters

### 3.1 Coupon Collector 问题

- **问题表述**：有 \(n\) 种不同类型的奖券（coupon），每次随机抽取一种，期望要抽多少次才能集齐所有类型？
- 结论：需要约 \(n \ln n\) 次抽取才能基本收齐所有类型。精确期望为 \(n \sum\_{k=1}^n \frac{1}{k}\approx n \ln n + \gamma n\)，其中 \(\gamma\) 是欧拉常数。
- 这个问题体现了**重复试验中采样覆盖面**的分析方法，也是很多随机过程（如布隆过滤器分析）的重要基石。

### 3.2 Bloom Filter

- **定义**：布隆过滤器是一种可判断“元素是否可能在集合中”的数据结构，允许一定的假阳性率，但不存在假阴性。它通过多个独立哈希函数，将元素映射到多个位位置并置为 1。
- **关键参数**：
  - 位数组大小：\(m\)
  - 哈希函数个数：\(k\)
  - 集合大小：\(n\)
- **误报率（False Positive Rate, FPR）** 约为 \(\left(1 - e^{-kn/m}\right)^k\)。在一定条件下，适当地选取 \(k \approx \ln(2) \times \frac{m}{n}\) 可以使误报率最小化。

### 3.3 Coupon Collector 与 Bloom Filter 的关系

- 在布隆过滤器初始化之后，每次插入元素都把若干个位置置 1；若希望保持较低的误报率，需要让置 1 的位数不要太“拥挤”，与 Coupon Collector 的覆盖分析有异曲同工之处：过高的覆盖导致过高的假阳性。

---

## 4. Randomness & Independence

### 4.1 独立性（Independence）与近似独立

- **完美独立**：指随机变量彼此之间没有任何线性或非线性相关。
- 在很多算法中，为了推导概率上限或期望下界，经常假设哈希函数独立、试验独立等，这给分析带来简化。
- **近似独立（Pairwise-Independent, k-Wise-Independent）**：有时只要求“成对独立”或“k 阶独立”就能完成足够的概率分析，不一定要全局独立。

### 4.2 在随机化算法中的应用

- **哈希函数对**：成对独立意味着，对任意两个不同元素 \(x \neq y\)，\(\Pr\{h(x) = h(y)\}\) 较小且可控。
- 从实践角度看，全局独立需要巨大随机数空间和复杂度，而适当的有限阶独立可兼顾效率和分析准确度。

---

## 5. Universal Hashing

### 5.1 定义

- **通用哈希（Universal Hashing）**：给定一个哈希函数的家族 \(\mathcal{H}\)，如果对于任意的两个不同输入 \(x \neq y\)，从 \(\mathcal{H}\) 中随机选一个 \(h\) 时满足  
  \[
  \Pr\_{h \in \mathcal{H}}\bigl[h(x) = h(y)\bigr] \le \frac{1}{m},
  \]
  则称 \(\mathcal{H}\) 为一个**通用哈希族**。

### 5.2 意义

- 通用哈希保证了不同元素碰撞的概率不会过大，因而在**期望分析**里可以得到较好的结论。例如，用通用哈希实现的链式哈希表，查找、插入在期望上都是 \(O(1)\)。

### 5.3 构造方法

- 常用的是**乘法+取模**的构造，或在有限域中利用多项式等方式来保证碰撞概率受控。

---

## 6. Universal Hashing with a Prime Field

### 6.1 在有限域 \(\mathbb{Z}\_p\) 的哈希构造

- 选取一个大素数 \(p\)，保证 \(p >\) 所有可能元素取值范围。
- 对元素 \(x\) 使用参数 \(a, b\)，令  
  \[
  h(x) = (a x + b) \mod p \mod m.
  \]
  其中 \(a \neq 0\)，\(b\) 在 \(\mathbb{Z}\_p\) 上随机选择。

### 6.2 碰撞概率分析

- 若 \(x \neq y\)，则 \((a x + b) \mod p\) 与 \((a y + b) \mod p\) 相同的概率在可控范围内，满足通用哈希族的性质。
- 这类构造让实现既简单，又能借助数论中的“不可约性”与“乘法逆元”性质保证随机性。

---

## 7. Cardinality Part 1: The Hat Problem

### 7.1 问题描述

- **Hat Problem（“帽子问题”）**可以是这样一个描述：有 \(n\) 个人，每个人戴的帽子颜色随机且有许多种可能，要求推断或猜测正确有多少人能猜到自己帽子的颜色（或编号）。
- 这是一类**信息论**+**随机化**的趣味问题，重点在于如何使用某些共同约定的“哈希”或“指示信息”来最大化猜中的期望数量。

### 7.2 与基数估计（Cardinality Estimation）的联系

- Hat Problem 的很多思想与**估计集合基数**（如 HyperLogLog、Flajolet-Martin 等）有类似之处，都涉及从随机变量中获得样本信息，并根据有限的哈希信息做出推断。
- 利用随机哈希可以让多个人（或多台机器）在不进行大规模通信的前提下，实现对整体某些统计量的估计。

---

## 8. Cardinality Part 2: Proof & k-th Minimum Value

### 8.1 Flajolet-Martin (FM) 及其变体

- **Flajolet-Martin 算法**通过使用哈希函数，将元素映射到一个位模式上，记录最右侧出现 1 的位置，借此估计全局基数。
- 思想：若某元素哈希值的后缀有 \(r\) 个 0，则它以概率 \(2^{-r}\) 出现这种模式。收集足够多的样本可估计集合大小。

### 8.2 k-th Minimum Value 技术

- 另一种思路：对所有元素哈希后排序，取第 \(k\) 小值。通过统计第 \(k\) 小哈希值的期望分布，可以推断集合大小。
- 在实践中可保持一个“小”样本集合，只用来存储哈希值较小的若干个，减少存储成本。

### 8.3 严谨证明

- 通过离散随机过程+指标随机变量，可形式化地证明这些算法估计基数的误差范围，并提供某种**置信区间**或**概率保证**。
- 要点：**随机哈希保证无偏**，并在统计意义上减少干扰。

---

## 9. Similarity & MinHash

### 9.1 MinHash 的背景

- 给定两个集合 \(A\) 和 \(B\)，我们常常想知道它们的相似度（如 Jaccard 相似度 \(\frac{|A \cap B|}{|A \cup B|}\)）。
- 若直接计算交并集，非常费时。MinHash 通过对元素进行哈希后仅记录最小哈希值，从而在概率意义上估计 Jaccard 相似度。

### 9.2 MinHash 核心思想

- 选取一个哈希函数 \(h\)（或多个哈希函数），对于集合 \(A\)，定义  
  \[
  \text{MinHash}(A) = \min \{\,h(x) : x \in A\}.
  \]
- 对于集合 \(A, B\)，若考虑多次独立哈希函数，MinHash 的碰撞概率（两集合最小哈希值相同）恰好等于它们的 Jaccard 相似度。
- 这样，在不必获取全部集合元素的前提下，只需比较 MinHash 签名即可近似推断集合相似度。

### 9.3 对大规模数据相似性的启示

- MinHash 是**局部敏感哈希（LSH）**的重要组成，与后续的各种近似最近邻搜索（ANN）等技术相辅相成。

---

## 10. Markov's Inequality

### 10.1 定义

- **Markov 不等式**：若 \(X\) 为非负随机变量，\(\alpha > 0\)，则  
  \[
  \Pr(X \ge \alpha) \le \frac{\mathbb{E}[X]}{\alpha}.
  \]
- 这是最基本、最常见的概率界之一，用于给出超出期望值一定倍数时发生的概率上界。

### 10.2 在算法分析中的应用

- 当我们想控制某些随机过程的“尾部风险”时，Markov 不等式可提供一个简单的上界。例如想保证数据结构溢出的概率、或某个抽样过程误差过大的概率不会太高。
- 如果想要更紧的界，往往借助 Chebyshev 不等式、Chernoff Bounds 等，这些都是同一思路在不断收紧估计。

---

## 11. CountMin Sketch

### 11.1 CountMin Sketch 的背景与应用

- 在流式数据（data stream）场景下，需要随时记录元素出现次数，但数据规模极大（无法完全保存在内存中）。
- **CountMin Sketch** 通过多组哈希函数和一个二维计数表来近似记录每个元素的频率。
  - 设计多个哈希函数 \(h_1, h_2, \dots, h_k\)。
  - 对应地维护 \(k\) 个数组（或矩阵行），其中每个数组大小为 \(w\)。
  - 每当元素 \(x\) 到来时，对于每个 \(i\)，在数组 \(i\) 的位置 \(h_i(x)\) 上加 1。

### 11.2 查询与误差分析

- 查询元素 \(x\) 的频率估计时，返回 \(\min\{\text{the }k\text{ counts for }x\}\)。
- **误差保证**：CountMin Sketch 不会低估元素的频率，但可能高估。
- 若选取 \(w \approx \frac{1}{\epsilon}\)，\(k \approx \ln \frac{1}{\delta}\)，则能以 \(1-\delta\) 的概率使误差不超过 \(\epsilon \times \text{(流总大小)}\)。

### 11.3 CountMin 与其他“Sketch”

- **Count Sketch** 与 CountMin 类似，但改用 \(\pm 1\) 更新方式来应对正负误差和减少碰撞。
- **AMS Sketch** 在第二矩（\(\ell_2\) 范数）估计和去重计数上也有广泛应用。
- 各种 Sketch 的核心都在于：用**小的存储**+**随机哈希**+**概率分析**来换取**近似结果**。

---

## 总结与思考

1. **随机化算法的本质**：

   - 使用随机哈希或抽样技术，可以有效地均衡、分摊或近似原始数据的复杂性。
   - 无需对输入分布做过多先验假设，也常常能提供高概率上的效率保证。

2. **哈希在大规模数据下的核心作用**：

   - 从基本的**哈希表**到**布隆过滤器**、**CountMin Sketch**、**MinHash**等，皆基于“用少量存储近似描述大量数据”这一思路。
   - 随机哈希函数是贯穿始终的关键，使得碰撞或统计误差可被分析并得以控制。

3. **概率分析与不等式**：

   - Markov、Chebyshev、Chernoff 等不等式，以及对随机变量独立性的恰当利用，都可以为各种随机化算法的误差范围提供上界或下界。
   - 这些不等式在推导“Sketch”类算法所需的存储规模、误差估计、置信区间等方面不可或缺。

4. **从理论到实践**：
   - 以上方法在分布式计算、流式数据分析、大规模相似检索、集合基数估计等场景有广泛应用。
   - 尽管很多结论是期望意义或高概率意义，实际中往往也足够可靠，同时极大地节省了空间和时间成本。

---

以上各部分相互关联，构成了“Sketching and Randomized Data Structures”领域的核心。无论是理解单个随机化数据结构的原理，还是将其组合用于更复杂的系统架构，都需要同时掌握以下三点：

1. **随机函数**如何设计与选取；
2. **概率分析**如何把握误差与碰撞概率；
3. **空间/时间权衡**如何在实际应用中落地。

通过这些要点，我们能从最初的哈希表到各种高级的 Sketch 结构与概率估计技术，逐步构建一套应对大规模数据的高效解决方案。
