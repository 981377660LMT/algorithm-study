https://zhuanlan.zhihu.com/c_1675205945264189440
https://zhuyie.github.io/posts/bsdiff-annotated/

bsdiff

好的，我们来深入且详细地讲解二进制差异（Binary Diffing）算法。

### 1. 什么是二进制差异算法？

二进制差异算法是一种比较两个二进制文件（例如，可执行文件 `app.exe` 的 v1.0 和 v1.1 版本）并生成一个“补丁文件”（patch file）的技术。这个补丁文件非常小，因为它只包含了从旧版本（v1.0）转变为新版本（v1.1）所需的最少信息。

然后，用户可以使用这个补丁文件和他们的旧版本文件，通过一个“应用补丁”的程序（Patcher）来重新构建出完整的新版本文件。

**核心目标**：用一个极小的补丁文件，代替分发整个巨大的新文件。

**类比**：想象一下，你写了一篇 1000 页的书，现在要出版第二版，只修改了其中的 50 个单词。你不需要把整本新书寄给编辑，你只需要告诉他：“在第 X 页，把‘旧词’换成‘新词’；在第 Y 页，删除这句话...”。这个指令列表就是“补丁”，它远比整本书要小。二进制差异算法就是为计算机程序自动生成这个“指令列表”。

### 2. 为什么需要它？（应用场景）

二进制差异算法至关重要，主要因为它能极大地节省带宽和存储空间。

- **软件更新/OTA (Over-the-Air)**：手机系统更新（Android, iOS）、桌面应用更新、游戏补丁等。下载一个几十 MB 的补丁，远比下载几个 GB 的完整安装包要快得多。
- **版本控制系统**：像 Git 这样的系统在处理大型二进制文件时，会使用或借鉴二进制差异的思想来节省仓库空间。
- **数据同步与备份**：`rsync` 等工具使用类似的算法，在同步两个文件夹时，只传输文件的差异部分，而不是整个文件。

### 3. 核心挑战：为什么比文本差异更难？

对于文本文件，差异比较相对简单。算法可以逐行比较，找到增加、删除或修改的行（例如 `diff` 命令）。

但二进制文件（如编译后的程序）完全不同：

1.  **没有“行”的概念**：二进制文件是连续的数据流。
2.  **微小改动，巨大影响**：在源代码中只修改一行，比如增加一个函数调用，可能会导致编译器重新排列成百上千个函数和数据块的内存地址。这使得两个版本的二进制文件在表面上看起来几乎完全不同，即使它们的逻辑只有细微差别。
3.  **地址和偏移量**：可执行文件中充满了绝对或相对的地址引用。一个微小的插入或删除，就会使后面的所有地址引用都失效，需要被修正。

因此，二进制差异算法不能简单地逐字节比较。它的核心思想是：**寻找两个文件中可以重复利用的、相同的数据块，无论这些数据块在旧文件中位于何处。**

### 4. 经典算法详解：`bsdiff`

`bsdiff` (Binary Suffix Diff) 是由 Colin Percival 开发的最著名和最有效的二进制差异算法之一。它的高效源于它巧妙地使用了**后缀数组（Suffix Array）**来快速查找两个文件中的共同部分。

我们来分解 `bsdiff` 的工作流程：

#### 第 1 步：寻找共同块 (Finding Common Blocks)

这是算法最关键也最耗时的一步。`bsdiff` 的目标是：对于新文件中的每一个字节，都尝试在旧文件中找到一个尽可能长的匹配块。

- **后缀数组**：`bsdiff` 首先为旧文件（`old_file`）构建一个后缀数组。

  - **什么是后缀？** "banana" 的后缀包括 "banana", "anana", "nana", "ana", "na", "a"。
  - **什么是后缀数组？** 将一个文件的所有后缀按字典序排序后，得到的原始后缀起始位置的索引数组。
  - **为什么用它？** 经过排序后，内容相同或相似的后缀会聚集在一起。这使得查找一个字符串是否存在于文件中（以及它的所有变体）变得极其高效。

- **匹配过程**：
  1.  `bsdiff` 从新文件（`new_file`）的开头开始，取一段数据。
  2.  利用旧文件的后缀数组，极快地搜索是否存在一个完全匹配的、尽可能长的块。
  3.  如果找到了一个足够长的匹配块，就记录下来。然后从新文件中匹配块的末尾继续向后搜索。
  4.  如果没有找到匹配，那么当前新文件中的这部分数据就被认为是“新数据”。

#### 第 2 步：生成补丁文件 (Generating the Patch)

经过上一步，`bsdiff` 已经知道了如何用旧文件的块和一些新数据来“拼凑”出新文件。现在它需要把这个“拼凑说明书”写入补丁文件。

`bsdiff` 的补丁文件通常包含三个部分：

1.  **控制块 (Control Block)**：
    这是一系列指令三元组 `(add, copy, seek)`。

    - `add` (x bytes)：从补丁文件的“差异块”中读取 `x` 个字节，并写入到输出文件。这部分是旧文件中没有的全新数据。
    - `copy` (y bytes)：从旧文件的当前位置读取 `y` 个字节，并写入到输出文件。这部分是可复用的数据。
    - `seek` (z bytes)：在旧文件中向前（或向后）移动 `z` 个字节，以准备下一次 `copy` 操作。这个 `seek` 操作是 `bsdiff` 强大的关键，因为它允许算法在旧文件的任何地方寻找可复用的块，而不必是连续的。

2.  **差异块 (Diff Block)**：
    这个块包含了所有在 `add` 指令中需要用到的新数据。它是所有在旧文件中找不到匹配的数据的集合。

3.  **额外块 (Extra Block)**：
    这个块包含了所有需要在 `copy` 指令中使用的、但与原始数据有差异的数据。通常是通过对旧数据和新数据进行异或（XOR）操作得到。这在两个块非常相似但又不完全相同时，可以节省空间。

#### 第 3 步：压缩

最后，`bsdiff` 使用像 `bzip2` 这样的高效压缩算法，分别对上述三个块进行压缩，生成最终的、极小的补丁文件。

### 5. 应用补丁：`bspatch`

`bspatch` 的过程则简单、快速且内存占用小得多。

1.  解压缩补丁文件，得到控制块、差异块和额外块。
2.  准备一个指向旧文件开头的指针 `old_ptr` 和一个指向差异块开头的指针 `diff_ptr`。
3.  顺序读取控制块中的每一个 `(add, copy, seek)` 指令：
    - **执行 `add x`**：从 `diff_ptr` 读取 `x` 字节，写入新生成的文件。
    - **执行 `copy y`**：从 `old_ptr` 读取 `y` 字节，写入新生成的文件。同时 `old_ptr` 向后移动 `y`。
    - **执行 `seek z`**：将 `old_ptr` 向前（或向后）移动 `z` 字节。
4.  重复此过程，直到所有控制指令执行完毕，新文件就完整地生成了。

### 总结

| 特性         | `bsdiff` (生成补丁)                       | `bspatch` (应用补丁)                              |
| :----------- | :---------------------------------------- | :------------------------------------------------ |
| **复杂度**   | 高                                        | 低                                                |
| **速度**     | 慢                                        | 快                                                |
| **内存占用** | 非常大 (需要加载整个旧文件并构建后缀数组) | 非常小 (只需要同时读取旧文件和补丁文件的一小部分) |
| **核心任务** | 寻找最优的块匹配和指令序列                | 简单地按指令执行复制和添加操作                    |

二进制差异算法的精髓在于，通过复杂的、耗时的分析（`bsdiff`），换取一个极小的补丁文件和极其快速、轻量的恢复过程（`bspatch`），这完美地契合了“一次构建，多次分发”的软件更新模式。

---

好的，你提供的这篇笔记已经对 `bsdiff` 和 `octodiff` 的原理和区别做了很好的总结。这是一个非常棒的起点。

根据你的要求“深入讲解”，我将对你笔记中的各个要点进行扩展和深化，补充一些关键的技术细节和背景，让你对二进制差异算法的理解更加透彻。

### 深入讲解

#### 1. 二进制差异的核心难题：位移（Displacement）

你提到“增量更新不能热更新，需要重启才能生效”，这背后最根本的技术原因是**地址和偏移量**。

一个编译后的可执行文件，不仅仅是代码指令的集合，它还包含了：

- **数据段**：全局变量、静态变量、字符串常量等。
- **跳转/调用指令**：`JMP <地址>`, `CALL <地址>`。
- **数据引用**：`MOV EAX, [<地址>]`。

当你对源代码做了一个微小的改动，比如增加了一个函数或一个全局变量，编译器重新编译后，这个新函数/变量会被插入到二进制文件的某个位置。这会导致它**后面所有**的代码和数据块的地址都发生**平移（Shift）**。

**结果就是：**

1.  **大量地址引用失效**：原来指向地址 `0x1000` 的指令，现在可能需要指向 `0x1020`。
2.  **简单的逐字节比较毫无意义**：即使 99%的代码逻辑完全相同，但由于地址全部改变，两个文件在二进制层面看起来几乎完全不同。

这就是为什么二进制差异算法不能像文本 `diff` 那样简单。它的核心任务必须是**在内容上识别出相同的代码/数据块，忽略它们在文件中的位置变化**。

#### 2. `bsdiff` 的精髓：全局搜索与后缀数组

你对 `bsdiff` 的原理描述是准确的。我们来深入一下“为什么是后缀数组”。

- **目的**：`bsdiff` 的策略是“贪婪”的：对于新文件中的任意一段数据，都要在旧文件中找到一个尽可能长的匹配。
- **挑战**：如何在 TB 级别的旧文件中，为新文件中的百万个不同位置，都快速找到最长匹配？暴力搜索是不可行的。
- **解决方案：后缀数组（Suffix Array）**
  - 它将旧文件的所有后缀（从每个字节开始到文件末尾的子串）按字典序排序。
  - **关键优势**：排序后，内容相似的子串会聚集在一起。例如，所有以 `MOV EAX, EBX; PUSH EBP` 开头的代码片段，无论它们在旧文件的何处，在后缀数组中都会排在一起。
  - **查找过程**：当 `bsdiff` 要为新文件的一段数据 `S` 寻找匹配时，它可以在后缀数组上通过二分查找，瞬间定位到所有与 `S` 开头相同或相似的区域，然后向后延伸比较，找到最长的匹配。

`bsdiff` 的高内存消耗正来源于此：它需要将整个旧文件读入内存，并为其构建一个庞大的后缀数组（通常是原文件大小的数倍）。它的慢也源于此：为新文件的每个部分执行这种复杂的全局搜索非常耗时。

但回报是巨大的：它能找到最优的、非连续的块复用方案，使得补丁文件极小。补丁文件中的 `seek` 指令正是这种“非连续跳跃”能力的体现。

#### 3. `octodiff` (及 `rsync`) 的精髓：分块与哈希

你对 `octodiff` 的描述也很到位。它的思想与著名的 `rsync` 算法非常相似，是一种工程上更均衡的方案。

- **核心思想**：放弃寻找“绝对最优”的字节级匹配，而是退而求其次，寻找“足够好”的**块级匹配**。
- **滚动校验和 (Rolling Checksum)**
  - 这是实现高效分块匹配的关键。它是一种特殊的哈希算法（如 Adler-32），当你计算完 `[byte_1, ..., byte_n]` 的哈希后，可以**极快地**计算出 `[byte_2, ..., byte_{n+1}]` 的哈希，而无需重新读取所有字节。
  - **工作方式**：`octodiff` 在新文件上滑动一个窗口，不断计算窗口内数据的滚动校验和。一旦这个值与旧文件签名库中的某个块的滚动校验和匹配，就意味着“可能找到了一个相同的块”。
- **强哈希 (Strong Hash)**
  - 滚动校验和可能存在碰撞（不同的数据块产生相同的哈希值）。因此，在滚动校验和匹配后，需要用一个更可靠的强哈希（如 SHA-256）进行**二次确认**，确保两个块的内容**完全一致**。

`octodiff` 的性能优势源于：

- **内存**：它只需要在内存中保留旧文件的“签名库”（哈希列表），而不是整个文件。签名库远小于文件本身。
- **速度**：查找过程是线性的。它只需要扫描一遍新文件，并在哈希表（签名库）中进行查找，这比 `bsdiff` 复杂的后缀数组搜索快得多。

代价是，由于它以“块”为单位进行匹配，对于那些跨越块边界的、或者小于一个块的细微改动，它无法做到像 `bsdiff` 那样精细的优化，因此生成的补丁通常会稍大一些。

#### 4. 对你思考的补充和验证

你关于手游热更新的思考非常正确，这里做一些深化：

1.  **增量更新 vs 热更新**：这是两个维度的概念。

    - **增量更新 (Delta Update)**：是一种**分发技术**，目的是减小下载包体的大小。
    - **热更新 (Hot-Fix/Hot-Reload)**：是一种**运行时技术**，目的是在不重启应用的情况下，动态修复逻辑或更新内容。
    - `bsdiff` 属于前者。`HybridCLR` 等方案属于后者。你可以用 `bsdiff` 去更新 `HybridCLR` 需要的热更 DLL 文件，两者并不冲突。

2.  **iOS 限制**：这是最致命的。iOS 的安全沙箱机制严格禁止对 `__TEXT` 段（即可执行代码段）进行任何修改。一旦修改，应用的签名就会失效，导致应用闪退或无法启动。因此，对主程序 `exe` 进行二进制补丁在 iOS 上是行不通的。这也是为什么所有 iOS 热更新方案都走向了基于 `Mono` 的 `C#` 解释执行或 `AOT+Interpreter` 混合模式的道路，因为它们更新的是**数据文件**（如 `dll` 文件），而不是可执行文件本身。

3.  **版本管理复杂性**：你的观察非常敏锐。
    - **链式更新**：`bsdiff` 生成的补丁是 `v1 -> v2`。如果你想从 `v1` 更新到 `v3`，你需要先应用 `v1 -> v2` 的补丁，再应用 `v2 -> v3` 的补丁，或者服务器需要单独为 `v1 -> v3` 生成一个专用补丁。
    - **多版本维护**：当线上存在 `v1, v2, v3...` 多个版本的用户时，服务器需要维护 `v1->vN`, `v2->vN`, `v3->vN`... 等大量的补丁组合，这是一个巨大的管理负担。
    - **MD5 文件替换**：这种方式虽然下载量可能更大，但逻辑极其简单：服务器只保留一份最新的完整资源，客户端计算本地文件列表的 MD5，与服务器对比，下载不一致的文件即可。逻辑清晰，维护成本低。

**结论**：在手游领域，对于代码，采用 `HybridCLR` 等热更新方案是刚需。对于资源（图片、模型、配置表），如果单个资源很大（如高清贴图、音频文件），可以考虑对单个文件使用 `bsdiff/octodiff` 进行增量更新。但更常见的做法是，为了简化管理，直接采用 MD5 整文件替换的策略，配合 CDN 来保证下载速度。
