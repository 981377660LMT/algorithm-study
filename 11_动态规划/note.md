1. 递推公式依赖几项就要几个初始值
2. 记忆化搜索(dfs)改 dp(bfs)：
   dp 的状态即为记忆化搜索里的变量

无后效性：未来与过去无关，以后做的决定不会影响之前做的决定（只有符合这一点才可以使用动态规划来做）
之前的某个状态的最优值可能因为后面某个值而导致之前取的最优值并不是适合当前值的最优值（例如：A、B 两个公司都需要招 8 个人，候选者都有 a,b 能力值，如何取人才能使得 A 公司招到员工的 a 能力值总和和 B 公司员工的 b 能力值总和加起来最大。这个就不能用动态规划去做

## 思路

- 动态规划要解决的都是一些问题的最优解，即从很多解决问题的方案中找到最优的一个
- 解决动态规划问题的核心：找出`子问题`及其`子问题与原问题`的关系

## 贪心与 dp

- 树木的举例非常形象，贪心是不完整的树，动态规范是完整的树木
  贪心：如果把所有的子问题看成一棵树的话，贪心从根出发，每次向下遍历最优子树即可，这里的最优是贪心意义上的最优。此时不需要知道一个节点的所有子树情况，于是构不成一棵完整的树
  动态规划：动态规划需要对每一个子树求最优解，直至下面的每一个叶子的值，最后得到一棵完整的树，在所有子树都得到最优解后，将他们组合成答案
- 贪心不能保证求得的最后解是最佳的，复杂度低
  动态规划本质是穷举法，可以保证结果是最佳的，复杂度高

**总结**

- `动态规划就是暴力的优化，贪心的尽头就是动态规划`
- `想象在树上做 dp，记忆化搜索是从下往上的后序dfs，dp数组就是拓扑排序bfs`
- `dp的本质就是在DAG上求最短(长)路`
  `dp[index][count] 对应 dijk 的 dist 数组 dist[index][count]`
  `不过直接拓扑序dp求最短路是线性的 堆优化dijk求最短路多了个logn`
  `用图写dp逻辑更加清晰 但是复杂度会多一个logn(如果用dijk的话，当然也可以写普通的bfs+deque)`

- 注意 **记忆化 dfs** 和 **dp 数组** 的应用场合 看是从前往后容易还是从后往前容易

其实感觉自己的`线性 dp `水平还是很弱的

- 找状态(点)
- 找转移关系(边)

**dp 的滚动数组(queue)优化空间**
如果状态转移只发生在相邻行，那么可以用滚动数组优化
想象 bfs 怎么做的，dp 就怎么做
从上面一个 dp 队列转移到下面一个 ndp 队列即可

```Python
dp = [int(1e20)] * 1024  # 这一层的queue
dp[0] = 0

for i in range(k):
    ndp = [int(1e20)] * 1024  # 下一层的queue
    for pre in range(1024):
          for cur in range(1024):
              ndp[cur] = min(ndp[cur], dp[pre] + counts[i - 1])
    dp = ndp  # 转移,C++里写 dp = move(ndp)

return dp[0]
```
